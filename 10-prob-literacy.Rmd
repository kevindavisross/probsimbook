# What is Probability? {#prob-literacy}


We hear the word "probability" often. Here are just a few quotes from recent online articles which mention probability (or odds).

- Researchers say the *probability* of living past 110 is on the rise ([CNBC, July 17, 2021](https://www.cnbc.com/2021/07/17/study-living-past-110-is-becoming-more-likely-longevity-tips.html))
- Forecasters now have a model that can predict the *probability* of rip currents up to six days out. ([CNN, July 18, 2021](https://www.cnn.com/2021/07/18/weather/weather-rip-currents-gulf-coast-great-lakes/index.html))
- A Week of negatives increases *probability* of stock market correction. ([Forbes, July 10, 2021](https://www.forbes.com/sites/johntobey/2021/07/10/opportunity-ahead-a-week-of-negatives-increases-probability-of-stock-market-correction/?sh=5d67bfe32f4f))
- Less than 1% *probability* that Earth’s energy imbalance increase occurred naturally ([Science Daily, July 28, 2021](https://www.sciencedaily.com/releases/2021/07/210728150340.htm))
- Basketball Reference's Hall of Fame *probability* model already has Giannis at 67.9 percent. ([Bleacher Report, July 23, 2021](https://bleacherreport.com/articles/2946241-giannis-epic-2021-nba-finals-sparks-new-debates-among-legends-historians))
- Study suggests that the rate of global warming increases the *probability* of extreme temperatures. ([NPR, July 29, 2021](https://www.npr.org/transcripts/1022412575))
- We anticipate an above-average *probability* for major hurricanes making landfall along the continental United States coastline and in the Caribbean. ([Weather Channel, June 1, 2021](https://weather.com/storms/hurricane/news/2021-05-20-atlantic-hurricane-season-2021-outlook-noaa-twc-may))
- Scientists fine-tune *odds* of asteroid Bennu hitting Earth through 2300 with NASA probe's help ([Space.com, Sept 3, 2021](https://www.space.com/asteroid-bennu-osiris-rex-impact-odds))

You have some familiarity with the words "probability", "chance", "odds", or "likelihood" from everyday life.  But what do we really mean when talk about "probability"?

This chapter provides a brief but non-technical introduction to randomness and probability.  Many of the topics introduced in this chapter will be covered in much more detail in later chapters.




(ref:cap-random-art) Picture generated by entering "probability" into the random art generator at <http://www.random-art.org/>

```{r random-art, echo=FALSE, fig.cap="(ref:cap-random-art)"}

knitr::include_graphics("_graphics/random-art.png")

```




## Instances of randomness {#randomness}

A wide variety of situations involve probability. Consider just a few examples.

1. The probability that you roll doubles in a turn of a board game.
1. The probability you win the next [Powerball lottery](https://www.powerball.com/) if you purchase a single ticket, 4-8-15-16-42, plus the Powerball number, 23.
1. The probability that a “randomly selected” Cal Poly student is a California resident.
1. The probability that the high temperature in San Luis Obispo tomorrow is above 90 degrees F.
1. The probability that Hurricane Peter makes landfall in the U.S.
1. The probability that the San Francisco 49ers win the next Superbowl.
1. The probability that President Biden wins the 2024 U.S. Presidential Election.
1. The probability that extraterrestrial life currently exists somewhere in the universe.
1. The probability that Alexander Hamilton actually wrote [51](https://www.youtube.com/watch?v=DPgE7PNzXag) of the [Federalist Papers](https://en.wikipedia.org/wiki/The_Federalist_Papers). (The papers were published under a common pseudonym and authorship of some of the papers is disputed.)
1. The probability that you ate an apple on April 17, 2009.


```{example randomness}

How are the situations above similar, and how are they different?  What is one feature that all of the situations have in common? Is the interpretation of "probability" the same in all situations?  Take some time to consider these questions before looking at the solution. The goal here is to just think about these questions, and not to compute any probabilities (or to even think about how you would).

```

```{solution randomness-sol}
to Example \@ref(exm:randomness)
```

```{asis, fold.chunk = TRUE}

This exercise is intended to motivate discussion, so you might have thought of some other ideas we don't address here.  That's good! And some of the things you considered might come up later in the book.  But here are a few thoughts we specifically want to mention now.

The one feature that all of the situations have in common is *uncertainty*.  Sometimes the uncertainty arises from a repeatedable physical phenomenon that can result in multiple potential outcomes, like rolling dice or drawing the winning Powerball number.  In other cases, there is uncertainty because the probability concerns the future, like tomorrow's high temperature or the result of the next Superbowl.  But there can also be uncertainty about the past: there are some Federalist papers for which the author is unknown, and you probably don't know for sure whether or not you ate an apple on April 17, 2009.

Whenever there is uncertainty, it is reasonable to consider relative likelihoods of potential outcomes.  For example, even though you don't know for certain whether you ate an apple on April 17, 2009, if you're usually an apple-a-day person (or were when you were younger) you might think the probability is high.  We don't know for sure what team will win the next Superbowl, but we might think that the 49ers are more likely than the Las Vegas (?!?!) Raiders to be the winner.

While all of the situations in the example involve uncertainty, it seems that there are different "types" of uncertainty.  Even though we don't know which side a die will land on, the notion of "fairness" implies that the sides are "equally likely".   Likewise, there are some rules to how the Powerball drawing works, and it seems like these rules should determine the probability of drawing that particular winning number.

However, there aren't any specific "rules of uncertainty" that govern whether or not you ate an apple on April 17, 2009.  You either did or you didn't, but that doesn't mean the two outcomes are necessarily equally likely.  Regarding the Superbowl, of course there are rules that govern the NFL season and playoffs, but there are no "rules of uncertainty" that tell us precisely how likely any particular team is to win any particular game, let alone how likely a team is to advance to and win the Superbowl.


It also seems that there are different interpretations of probability. Given that a six-sided die is fair, we might all agree that the probability that it lands on any particular side is 1/6.
Similarly, given the rules of the Powerball lottery, we might all agree on the probability that a drawing results in a particular winning number.  However, there isn't necessarily consensus about what the high temperature will be in San Luis Obispo tomorrow.  Different weather prediction models, forecasters, or websites might provide different values for the probability that the high temperature will be above 90 degrees Fahrenheit.
Similarly, Superbowl odds might vary by source.
Situations like tomorrow's weather or the Superbowl where there is no consensus about the "rules of uncertainty" require some subjectivity in determining probabilities.

Finally, some of these situations are repeatedable. We could (in principle) roll a pair of dice many times and how often we get doubles, or repeat the Powerball drawing over and over to see how the winning numbers behave.
However, many of these situations involve something that only happens once, like tomorrow or April, 17, 2009 or the next Superbowl.
Even when the phenomenon happens only once it reality, we can still develop models of what might happen if we were to hypothetically repeat the phenomenon many times.
For example, meteorologists use historical data and meteorological models to forecast [potential paths of a hurricane](https://www.nhc.noaa.gov/cone_usage.php).



```
	




The subject of probability concerns *random* phenomena. A phenomenon is **random**^[In this book, "random" and "uncertain" are synonyms; the opposite of "random" is "certain". (Later we will encounter random variables; "constant" is an antonym of "random variable".)  The word "random" has many uses in everyday life, which have [evolved over time](https://www.npr.org/2012/11/30/166240531/thats-so-random-the-evolution-of-an-odd-word).  Unfortunately, some of the everyday meanings of "random", like "haphazard" or "unexpected", are contrary to what we mean by "random" in this book.  For example, we would consider Steph Curry shooting a free throw to be a random phenomenon because we're not certain if he'll make it or miss it; but we would not consider this process to be haphazard or unexpected.] if there are multiple potential outcomes, and there is **uncertainty** about which outcome will occur. Uncertainty is understood in broad terms, and in particular does not only concern future occurrences.

Some phenomena involve physical randomness^[We will refer to as "random" any scenario that involves a reasonable degree of uncertainty.  We're avoiding philosophical questions about what is "true" randomness, like the following.  Is a coin flip really random? If all factors that affect the trajectory of the coin were known precisely, then wouldn't the outcome be determined?  Does true randomness only exist in quantum mechanics?], like flipping coins, rolling dice, drawing Powerballs at random from a bin, or randomly selecting Cal Poly students.  In many other situations randomness just vaguely reflects uncertainty.

Contrary to colloquial uses of the word, random does *not* mean haphazard. In a random phenomenon, while
individual outcomes are uncertain, we will see that there is a *regular distribution of
outcomes over a large number of (hypothetical) repetitions*. For example,

- In two flips of a fair coin we wouldn't necessarily see one head and one tail. But in 10000 flips of a fair coin, we might expect to see close to 5000 heads and 5000 tails. 
- We don't know who will win the next Superbowl, but we can and should consider some teams as more likely to win than others.  We could imagine a large number of hypothetical 2021-2022 seasons; how often would we expect the 49ers to win? The Raiders?
<!-- (Hopefully a lot for the Eagles; probably not much for the Raiders). -->


Random also does *not* necessarily mean equally likely. In a random
phenomenon, certain outcomes or events might be more or less likely than
others.
For example,

- It's much more likely than not that a randomly selected Cal Poly student is a California resident.
- Not all NFL teams are equally likely to win the next Superbowl.

Finally, randomness is also not necessarily undesirable.  In particular, many statistical applications often employ the planned use of randomness with the goal of collecting "good" data.
For example,

- *Random selection* involves selecting a sample of individuals "at random" from a population (e.g., via random digit dialing), with the goal of selecting a representative sample.  
- *Random assignment* involves assigning individuals at random to groups (e.g., in a randomized experiment), with the goal of constructing groups that are similar in all aspects so that the effect of a treatment (like a new vaccine) can be isolated.

The **probability** of an event associated with a random phenomenon is a number in the interval $[0, 1]$ measuring the event's likelihood or degree of uncertainty. A probability can take any values in the continuous scale from 0% to 100%^[Probabilities are usually defined as decimals, but are often colloquially referred to as percentages.  We're not sticklers; we'll refer to probabilities both as decimals and as percentages.]. In particular, a probability requires much more interpretation than "is the probability greater than, less than, or equal to 50%?" As Example \@ref(exm:randomness) suggests, there can be different interpretations of "probability", which we'll start to explore in the next section.

### Exercises


1. For each of the following, provide examples of random phenomenon that fit the description.
Try to think of examples that are interesting to you personally!
  
    a. Just two possible outcomes, but they are not equally likely.
    a. Physically repeatable (at least in principle).
    a. Well defined "rules of randomness".
    a. Involves subjectivity in determining probabilities.
    a. Involves uncertainty about the future.
    a. Involves uncertainty about the present or past.
    a. Associated with the planned use of randomness in a particular statistical study.



## Interpretations of probability {#interpretations}


In the previous section we encountered a variety of scenarios which involved uncertainty, a.k.a. randomness.  Just as there are a few "types" of randomness, there are a few ways of interpreting probability, most notably, *long run relative frequency* and *subjective probability*.








### Long run relative frequency {#rel-freq}




```{r, echo = FALSE}

N = 1000000

roll_sums = data.frame(x = apply(matrix(sample(1:6, 3 * N, replace = TRUE),
                         nrow = N), 1, sum)) 

sim_freqs = roll_sums %>%
  count(x, name = "freq") %>%
  mutate(x_ind =
           case_when(x == 9 ~ "9",
                     x == 10 ~ "10",
                     TRUE ~ "else"))

```

One of the oldest documented[^probability-literacy-4] problems in probability is the following: If three fair six-sided dice are rolled, what is more likely: a sum of 9 or a sum of 10?
Let's try to answer this question by simply rolling dice and seeing if a sum of 9 or 10 happens more frequently.
Roll three fair six-sided dice, find the sum, repeat many times, and see how often we get a sum of 9 versus a sum of 10.
Table \@ref(tab:galileo-dice-table) displays the results of a few repetitions.
We encourage you to try this out on your own now; of course, your results will naturally be different from ours.

[^probability-literacy-4]: The Grand Duke of Tuscany posed this problem to Galileo, who published his solution in 1620.
    However, unbeknownst to Galileo, the same problem had been solved almost 100 years earlier by [Gerolamo Cardano, one of the first mathematicians to study probability](http://www.columbia.edu/~pg2113/index_files/Gorroochurn-Some%20Laws.pdf).



```{r galileo-dice-table, echo = FALSE}

data.frame(matrix(sample(1:6, 3 * 10, replace = TRUE), nrow = 10)) %>%
  mutate(rep_num = row_number(), .before = everything()) %>%
  adorn_totals("col") %>%
  kable(col.names = c("Repetition", "First roll", "Second roll", "Third roll", "Sum"),
        booktabs = TRUE,
        caption = 'Results of 10 sets of three rolls of a fair six-sided die.'
  )

```

The results of a few repetitions should not be very convincing.
What we really want is to perform many, many repetitions.
Of course, this would be a time consuming process by hand, but it's quick and easy on a computer.
Figure \@ref(fig:galileo-dice) displays the result of one million repetitions of this process, each repetition resulting in the sum of three rolls.
A sum of 9 occurred in `r sim_freqs %>% filter(x == 9) %>% pull(freq)` repetitions and a sum of 10 occurred in `r sim_freqs %>% filter(x == 10) %>% pull(freq)` repetitions.
Comparing these frequencies, our results suggest that a sum of 10 is more likely than a sum of 9.

(ref:galileo-dice-cap) Results of 1 million sets of three rolls of fair six-sided dice. Sets in which the sum of the dice is 9 (10) are represented by orange (blue) spike.

```{r galileo-dice, echo = FALSE, fig.cap='(ref:galileo-dice-cap)'}

ggplot(sim_freqs,
       aes(x = x,
           xend = x,
           y = 0,
           yend = freq, col = x_ind)) +
  geom_segment(size = 1.2) +
  scale_color_manual(values = c("#56B4E9", "#E69F00", "#999999")) +
  scale_x_continuous(breaks = 3:(3 * 6)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "Sum of three rolls of six-sided dice",
       y = "Number of sets of three rolls")

```

In the previous problem we assessed relative likelihoods by repeating the process many times.
This is the idea behind the relative frequency interpretation of probability.
We'll investigate this idea further in the context of what is probably the most iconic random process: coin flipping.

We might all agree that the probability that a single flip of a fair coin lands on heads is 1/2, a.k.a., 0.5, a.k.a, 50%.
After all, the notion of "fairness" implies that the two outcomes, heads and tails, should be equally likely, so we have a "50/50 chance" of heads.
But how else can we interpret this 50%?
As in the dice rolling problem, we can consider *what would happen if we flipped the coin main times*.
Now, if we would flipped the coin twice, we wouldn't expect to necessarily see one head and one tail.
But in many flips, we might expect to see heads on something close to 50% of flips.

```{r, echo = FALSE}

n = 10 ^ (1:3)

last_n = 1000

i_n = 1:last_n

x = sample(c("H", "T"), size = last_n, replace = TRUE)

x_n = cumsum(x == "H")

x2 = cbind(as.numeric(x == "H"),
           matrix(rbinom(3 * last_n, 1, 0.5), ncol = 3))

phat_n = sweep(apply(x2, 2, cumsum), 1, i_n, FUN = '/') %>%
  as.data.frame() %>%
  mutate(i_n = row_number(), .before = everything()) %>%
  pivot_longer(cols = !i_n, names_to = "set", values_to = "proportion") %>%
  mutate(set = str_remove(set, "V"))



```

Let's try this out.
Table \@ref(tab:coin-flips-table) displays the results of `r n[1]` flips of a fair coin.
The first column is the flip number (first flip, second flip, and so on) and the second column is the result of the flip.
The third column displays the *running proportion of flips that result in H*.
For example, the first flip results in `r x[1]` so the running proportion of H after 1 flip is `r sum(x[1] == "H")`/1; the first two flips result in (`r x[1]`, `r x[2]`) so the running proportion of H after 2 flips is `r sum(x[1:2] == "H")`/2; the first three flips result in (`r x[1]`, `r x[2]`, `r x[3]`) so the running proportion of H after 2 flips is `r sum(x[1:3] == "H")`/3; and so on.
Figure \@ref(fig:coin-flips-plot) plots the running proportion of H by the number of flips.
We see that with just a small number of flips, the proportion of H fluctuates considerably and is not guaranteed to be close to 0.5.
Of course, the results depend on the particular sequence of coin flips.
We encourage you to flip a coin 10 times and compare your results.

 

```{r coin-flips-table, echo = FALSE}

knitr::kable(
  data.frame(i_n[1:n[1]],
             x[1:n[1]],
             x_n[1:n[1]],
             phat_n %>% filter(set == "1") %>% filter(i_n <= n[1]) %>% select(proportion)),
  align = "r",
  col.names = c("Flip", "Result",
                "Running count of H",
                "Running proportion of H"),
  digits = 3,
  booktabs = TRUE,
  caption = 'Results and running proportion of H for 10 flips of a fair coin.'
)

```


(ref:coin-flips-plot-cap) Running proportion of H versus number of flips for the 10 coin flips in Table \@ref(tab:coin-flips-table).

```{r coin-flips-plot, echo = FALSE, fig.cap = '(ref:coin-flips-plot-cap)'}

ggplot(phat_n %>%
         filter(set == "1") %>%
         filter(i_n <= n[1]),
       aes(x = i_n,
           y = proportion,
           col = set)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0.5, lty = "dotted") +
  scale_x_continuous(breaks = 0:n[1]) +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "Flip number",
       y = "Running proportion of H")
  

```

Now we'll flip the coin 90 more times for a total of 100 flips.
The plot on the left in Figure \@ref(fig:coin-flips-plot2) summarizes the results, while the plot on the right also displays the results for 3 additional sets of 100 flips.
The running proportion fluctuates considerably in the early stages, but settles down and tends to get closer to 0.5 as the number of flips increases.
However, each of the fours sets results in a different proportion of heads after 100 flips: `r phat_n %>% filter(set == "1", i_n == n[2]) %>% pull(proportion)` (gray), `r phat_n %>% filter(set == "2", i_n == n[2]) %>% pull(proportion)` (orange), `r phat_n %>% filter(set == "3", i_n == n[2]) %>% pull(proportion)` (blue), `r phat_n %>% filter(set == "4", i_n == n[2]) %>% pull(proportion)` (green).
Even after 100 flips the proportion of flips that result in H isn't guaranteed to be very close to 0.5.

(ref:coin-flips-plot-cap2) Running proportion of H versus number of flips for four sets of 100 coin flips.

```{r coin-flips-plot2, echo = FALSE, fig.cap = '(ref:coin-flips-plot-cap2)', fig.show="hold", out.width="50%"}


ggplot(phat_n %>%
         filter(set == "1") %>%
         filter(i_n <= n[2]),
       aes(x = i_n,
           y = proportion,
           col = set)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0.5, lty = "dotted") +
  scale_x_continuous(breaks = seq(0, n[2], 10)) +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "Flip number",
       y = "Running proportion of H")


ggplot(phat_n %>%
         filter(i_n <= n[2]),
       aes(x = i_n,
           y = proportion,
           col = set)) +
  geom_line(aes(linetype = set)) +
  geom_point(aes(shape = set)) +
  geom_hline(yintercept = 0.5, lty = "dotted") +
  scale_x_continuous(breaks = seq(0, n[2], 10)) +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  labs(x = "Flip number",
       y = "Running proportion of H")



```

Now for each set of 100 flips, we'll flip the coin 900 more times for a total of 1000 flips in each of the four sets.
The plot on the left in Figure \@ref(fig:coin-flips-plot3) summarizes the results for our original set, while the plot on the right also displays the results for the three additional sets.
Again, the running proportion fluctuates considerably in the early stages, but settles down and tends to get closer to 0.5 as the number of flips increases.
Compared to the results after 100 flips, there is less variability between sets in the proportion of H after 1000 flips: `r phat_n %>% filter(set == "1", i_n == n[3]) %>% pull(proportion)` (gray), `r phat_n %>% filter(set == "2", i_n == n[3]) %>% pull(proportion)` (orange), `r phat_n %>% filter(set == "3", i_n == n[3]) %>% pull(proportion)` (blue), `r phat_n %>% filter(set == "4", i_n == n[3]) %>% pull(proportion)` (green).
Now, even after 1000 flips the proportion of flips that result in H isn't guaranteed to be exactly 0.5, but we see a tendency for the proportion to get closer to 0.5 as the number of flips increases.

(ref:coin-flips-plot-cap3) Running proportion of H versus number of flips for four sets of 1000 coin flips.

```{r coin-flips-plot3, echo = FALSE, fig.cap = '(ref:coin-flips-plot-cap3)', fig.show="hold", out.width="50%"}

ggplot(phat_n %>%
         filter(set == "1"),
       aes(x = i_n,
           y = proportion,
           col = set)) +
  geom_line() +
  geom_hline(yintercept = 0.5, lty = "dotted") +
  scale_x_continuous(breaks = seq(0, n[3], 100)) +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "Flip number",
       y = "Running proportion of H")

ggplot(phat_n ,
       aes(x = i_n,
           y = proportion,
           col = set)) +
  geom_line(aes(linetype = set)) +
  geom_hline(yintercept = 0.5, lty = "dotted") +
  scale_x_continuous(breaks = seq(0, n[3], 100)) +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  labs(x = "Flip number",
       y = "Running proportion of H")

```

In summary, in a large number of flips of a fair coin we expect about 50% of flips to result in H.
That is, the probability that a flip of a fair coin results in H can be interpreted as the *long run proportion of flips that result in H*, or in other words, the *long run relative frequency of H*.

In general, the probability of an event associated with a random phenomenon can be interpreted as a **long run proportion** or **long run relative frequency**: the probability of the event is the proportion of times that the event would occur in a very large number of hypothetical repetitions of the random phenomenon. A natural question is: "how many repetitions are required to represent the long run?"  We'll return to this question and the idea of long run relative frequency in later chapters.


The long run relative frequency interpretation of probability can be applied when a situation can be repeated numerous times, at least conceptually, and an outcome can be observed for each repetition. One benefit of the relative frequency interpretation is that the probability of an event can be *approximated by simulating* the random phenomenon a large number of times and determining the proportion of simulated repetitions on which the event occurred out of the total number of repetitions in the simulation. A **simulation** involves an artificial recreation of the random phenomenon, usually using a computer.  After many repetitions the relative frequency of the event will settle down to a single constant value, and that value is the approximately the probability of the event.

Of course, the accuracy of simulation-based approximations of probabilities depends on how well the simulation represents the actual random phenomenon. Conducting a simulation can involve many assumptions which influence the results. Simulating many flips of a fair coin is one thing; simulating an entire NFL season and the winner of the Superbowl is an entirely different story.


```{example interpret-rel-freq}

In each of the following, write a clearly worded sentence interpreting the numerical value of the probability as a long run relative frequency in context.  (Just take the numerical values--- 0.1, 0.25, and 0.73 --- as given. We'll see how to compute probabilities like these later.)

1. The probability that a roll of a fair ten-sided die lands on 1 is 0.1.
1. The probability that two flips of a fair coin both land on H is 0.25.
1. The probability that in 100 flips of a fair coin the proportion of flips that land on H is between 0.45 and 0.55 is 0.73.

```


```{solution interpret-rel-freq-sol}
to Example \@ref(exm:interpret-rel-freq)
```

```{asis, fold.chunk = TRUE}

1.  About 10% of rolls of a fair ten-sided result in a roll of 1. The phenomenon is a roll of a far ten-sided die and the event of interest is whether the die lands on 1.
If we rolled a fair ten-sided die many, many times, we would expect the proportion of rolls that landed on 1 to be close to 0.1.
1. In about 25% of sets of two fair coin flips, both flips in the set land on H.   The phenomenon involves *two* flips of a coin, so we consider what would happen over many *sets* of two flips each.
1. In about 73% of sets of 100 fair coin flips, the proportion of H for the set is between 0.45 and 0.55.  The phenomenon involves 100 coin flips, so we consider many sets of 100 coin flips each, each set resulting in a proportion of H that is either between 0.45 and 0.55 or not.  Imagine adding many more paths to the plot on the right in Figure Figure \@ref(fig:coin-flips-plot2), each corresponding to a set of 100 flips, and seeing how many of the paths result in a value between 0.45 and 0.55 at flip 100.

```


### Subjective probability {#subjective-probability}

The long run relative frequency interpretation is natural in  repeatable situations like flipping coins, rolling dice, drawing Powerballs, or randomly selecting Cal Poly students.

On the other hand, it is difficult to conceptualize some scenarios in the long run.  Superbowl 2023 will only be played once, the 2024 U.S. Presidential Election will only be conducted once (we hope), and there was only one April 17, 2009 on which you either did or did not eat an apple.  But while these situations are not naturally repeatable they still involve randomness (uncertainty) and it is still reasonable to assign probabilities.  At this point in time we might think that the Kansas City Chiefs are more likely than the [Jacksonville Jaguars](https://tenor.com/0JBf.gif) to win Superbowl 2023 and that President Biden is more likely than Dwayne Johnson to win the U.S. 2024 Presidential Election. If you've always been an apple-a-day person, you might think there's a good chance you ate one on April 17, 2009.
It is still reasonable to assign probabilities to quantify such assessments even when an uncertain phenomenon is not repeated.

However, the *meaning* of probability does seem different in a physically repeatable situations like coin flips than in single occurrences like the 2023 Superbowl.  Let's switch sports and consider the 2022 World Series of Major League Baseball.  As of June 17, 2022,

- According to [FiveThirtyEight](https://projects.fivethirtyeight.com/2022-mlb-predictions/), the Los Angeles Dodgers have a 20% chance of winning the 2022 World Series, and the San Diego Padres have an 8% chance.
- According to [FanGraphs](https://www.fangraphs.com/standings/playoff-odds/fg/mlb), the Dodgers have a 12.4% chance of winning the 2022 World Series, and the Padres have a 9.9% chance.
- According to gambling site [Odds Shark](https://www.oddsshark.com/mlb/world-series-odds), the Dodgers have a 20% chance of winning the 2022 World Series, and the Padres have a 7.7% chance.


Each source, as well as many others, assigns different probabilities to the Dodgers or Padres winning. Which source, if any, is "correct"?

When the situation involves a fair coin flip, we could perform a simulation to see that the long run proportion of flips that land on H is 0.5, and so the probability that a fair coin flip lands on H is 0.5.  Even though the actual 2022 World Series will only happen once, we could still perform a simulation involving hypothetical repetitions. However, simulating the World Series involves first simulating the 2022 season to determine the playoff matchups, then simulating the playoffs to see which teams make the World Series, then simulating the World Series matchup itself.  And simulating the 2022 season involves simulating all the individual games. Even just simulating a single game involves many assumptions; differences in opinions with regards to these assumptions can lead to different probabilities.   For example, on June 17, according to [FiveThirtyEight](https://projects.fivethirtyeight.com/2022-mlb-predictions/dodgers/) the Dodgers had a 68% chance of beating the Cleveland Guardians in their game on June 17, but according to [FanGraphs](https://www.fangraphs.com/teams/dodgers/schedule) it was 66%.
Even if  the differences in probabilities between sources is small, many small differences over the course of the season could result in large differences in predictions for the World Series champion.

Unlike physically repeatable situations such as flipping a coin, there is no single set of "rules" for conducting a simulation of a season of baseball games or the World Series champion. Therefore, there is no single long run relative frequency that determines the probability.  Instead we consider *subjective probability*.

A **subjective (a.k.a. personal) probability** describes the degree of likelihood a given individual assigns to a certain event. As the name suggests, different individuals (or probabilistic models) might have different subjective probabilities for the same event.  In contrast, in the long run relative frequency interpretation the probability is agreed to be defined as the long run relative frequency, a single  number.

**Think of subjective probabilities as measuring *relative degrees of likelihood, uncertainty, or plausibility* ** rather than long run relative frequencies.  For example, in the FiveThirtyEight forecast, the Dodgers are about *2.5 times more likely* to win the World 2022 Series than the Padres ($2.5 = 20 / 8$).  Relative likelihoods can also be compared across different forecasts or scenarios. For example, FiveThirtyEight believes that the Dodgers are about 1.6 times more likely to win the World Series than FanGraphs does.  Also, FiveThirtyEight believes that the likelihood that a fair coin lands on H is about 2.5 times larger than the likelihood that the Dodgers win the 2022 World Series.

The [FiveThirtyEight MLB predictions](https://fivethirtyeight.com/features/how-our-mlb-predictions-work/) are the output of a probabilistic forecast. A **probabilistic forecast** combines observed data and statistical models to make predictions. Rather than providing a single prediction (such as "the Los Angeles Dodgers will win the 2022 World Series"), probabilistic forecasts provide a range of scenarios and their relative likelihoods.  Such forecasts are subjective in nature, relying upon the data used and assumptions of the model. Changing the data or assumptions can result in different forecasts and probabilities.  In particular, probabilistic forecasts are usually revised over time as more data becomes available.


Simulations can also be based on subjective probabilities.  If we were to conduct a simulation consistent with FiveThirtyEight's model (as of June 17), then in about 20.9% of repetitions the Dodgers would win the World Series, and in about 8% of repetitions the Padres would win.  Of course, different sets of subjective probabilities correspond to different assumptions and different ways of conducting the simulation.  

Subjective probabilities can be calibrated by weighing the relative favorability of different bets, as in the following example.


```{example subjective-bet}

What is your subjective probability that Professor Ross has a TikTok account? Consider the following two bets, and suppse you must choose only one^[We do not advocate gambling.  We merely use gambling contexts to motivate probability concepts.].

A)  You win $100 if Professor Ross has a TikTok account, and you win nothing otherwise.
A)  A box contains 40 green and 60 gold marbles that are otherwise identical.  The marbles are thoroughly mixed and one marble is selected at random. You win $100 if the selected marble is green, and you win nothing otherwise.

1. Which of the above bets would you prefer?  Or are you completely indifferent? What does this say about your subjective probability that Professor Ross has a Tik Tok account?
1. If you preferred bet B to bet A, consider bet C which has a similar setup to B but now there are 20 green and 80 gold marbles. Do you prefer bet A or bet C? What does this say about your subjective probability that Professor Ross has a Tik Tok account? 
1. If you preferred bet A to bet B, consider bet D which has a similar setup to B but now there are 60 green and 40 gold marbles. Do you prefer bet A or bet D? What does this say about your subjective probability that Professor Ross has a Tik Tok account?
1. Continue to consider different numbers of green and gold marbles.  Can you zero in on your subjective probability?
  
```


```{solution subjective-bet-sol}

to Example \@ref(exm:subjective-bet)

```

```{asis, fold.chunk = TRUE}

1. Since the two bets have the same payouts, you should prefer the one that gives you a greater chance of winning! If you choose bet B you have a 40% chance of winning.
    - If you prefer bet B to bet A, then your subjective probability that Professor Ross has a TikTok account is less than 40%.
    - If you prefer bet A to bet B, then your subjective probability that Professor Ross has a TikTok account is greater than 40%.
    - If you're indifferent between bets A and B, then your subjective probability that Professor Ross has a TikTok account is equal to 40%.  
1. If you choose bet C you have a 20% chance of winning.
    - If you prefer bet C to bet A, then your subjective probability that Professor Ross has a TikTok account is less than 20%.
    - If you prefer bet A to bet C, then your subjective probability that Professor Ross has a TikTok account is greater than 20%.
    - If you're indifferent between bets A and C, then your subjective probability that Professor Ross has a TikTok account is equal to 20%.  
1. If you choose bet D you have a 60% chance of winning.
    - If you prefer bet D to bet A, then your subjective probability that Professor Ross has a TikTok account is less than 60%.
    - If you prefer bet A to bet D, then your subjective probability that Professor Ross has a TikTok account is greater than 60%.
    - If you're indifferent between bets A and D, then your subjective probability that Professor Ross has a TikTok account is equal to 60%.  
1. Continuing in this way you can narrow down your subjective probability. For example, if you prefer bet B to bet A and bet A to bet C, your subjective probability is between 20% and 40%.  Then you  might consider bet E corresponding to 30 gold marbles and 70 green to determine if you subjective probability is greater than or less than 30%.  At some point it will be hard to choose, and you will be in the ballpark of your subjective probability.  (Think of it like going to the eye doctor: "which is better: 1 or 2?"  At some point you can't really see a difference.)

```

(ref:cap-subjective-bet) The three marble bins in Example \@ref(exm:subjective-bet). Left: Bet A, 40% chance of selecting green. Middle: Bet B, 20% chance of selecting green. Left: Bet C, 60% chance of selecting green.


```{r subjective-bet-fig, echo = FALSE, fig.cap = "(ref:cap-subjective-bet)", fig.show = "hold", out.width = "33%"}

library(waffle)


waffle(c(40, 60), rows = 10,
       legend_pos = "none",
       colors = c("#154734", "#BD8B13"),
       title = "40 green, 60 gold")

waffle(c(20, 80), rows = 10,
       legend_pos = "none",
       colors = c("#154734", "#BD8B13"),
       title = "20 green, 80 gold")

waffle(c(60, 40), rows = 10,
       legend_pos = "none",
       colors = c("#154734", "#BD8B13"),
       title = "60 green, 40 gold")

```

Of course, the strategy in the above example isn't an exact science, and there is a lot of behavioral psychology behind how people make choices in situations like this, especially when betting with real money.
But the example provides a very rough idea of how you might discern a subjective probability of an event.
The example also illustrates that probabilities can be "personal"; *your* information or assumptions will influence your assessment of the likelihood.

We close this section with some brief comments about subjectivity. Subjectivity is not bad; "subjective" is not a "dirty" word.
Any probability model involves some subjectivity, even when probabilities can be interpreted naturally as long run relative frequencies.
For example, assuming a die is fair does not codify an objective truth about the die.
Instead, "fairness" reflects a reasonable and tractable mathematical model.
In the real world, any "fair" six-sided die has small physical imperfections that cause the six faces to have different probabilities.
However, the differences are usually small enough to be ignored for most practical purposes.
Assuming that the probability that the die lands on each side is 1/6 is much more tractable than assuming the probability of a 1 is 0.1666666668, the probability of a 2 is 0.1666666665, etc.
(Furthermore, measuring the probability of each side so precisely would be extremely difficult.)
But assuming that the probability that the die lands on each side is 1/6 is also subjective.
We might agree more easily on the probability that a six-sided die lands on 1 than on the probability that the Dodgers win the 2021 World Series.
But the fact that there cam be many reasonable probability models for a situation like the 2021 World Series does not make the corresponding subjective probabilities any less valid than long run relative frequencies.

### Exercises



1. In each of the following, write a clearly worded sentence interpreting the numerical value of the probability as a long run relative frequency in context.  (Just take the numerical values as given for now. We'll see how to compute probabilities like these later.)  

    a. The probability of rolling doubles when you roll two fair six-sided dice is 1/6.
    a. The probability of rolling doubles on three consecutive rolls of two fair six-sided dice is 0.00463.
    a. The probability that the sum of 100 rolls of a fair six-sided die is less than 370 is 12%. 
    a. Roll a fair six-sided die until you roll a 6 three times and then stop.  The probability that you roll the die at least 10 times is 0.822.
    
1. Various sources post odds for who will win the 2024 U.S. Presidential Election.  As of July 28, 2021, the website [bonus.com](https://www.bonus.com/election/) lists the following probabilities.

    | Potential candidate | Probability of winning 2024 election |
    |---------------------|-------------------------------------:|
    | Joe Biden           |                                20.0% |
    | Kamala Harris       |                                16.7% |
    | Donald Trump        |                                12.5% |
    | Nikki Haley         |                                 7.7% |
    | Ron DeSantis        |                                 7.7% |

    a. According to bonus.com, how many times more likely is Joe Biden to win than Nikki Haley is to win?
    a. According to bonus.com, is the probability that Nikki Haley wins the Republican nomination greater than, less than, or equal to 7.7%?  Why?
    a. Another source list the probability for Kamala Harris as 22%.  How many times more likely is Kamala Harris to win according to this source relative to bonus.com? 
    a. Say it's October 2024.  How do you think the above table would change?  We obviously can't predict the future, but in general terms what would you expect a table like this to look like a month before the election?
    
1. Identify your subjective probability of each of the following (to the nearest 5% or 10% is fine).  Explain how you arrived at your value by considering bets like those in Example \@ref(exm:subjective-bet).  

    a. The probability that a Cal Poly team will ever win an NCAA Division I championship.
    a. The probability that you will eventually visit all 50 U.S. states at some time in your life.
    a. The probability that we live in a multiverse.
    a. Choose a situation of interest to you and identify your subjective probability!
    




## Working with probabilities {#consistency}


In the previous section we encountered two interpretations of probability: long run relative frequency and subjective.
We will use these interpretations interchangeably.
With subjective probabilities it is often helpful to consider what might happen in a simulation.
It is also useful to consider long run relative frequencies in terms of relative degrees of likelihood.
Fortunately, the mathematics of probability work the same way regardless of the interpretation.

### Consistency requirements

With either the long run relative frequency or subjective probability interpretation there are some basic logical consistency requirements which probabilities need to satisfy. Roughly, probabilities cannot be negative and the sum of probabilities over all possible outcomes must be 100%. We will formalize these requirements in mathematical formulas later.  For now, we just proceed using intuition.



```{example worldseries}

As of Jun 17, [FiveThirtyEight](https://projects.fivethirtyeight.com/2021-mlb-predictions/) listed the following probabilities for who will 
win the 2022 World Series.

```

| Team                | Probability |
|---------------------|------------:|
| Los Angeles Dodgers |         20% |
| New York Yankees    |         20% |
| Houston Astros      |          9% |
| San Diego Padres    |          8% |
| Other               |             |

According to FiveThirtyEight (as of June 17):

1. What would you expect the results of 10000 repetitions of a simulation of the World Series champion to look like?  Construct a table summarizing what you expect. Is this necessarily what would happen? 
1. What must be the probability that the Dodgers do *not* win the 2022 World Series?
1. What must be the probability that one of the above four teams is the World Series champion?
1. What must be the probability that a team other than the above four teams is the World Series champion?  That is, what value goes in the "Other" row in the table?

```{solution worldseries-sol}

to Example \@ref(exm:worldseries)

```

```{asis, fold.chunk = TRUE}


1. While these particular probabilities are subjective, imagining probabilities as relative frequencies often helps our intuition.  If we think of this as a simulation, each repetition results in a World Series champion and in the long run we would expect the Dodgers would be the champion in 20%, or 2000, of the 10000 repetitions.  We would expect the simulation results to look like

    | Team                | Repetitions as winner |
    |---------------------|----------------------:|
    | Los Angeles Dodgers |                  2000 |
    | New York Yankees    |                  2000 |
    | Houston Astros      |                   900 |
    | San Diego Padres    |                   800 |
    | Other               |                  4300 |
    | Total               |                 10000 |
  
    Of course, there would be some variability from simulation to simulation, just like in the sets of 1000 coin flips in Figure Figure \@ref(fig:coin-flips-plot3).  But the above counts represent about what we would expect.  

1. 80%. Either the Dodgers win or they don't; if there's a 20% chance that the Dodgers win, there must be a 80% chance that they do not win. If we think of this as a simulation with 10000 repetitions, each repetition results in either the Dodgers winning or not, so if they win in 2000 of repetitions then they must not win in the other 8000.
1. 57%. There is only one World Series champion, so if say the Dodgers win then no other team can win.  Thinking again of the simulation, the repetitions in which the Dodgers win are distinct from those in which the Astros win.  So if the Dodgers win in 2000 repetitions and the Astros win in 900 repetitions, then on a total of 2900 repetitions either the Dodgers or Astros win.  Adding the four probabilities, we see that the probability that one of the four teams above wins must be 57%.
1. 43%. Either one of the four teams above wins, or some other team wins.  If one of the four teams above wins in 5700 repetitions, then in 4300 repetitions the winner is not one of these four teams.

``` 


```{example worldseries-proportional}

Suppose your subjective probabilities for the 2022 World Series champion satisfy the following conditions.

- The White Sox and Brewers are equally likely to win
- The Astros are 1.5 times more likely than the White Sox to win
- The Dodgers are 2 times more likely than the Astros to win
- The winner is as likely to be among these four teams --- Dodgers, Astros, White Sox, Brewers --- as not


Construct a table of your subjective probabilities like the one in Example \@ref(exm:worldseries). 

```


```{solution worldseries-proportional-sol}

to Example \@ref(exm:worldseries-proportional)

```

```{asis, fold.chunk = TRUE}

Here, probabilities are specified indirectly via relative likelihoods.  We need to find probabilities that are in the given ratios and add up to 100%.  It helps to designate one outcome as the "baseline".  It doesn't matter which one; we'll choose the White Sox.

- Suppose the White Sox account for 1 "unit".  It doesn't really matter what a unit is, but let's say it corresponds to 1000 repetitions of the simulation.  That is, the White Sox win in 1000 repetitions.  Careful: we haven't yet specified how many total repetitions we have done, or how many units the entire simulation accounts for.  We're just starting with a baseline of what happens for the White Sox.
- The White Sox and Brewers are equally like to win, so the Brewers also account for 1 unit.
- The Astros are 1.5 times more likely than the White Sox to win, so the Astros account for 1.5 units.  If 1 unit is 1000 repetitions, then the Astros win in 1500 repetitions, 1.5 times more often than the White Sox.
- The Dodgers are 2 times more likely than the Astros to win, so the Dodgers account for $2\times 1.5=3$ units. If 1 unit is 1000 repetitions, then the Dodgers win in 3000 repetitions.
- The four teams account for a total of $1+1+1.5+3 = 6.5$ units. Since the winner is as likely to among these four teams as not, then "Other" also accounts for 6.5 units.
- In total, there are 13 units which account for 100% of the probability.  The White Sox account for 1 unit, so their probability of winning is $1/13$ or about 7.7%.  Likewise, the probability that the Dodgers win is $3/13$ or about 23.1%.


| Team                | Units | Repetitions | Probability |
|---------------------|------:|------------:|------------:|
| Los Angeles Dodgers |   3.0 |        3000 |       23.1% |
| Houston Astros      |   1.5 |        1500 |       11.5% |
| Chicago White Sox   |   1.0 |        1000 |        7.7% |
| Milwaukee Brewers   |   1.0 |        1000 |        7.7% |
| Other               |   6.5 |        6500 |       50.0% |
| Total               |  13.0 |       13000 |      100.0% |
  
You should verify that all of the probabilities are in the specified ratios.  For example, the Dodgers are 2 times more likely ($2 = 23.1 / 11.5$) than the Astros to win, and the Astros are 1.5 times more likely $(1.5 \approx 11.5 / 7.7)$ than the White Sox to win.

We could have also solved this problem using algebra.  Let $x$ be the probability, as a decimal, that the White Sox are the winner.  (Again, it doesn't matter which team is the baseline.) Then $x$ is also the probability that the Brewers are the winner, $1.5x$ for the Astros, and $3x$ for the Dodgers.  The probability that one of the four teams wins is $x + x + 1.5x + 3x = 6.5x$, so the probability of Other is also  $6.5x$.  The probabilities in decimal form must sum to 1 (that is, 100%), so $1 = x + x + 1.5x + 3x + 6.5x = 13x$.  Solve for $x=1/13$ and then plug in $x=1/13$ to find the other probabilities.


``` 


Example \@ref(exm:worldseries-proportional) illustrates one way of formulating probabilities.  We start by specifying probabilities in relative terms, and then "normalize" these probabilities so that they add up to 100% while maintaining the ratios. As in the example, it helps to consider one outcome as a "baseline" and to specify all likelihoods relative to the baseline. 

Figure Figure \@ref(fig:fig-worldseries-proportional) provides a visual representation of Example \@ref(exm:worldseries-proportional).
The ratios provided in the problem setup are enough to draw the shape of the plot, represented by the plot on the left without a scale on the vertical axis.
The heights are equal for the White Sox and the Brewers, the height for the Astros is 1.5 times higher, etc.
The plot on the right simply adds a probability axis to ensure the values add to 1.
The plot on the right represents the "normalization" step, but it does not affect the shape of the plot or the relative heights of the bars.

(ref:cap-worldseries-proportional) Bar chart representation of the subjective probabilities in Example \@ref(exm:worldseries-proportional). Left: Relative heights without absolute scale. Right: Heights scaled to sum to 1 to represent probabilities.




```{r fig-worldseries-proportional, echo = FALSE, fig.cap="(ref:cap-worldseries-proportional)", fig.show="hold", out.width="50%"}

df <- data.frame(team = c("Dodgers",
                          "Astros",
                          "White Sox",
                          "Brewers",
                          "Other"),
                 freq = c(3, 1.5, 1, 1, 6.5)) %>%
  mutate(team = fct_reorder(team, freq, .desc = TRUE),
         rel_freq = freq / sum(freq))

ggplot(df, aes(x = team, y = rel_freq)) +
  geom_col(color = "skyblue", fill = "skyblue") +
  theme_classic() +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(x = "Team")

ggplot(df, aes(x = team, y = rel_freq)) +
  geom_col(color = "skyblue", fill = "skyblue") +
  theme_classic() +
  labs(x = "Team",
       y = "Subjective Probability")

```






### Odds

The words "probability", "chance", "likelihood", and "odds" are colloquially treated as synonyms.  However, in the mathematical language of probability, *odds* provide a different way of reporting a probability.  Rather than reporting probability on a 0\% to 100\% scale, odds report probabilities in terms of ratios.  


```{example worldseries-odds}

In Example \@ref(exm:worldseries) the odds that the Astros win the World Series are about 10 to 1 against.

```


1. What do you think that "10 to 1 against" means?
1. What are the odds of the Astros *not* winning?
1. What are the odds of the Dodgers winning?
1. What are the odds of one of the Other teams winning?
1. The Philadelphia Phillies have 50 to 1 odds against winning.  What is the probability that the Phillies win the World Series?


```{solution worldseries-odds-sol}

to Example \@ref(exm:worldseries-odds)

```



```{asis, fold.chunk = TRUE}

1. The probability that the Astros win is 0.09, so the probability that they do not win is 0.91.  These numbers are in a 10 to 1 ratio: the probability of not winning (0.91) is about 10 ($10.1 \approx 0.91/0.09$) times greater than the probability of winning (0.09).  So the odds *against* the Astros winning the World Series are about 10 to 1; "against" because the Astros are less likely to win than to not win.
1. The probabilities are still in the 10 to 1 ratio, but we can say that the odds are 10 to 1 *in favor* of the Astros *not* winning.  We could also say the odds are 1 to 10 in favor of the Astros winning, but odds are typically reported with the larger value first --- 10 to 1 instead of 1 to 10.
1. The probability that the Dodgers win is 0.20 and that they don't win is 0.80, and $0.80/0.20 = 4$.  So the odds are 4 to 1 *against* the Dodgers winning; "against" because the Dodgers are less likely to win than to not win.
1. The probability that an Other team wins is 0.43 and that an Other team doesn't win is 0.57, and $0.57/0.43 \approx 1.33$.  So the odds are 1.33 to 1 against an Other team winning.   Odds are often reported as whole numbers, so we could say the odds are 13 to 10 against an other team winning.  
1. The probability that the Phillies do not win is 50 times greater than the probability that they do win.  Let the event that the Phillies win account for 1 "unit" so that the event that they do not win accounts for 50 units, for a total of 51 units.  So the probability that the Phillies win is $1/51\approx 0.02$. Note that the probability of not winning, 50/51, is 50 times greater than the probability of winning.

    You could also solve this with algebra.  Let $x$ be the probability that the Phillies win, so $50x$ is the probability that they don't win. The probabilities must sum to 1, so set $x + 50x = 1$ and solve for $x$.


```



The **odds** of an event is a ratio^[We focus on odds as a ratio of probabilities to illustrate relative likelihoods; these are called "fractional odds".  But odds can be reported in other ways.  In particular, "moneyline odds" (a.k.a., "American odds") are expressed  in terms of the net profit on a 100 dollar bet.  For example, in Example \@ref(exm:worldseries)  the moneyline odds for the Dodgers are +400.  This means that someone who bets 100 dollars on the Dodgers to win the World Series would win 500 dollars if the Dodgers actually win, for a net profit of +400 dollars after subtracting the initial stake of 100 dollars. The amounts 400 and 100 are in a 4 to 1 ratio, implying a probability of $1/(1+4) = 0.20$.] involving the probability that the
event occurs and the probability that the event does not occur.  Odds can be expressed as either "in favor" of or "against" the event occurring.

$$
\begin{aligned}
\text{odds in favor} & = \frac{\text{probability that the event occurs}}{\text{probability that the event does not occur}} \\
& \\
\text{odds against} & = \frac{\text{probability that the event does not occur}}{\text{probability that the event occurs}}\end{aligned}
$$

In some situations odds are typically reported as odds against.  While the odds of an event is a just a single number, odds are often reported as a ratio of whole numbers, e.g., 11 to 1, 7 to 2.
<!-- In Example \@ref(exm:worldseries-odds) the odds against the Dodgers winning the World Series are 3.5, which can be reported as 7 to 2 odds (against). -->

As discussed at the end of Section \@ref(subjective-probability) bets can be used to discern probabilities or odds.

```{example bet-EV}

Ron and Leslie agree to the following bet. They'll ask Professor Ross if he has a TikTok account. If he does, Leslie will pay
Ron $200; if not, Ron will pay Leslie $100.  (Neither has any prior information about whether or not Professor Ross has a TikTok account.)

1. Given this setup, which of the following is being judged as more likely: that Professor Ross has a TikTok account, or that he does not?  Why?
1. What are this bet's odds?
1. Ron and Leslie agree that this is a fair bet, and neither would accept worse odds. What is the subjective probability that Professor Ross has a TikTok account?
1. Suppose they were to hypothetically repeat this bet many times, say 3000 times.  Given the probability from the previous part, how many times would you expect Leslie to win? To lose? What would you expect Leslie's net dollar winnings to be?  In what sense is this bet "fair"?  (Remember: Leslie's winnings are Ron's losses and vice versa.)

```


<!-- 1. Leslie would not agree to the bet if her potential payout were less than $100 given her potential loss of $200. What can you say about Leslie's subjective probability that Professor Ross has a TikTok account? -->
<!-- 1. Ron would not agree to the bet if his potential payout were less than $200 given his potential loss of $100. What can you say about Ron's subjective probability that Professor Ross has a TikTok account? -->


```{solution bet-EV-sol}

to Example \@ref(exm:bet-EV)

```



```{asis, fold.chunk = TRUE}

1. The larger potential payout corresponds to the *less* likely event.  So Professor Ross is more likely to *not* have a TikTok account than to have one.
1. The payouts are in a 2 to 1 ratio, so the odds that Professor Ross has a TikTok account are 2 to 1 against.
1. The odds that Professor Ross has a TikTok account are 2 to 1 against, so Professor Ross is twice as likely to not have a TikTok account than to have one.  This corresponds to a subjective probability^[Technically, Ron and Leslie could still have different subjective probabilities.  Leslie would not agree to worse odds, but she would accept better if Ron offered them.  For example, given a potential loss of $200, Leslie would also agree to a potential payout from Ron of $125 rather than $100. That is, Leslie would accept odds of 1.6 to 1 against ($200/125 = 1.6$), corresponding to a subjective probability of 0.385 ($1/(1 + 1.6)$) .  So Leslie's subjective probability that Professor Ross has a TikTok account is *at least* 1/3.  Similarly, Ron's subjective probability that Professor Ross has a TikTok account is *at most* 1/3.] that Professor Ross has a TikTok account of 1/3 (and a probability that he does not have one of 2/3).
1. The probability that Leslie wins is 2/3, so you would expect her to win in 2000 of the 3000 repetitions.  She wins $100 each time she wins, so you would expect her to win a total of $200,000 on games she wins.  The probability that she loses is 1/3, so you would expect her to lose in 1000 of the 3000 repetions. She loses $200 each time, so you would expect her to lose a total of $200,000 on the games she loses.  So you would expect Leslie's net winnings to be 0, and likewise for Ron.  The bet is fair in the sense that neither party is expected to profit or lose in the long run.

| Winner | Number of repetitions | Leslie's winnings per repetition | Leslie's total winnings |
|--------|----------------------:|---------------------------------:|------------------------:|
| Leslie |                  2000 |                              100 |                 200,000 |
| Ron    |                  1000 |                             -200 |                -200,000 |
| Total  |                  3000 |                               NA |                       0 |

```


The previous example illustrates that the odds of a fair bet on whether or not an event will occur imply a
probability for the event.

\begin{align*}
\text{probability that event occurs} & = \frac{\text{odds in favor of the event}}{1+\text{odds in favor of the event}}\\
& \\
& = \frac{1}{1+\text{odds against the event}}
\end{align*}





### Why do we need consistency?

Regardless of the interpretation --- long run relative frequency or subjective --- probabilities must follow basic logical consistency requirements. If these requirements are mistakenly not satisfied, bad things can happen.  



```{example dutch}

Donny Don't thinks the Dodgers have a pretty good chance to win the World Series.  He thinks their only real competition is the Yankees.  The following are Donny's subjective probabilities for which team will win the World Series.

| Team                | Probability |
|---------------------|------------:|
| Los Angeles Dodgers |         50% |
| New York Yankees    |         25% |
| Other               |         10% |

```

1. What is wrong with Donny's probabilities?
1. What are Donny's odds that the Dodgers win? (Consider only Donny's probability that the Dodgers win^[We're assuming Donny's probability that the Dodgers don't win is 50%.  But if Donny's probabilities don't add to 100% why would we expect him to obey other consistency requirements?  A fair question, but the point is that bad things can happen even if just one of the consistency requirements is violated.].)
1. Would Donny agree to a bet where he pays you $100 if the Dodgers win but you pay him $100 if the Dodgers do not win?
1. What are Donny's odds that the Yankees win? Would Donny agree to a bet where he pays you $150 if the Yankees win but you pay him $50 if the Yankees do not win?
1. What are Donny's odds that a team other than the Dodgers or Yankees wins? Would Donny agree to a bet where he pays you $180 if an other team wins but you pay him $20 if the winner is either the Yankees or Dodgers?
1. Suppose you and Donny agree to make all of the bets in the three previous parts.  Consider your net profit for each of the potential outcomes (Dodgers win, Yankees win, other wins).  What do you notice?  Who would you rather be in this situation: you or Donny?





```{solution dutch-sol}

to Example \@ref(exm:dutch)

```



```{asis, fold.chunk = TRUE}

1. Donny's probabilities do not add up to 100%.
1. Donny's odds that the Dodgers win are $\frac{0.5}{0.5}=1$, or even odds.
1. Donny believes that the Dodgers are equally likely to win as to not win so, yes, he would agree to this bet with even payouts.
1. Donny's odds that the Yankees do not win are $\frac{0.75}{0.25}=3$, or 3 to 1 odds against the Yankees winning. Donny believes that the Yankees are 3 times more likely to not win than to win.  Since the payouts are in a 3 to 1 ratio with the larger payout corresponding to the Yankees winning (the less likely event), then Donny would agree to this bet.
1. Donny's odds that an other team does not win are $\frac{0.9}{0.1}=9$, or 9 to 1 odds against an other team winning. Donny believes that an other team is 9 times more likely to not win than to win.  Since the payouts are in a 9 to 1 ratio with the larger payout corresponding to an other team winning (the less likely event), then Donny would agree to this bet.
1. Given Donny's odds for each outcome, he would agree to each of these bets.

    - If the Dodgers win, you win the first bet but lose the other two, so your net profit is 100 - 50 - 20 = 30.
    - If the Yankees win, you win the second bet but lose the other two, so your net profit is 150 - 100 - 20 = 30
    - If an other team wins, you win the third bet but lose the other two, so your net profit is 180 - 100 - 50 = 30.
    
    Regardless of the outcome, you are guaranteed to earn a net profit of $30, and Donny is guaranteed to lose a net of $30.  That's free money for you with no risk, and pretty bad business on Donny's part.  



```

The previous problem contained an example of a "Dutch book". A **Dutch book**^["Book" in the sense of a bookie taking bets, as opposed to a Dutch-language novel like *De ontdekking van de hemel*.] is a set of probabilities and bets which guarantees a profit, regardless of the outcome of the gamble.  Probabilities that fail to satisfy logical consistency requirements allow for the possibility of Dutch books. The fact that no one should ever want to get caught in a Dutch book, like Donny was in the previous problem, is one justification of why even subjective probabilities should satisfy logical consistency requirements.

### Exercises


1. Various sources post odds for who will win the 2024 U.S. Presidential Election.  As of July 28, 2021, the website [bonus.com](https://www.bonus.com/election/) lists the following probabilities.

    | Potential candidate | Probability of winning 2024 election |
    |---------------------|-------------------------------------:|
    | Joe Biden           |                                20.0% |
    | Kamala Harris       |                                16.7% |
    | Donald Trump        |                                12.5% |
    | Nikki Haley         |                                 7.7% |
    | Ron DeSantis        |                                 7.7% |

    a. According to bonus.com, what is the probability that either Joe Biden or Kamala Harris wins the 2024 election?
    a. According to bonus.com, what is the probability that someone other than these five people wins the 2024 election?
    a. According to bonus.com, what are the odds that Joe Biden wins the 2024 election?
    a. Suppose that a source gives Dwayne Johnson 500 to 1 odds of winning.  What is the probability that Dwayne Johnson wins?
    
    
1. Suppose your subjective probabilities for who will win the 2024 U.S. Presidential Election satisfy the following.

    - Joe Biden is 5 times more likely to win than Kamala Harris, and no other Democratic candidate has a chance of winning
    - The Democratic candidate and the Republican candidate are equally likely to be the winner
    - Donald Trump is twice as likely to win as any other Republican candidate.
    
    Create a table of your subjective probabilities.
    
<!-- 1. Given odds find probability, and vice versa -->
<!-- 1. Dutch book -->

## Proportional reasoning and tables of counts

It is often helpful to think of probabilities as percentages or proportions.  Furthermore, when working with multiple percentages, it is also helpful to construct hypothetical tables of counts.

```{example free-college-twoway}

Are Americans in favor of free tuition at public colleges and universities? Suppose that^[These values are based on a study by the [Pew Research Foundation](https://www.pewresearch.org/fact-tank/2020/02/21/democrats-overwhelmingly-favor-free-college-tuition-while-republicans-are-divided-by-age-education/) conducted in January 2020.]

- 83% of Democrats are in favor of free tuition
- 60% of Independents are in favor of free tuition
- 39% of Republicans are in favor of free tuition

Also suppose that^[These values are based on surveys by [Gallup](https://news.gallup.com/poll/15370/party-affiliation.aspx), but the values change somewhat over time.]

- 32% of Americans are Democrats
- 42% of Americans are Independents
- 26% of Americans are Republicans

We'll use this information to investigate the following questions, as well as a few others.
  
- What percentage of Americans are in favor of free college tuition?
- What percentage of Americans who are in favor of free college tuition are Democrats?

  
  
```


1. Donny Don't says the answer to the question "what percentage of Americans who are in favor of free college tuition are Democrats" is 83%.  Explain why Donny is wrong without doing any calculations.
1. For the remaining parts, consider a hypothetical group of 10000 Americans and assume the percentages provided apply to this group. How many people in the group are Democrats?
1. How many Americans in the group are Democrats who are in favor of free college tuition?
1. Fill in the counts in each of the cells of the following table.

    |                              | Democrat | Independent | Republican | Total |
    |------------------------------|---------:|------------:|-----------:|------:|
    | In favor of free tuition     |          |             |            |       |
    | Not in favor of free tuition |          |             |            |       |
| Total                        |          |             |            | 10000 |

1. What percentage of Americans in this group who are in favor of free college tuition are Democrats?  (Answer with both an unreduced fraction and a percent.)
1. Suppose we had started with a hypothetical group of 100,000 Americans.  How would the table of counts change?  Would the answer to the previous part change?
1. Now answer the original question: What percentage of Americans who are in favor of free college tuition are Democrats?
1. What percentage of Americans who are Democrats are in favor of free college tuition?  (Answer with both an unreduced fraction and a percent.)
1. What percentage of Americans are Democrats in favor of free college tuition? (Answer with both an unreduced fraction and a percent.)
1. Compare the unreduced fractions for the previous three parts.  What is the same?  What is different?
1. What percentage of Americans are in favor of free college tuition? 
1. Suppose that we were only told that 61.9% of Americans overall support free tuition, and that we not given the values 83%, 60%, 39%.  Would we be able to complete the two-way table?  




```{solution free-college-twoway-sol}

to Example \@ref(exm:free-college-twoway)

```



```{asis, fold.chunk = TRUE}

1. Donny is confusing two different percentages, which refer to two different groups.  

    - 83% *of Democrats* are in favor of free college tuition.  This percentage applies to Democrats; *among Democrats* what percentage are in favor of free college tuition?
    - What we want is the percent of *Americans in favor of free tuition* who are Democrats.  This percentage applies to Americans in favor of free tuition; *among Americans in favor of free tuition* what percentage are Democrats?
  
1. Of the 10000 Americans, 32%, that is 3200, are Democrats. ($0.32 \times 10000 = 3200$)
1. Out of the 3200 Democrats, 83%, that is 2656 are in favor of free tuition.  ($3200 \times 0.83 = 2656$)
1. We fill in the total for each party first.  Then we use the percentages to determine the number who are in favor of free tuition within each party.  For example, 60% of the 4200 Independents are in favor of free tuition. ($4200 \times 0.6 = 2520$)  

    |                              | Democrat | Independent | Republican | Total |
|------------------------------|---------:|------------:|-----------:|------:|
    | In favor of free tuition     |     2656 |        2520 |       1014 |  6190 |
    | Not in favor of free tuition |      544 |        1680 |       1586 |  3810 |
    | Total                        |     3200 |        4200 |       2600 | 10000 |

1. Out of 6190 Americans in this group who are in favor of free college tuition, 2656 are Democrats.  Since $\frac{2656}{6190}\approx 0.43$, about 43% of Americans in this group who are in favor of free college tuition are Democrats.
1. If we had started with a hypothetical group of 100,000 Americans then the count in every cell in the table would be 10 times greater.  However, ratios and percentages would still be the same.  The answer to the previous part would not change; it would still be $\frac{26560}{61900} =\frac{2656}{6190}\approx 0.43$.
1. Now we are interested in Americans in general rather than the 10000 Americans in our hypothetical group.  But as the previous part illustrates, the relative percentages will be the same regardless of the size of the group.  So we can say that 43% of Americans who are in favor of free college tuition are Democrats.
1. We were provided the percentage of Americans who are Democrats that are in favor of free college tuition, 83%, or from the table, $\frac{2656}{3200}$.  Pay careful attention to the difference in wording between this part and the previous one.
1. Out of 10000 Americans, 2656 are Democrats in favor of free college tuition, so $\frac{2656}{10000}= 26.56\%$ of Americans are Democrats in favor of free college tuition.
1. There are subtle but important differences in wording between the percentages of interest in the previous three parts.  Note that the numerator is the same in each part: 2656, the number of Americans in the group who are both Democrats and in favor of free tuition.  But the *denominators* are different, each corresponding to a different reference group 
  
    - the percentage *of Americans who favor free tuition*... (denominator of 6190)
    - the percentage *of Americans who are Democrats*... (denominator of 3200)
    - the percentage *of Americans*... (denominator of 10000)  
  
1. Out of 10000 Americans, 6190 are in favor of free college tuition, so 61.9% of Americans are in favor of free college tuition.
1. Even if 61.9% of Americans overall support free tuition, it would not be safe to assume that 61.9% of Democrats support, 61.9% of Independent support, and 61.9% of Republicans support.  We would expect support to vary by party, but without such information we would not be able to complete the two-way table.

```

**Two-way tables** (a.k.a., contingency tables) of counts are a useful tool for probability problems dealing with two events. For the purposes of constructing the table and computing related probabilities, any value can be used for the hypothetical^[Careful: we are only claiming that the total does not matter when constructing hypothetical tables.  When collecting real data, the sample size matters a great deal.  For example, a random sample of 1000 Americans provides a more precise *estimate* of the population proportion of *all* Americans who support free tuition than a sample of 100 Americans does.  The Pew Research study was based on a sample of over 12000 Americans.] total count^[You can only run into problems if you round.  Suppose we had started with a group size of 100.  Then the top left cell in the table would have been 26.56.  If we had rounded this to 27, our answers would change.  So when dealing with a *hypothetical* table of counts, don't round.  If you are uncomfortable with decimal counts, just increase the size of your original group].

When dealing with percentages (or proportions or probabilities) be sure to ask "percent *of what*?" Thinking in fraction terms, be careful to identify the correct reference group which corresponds to the denominator.



```{example nba-conditional}

Which of the following is larger - 1 or 2?
  
1. The probability that a randomly selected man who is greater than six feet tall plays in the NBA.
1. The probability that a randomly selected man who plays in the NBA is greater than six feet tall.

```

```{solution, nba-conditional-sol}
to Example \@ref(exm:nba-conditional)
```

```{asis, fold.chunk = TRUE}

The probability in (2) is much larger.  Think in terms of fractions. The corresponding fractions would have the same numerator --- number of men who are both greater than six feet tall and play in the NBA --- but vastly different denominators. 

\begin{align*}
(1): & \quad \frac{\text{number of men who are greater than six feet tall and play in the NBA}}{\text{number of men who are greater than six feet tall}}\\
(2): & \quad \frac{\text{number of men who are greater than six feet tall and play in the NBA}}{\text{number of men who play in the NBA}} 
\end{align*}

1. There are over a billion men in the world who are greater than six feet tall, only a few hundred of whom play in the NBA.  The probability that a randomly selected man who is greater than six feet tall plays in the NBA is pretty close to 0.
1. There only a few hundred men who play in the NBA, almost all of whom are greater than six feet tall.  The probability that a randomly selected man who plays in the NBA is greater than six feet tall is pretty close to 1.

```




In Example \@ref(exm:free-college-twoway), we needed the information about support for free tuition *within in each party* to fill in the table.  That is, it was not enough to know that 61.9% of Americans overall support free tuition. In general, knowing probabilities of individual events alone is not enough to determine probabilities of combinations of them.  


```{example cats-dogs}

Suppose that 47% of American adults^[These values are based on the 2018 [General Social Survey](https://gss.norc.org/).] have a pet dog and 25% have a pet cat.

```

1. Donny Don't says that 72% (which is 47% + 25%) of American adults have a pet dog or a pet cat.  Is that necessarily true?  If not, is it even possible (in principle anyway) for this to be true?  Under what circumstance (however unrealistic) would this be true?  Construct a corresponding two-way table.
1. Given only the information provided, what is the smallest possible percentage of American who adults have a pet dog or a pet cat. Under what circumstance (however unrealistic) would this be true?  Construct a corresponding two-way table.
1. Donny Don't says that 11.75% (which is 47% $\times$ 25%) of Americans have both a pet dog *and* a pet cat. Explain to Donny why that's not necessarily true. Without further information, what can you say about the percent of American adults who have both a pet dog and a pet cat?
1. Suppose that 14% of American adults have both a pet dog *and* a pet cat.  What is the percentage of American adults who have a pet dog *or* a pet cat? Construct a corresponding two-way table.  Use your table to show Donny how to correct his error from part 1.
1. What percentage of American adults who have a pet dog also have a pet cat? Is it 25%?
1. What percentage of American adults who do not have a pet dog have a pet cat?  Is this the same value as in the previous part?


```{solution cats-dogs-sol}

to Example \@ref(exm:cats-dogs)


```



```{asis, fold.chunk = TRUE}

1. Donny's conclusion isn't necessarily true because some people have both a pet dog and a pet cat.  By adding 47% and 25%, Donny has  double-counted the people who have both a dog and a cat.  It’s theoretically possible that 72% have a pet dog or a pet cat, but this would only be true if absolutely no Americans have both a pet dog and a pet cat (which is obviously not realistic).  The two-way table corresponding to Donny's claim is  

    |          | Have dog | No dog | Total |
    |----------|---------:|-------:|------:|
    | Have cat |        0 |     25 |    25 |
    | No cat   |       47 |     28 |    75 |
    | Total    |       47 |     53 |   100 |

1. The situation in the previous part corresponds to the largest possible value, 72%, which occurs when the percentage who have both a dog and cat is as small as possible (0%). Now we consider the reverse situation.  The largest possible percentage who have both a dog and cat is 25%. Theoretically this is possible, but it would only occur if every person who has a cat also has a dog, which isn't realistic.  The two-way table would be


    |          | Have dog | No dog | Total |
    |----------|---------:|-------:|------:|
    | Have cat |       25 |      0 |    25 |
    | No cat   |       22 |     53 |    75 |
    | Total    |       47 |     53 |   100 |

    Thus the smallest possible percentage of American adults who have a pet dog or a pet cat is 47%.  

1. In the first two parts of this problem we have provided two theoretically possible (though unrealistic) scenarios of how Donny's claim would be false: if no Americans who have a pet dog have a pet cat, and if 100% of Americans who have a pet dog also have a pet cat. Donny's claim would be true if exactly 25% of American adults *who have a pet dog* also have a pet cat.  (Equivalently, his claim would be true if exactly 47% of American adults *who have a pet cat* also have a pet dog.) But all we are given so far is that 25% of American adults *in general* have a pet cat. The likelihood of having a pet cat might change based on whether or not the adult has a dog.  We would need more information about the relationship between pet dog and pet cat ownership before we could determine what percentage of American adults have both. Without further information, all we can say is that between 0% and 25% of Americans have both a pet dog and a pet cat.

1. If 14% of American adults have both a dog and a cat the two-way table is

    |          | Have dog | No dog | Total |
    |----------|---------:|-------:|------:|
    | Have cat |       14 |     11 |    25 |
    | No cat   |       33 |     42 |    75 |
    | Total    |       47 |     53 |   100 |

    Therefore 58% of American adults have a pet dog or a pet cat (58 = 14 + 11 + 33).  In other words, 42% of of American adults have neither a pet dog nor a pet cat.
    We can show Donny that adding 47% and 25% double counts the 14% who have both.  Donny should have subtracted 14% to correct for the double-counting: 58 = 47 + 25 - 14.  

1. Out of the 47 (hypothetical) adults who have a pet dog, 14 also have a pet cat, and $\frac{14}{47} = 0.298$. So 29.8% of American adults who have a pet dog also have a pet cat.  American adults who have a pet dog are a little more likely than American adults in general to have a pet cat.
1. Out of the 53 (hypothetical) people who do not have a pet dog, 11  have a pet cat, and $\frac{11}{53} = 0.208$. So 20.8% of American adults who do not have a pet dog  have a pet cat.  This is not the same value in the previous part.  People with pet dogs are more likely than people without pet dogs to have a pet cat.


``` 


```{example bayes-false-positive-twoway}

A woman's chances of giving birth to a child with Down syndrome increase
with age. The CDC estimates^[Source: <http://www.cdc.gov/ncbddd/birthdefects/downsyndrome/data.html>] that a woman in her mid-to-late 30s has a risk of conceiving a child with Down syndrome of about 1 in 250. A [nuchal translucency (NT) scan](https://www.webmd.com/baby/first-trimester-screening-nuchal-translucency-blood-test#1), which involves a blood draw from the mother and an ultrasound, is often performed around the 13th week of pregnancy to test for the presence of Down syndrome (among other things).
If the baby has Down syndrome, the probability that the test is positive is about 0.9.
However, when the baby does not have Down syndrome, there is still a probability that the test returns a (false) positive of about^[Estimates of these probabilities vary between different sources.
The values in the exercise were based on <https://www.ncbi.nlm.nih.gov/pubmed/17350315>] 0.05.
Suppose that the NT test for a pregnant woman in her mid-to-late 30s comes back positive for Down syndrome. What is the probability that the baby actually has Down syndrome?

```

1. Before proceeding, make a guess for the probability in question.
    $$
\text{0-20\%} \qquad \text{20-40\%} \qquad \text{40-60\%} \qquad \text{60-80\%} \qquad \text{80-100\%}
$$
1. Donny Don't says: 0.90 and 0.05 should add up to 1, so there must be a typo in the problem.  Do you agree?
1. Considering a hypothetical population of babies (of pregnant women in this demographic), express the probabilities as percents in context.
1. Construct a hypothetical two-way table of counts.
1. Use the table to find the probability in question.
1. The probability in the previous part might seem very low to you.  Explain why the probability is so low.
1. Compare the probability of having Down Syndrome before and after the positive test.  How much more likely is a baby who tests positive to have Down Syndrome than a baby for whom no information about the test is available?


```{solution, bayes-false-positive-twoway-sol}
to Example \@ref(exm:bayes-false-positive-twoway)
```

```{asis, fold.chunk = TRUE}

1. We don't know what you guessed, but from experience many people guess 80-100%.  Afterall, the test is correct for most of the babies who have Down Syndrome, and also correct for the most of the babies who do not have Down Syndrome, so it seems like the test is correct most of the time.  But this argument ignores one important piece of information that has a huge impact on the results: most babies do not have Down Syndrome.
1. No, these probabilities apply to different groups: 0.9 to babies with Down Syndrome, and 0.05 to babies without Down Syndrome.  Donny is using the complement rule incorrectly.  For example, if 0.9 is the probability that a baby with Down Syndrome tests positive, then 0.1 is the probability that a baby with Down Syndrome *does not test positive*; both probabilities apply to babies with Down Syndrome, and each baby with Down Syndrome either tests positive or not.
1. Considering a hypothetical population of babies (of pregnant women in this demographic):
    - 0.4% *of babies* have Down Syndrome
    - 90% *of babies with Down Syndrome* test positive
    - 5% *of babies without Down Syndrome* test positive
    - We want to find the percentage *of babies who test positive* that have Down Syndrome.  
1. Assuming 10000 babies (of pregnant women in this demographic)

    |                   | Has Down Syndrome | Does Not have Down Sydrome | Total |
    |-------------------|------------------:|---------------------------:|------:|
    | Tests positive    |                36 |                        498 |   534 |
    | Not test positive |                 4 |                       9462 |  9466 |
    | Total             |                40 |                       9960 | 10000 | 

1. Among the 534 babies who test positive, 36 have Down Syndrome, so the probability that a baby who tests positive has Down Syndrome is 36/534 = 0.067.
1. The result says that only 6.7% *of babies who test positive* actually have Down Syndrome.  It is true that the test is correct for most babies with Down Syndrome (36 out of 40) and incorrect only for a small proportion of babies without Down Syndrome (498 out of 9960).  But since so few babies have Down Syndrome, the sheer *number* of false positives (498) swamps the *number* of true positives (36).
1. Prior to observing the test result, the prior probability that a baby has Down Syndrome is 0.004.  The posterior probability that a baby has Down Syndrome given a positive test result is 0.067. A baby who tests positive  is about 17 times (0.067/0.004) more likely to have Down Syndrome than a baby for whom the test result is not known.  So while 0.067 is still small in absolute terms, the posterior probability is much larger relative to the prior probability.

```



Remember to ask "percentage *of what*"?
For example, the percentage of *babies who have Down syndrome* that test positive is a very different quantity than the percentage of *babies who test positive* that have Down syndrome.

Probabilities are often conditional on information.
Conditional probabilities (e.g., probability of Down Syndrome *given a positive test*) can be highly influenced by the original unconditional probabilities (e.g. probability of Down Syndrome), sometimes called the **base rates**.
Don't neglect the base rates when evaluating probabilities.

The example illustrates that when the base rate for a condition is very low and the test for the condition is less than perfect there will be a relatively high probability that a positive test is a *false positive.*

(ref:cap-DS-mosaic-twoway) Mosaic plots for Example \@ref(exm:bayes-false-positive-twoway). The plot on the left represents conditioning on Down Syndrome status, while the plot on the right represents conditioning on test result.

```{r DS-mosaic-twoway, echo=FALSE, fig.cap="(ref:cap-DS-mosaic-twoway)", out.width='40%', fig.show='hold'}

knitr::include_graphics(c("_graphics/DS-mosaic2.png", "_graphics/DS-mosaic.png"))

```


### Exercises

1. In each of the following, which is greater: (1) or (2)?
Or are they equal?
Or is there not enough information to decide?
  
    a. Surfing
        1. The probability that a randomly selected Californian likes to surf.
        1. The probability that a randomly selected American is a Californian who likes to surf
    a. Cal Poly alums
        1. The probability that a California resident is a Cal Poly alum.
        1. The probability that a Cal Poly alum is a California resident

1. Continuing Example \@ref(exm:cats-dogs)

    a. What percentage of American adults who have a pet cat also have a pet dog?
    a. What percentage of American adults who do not have a pet cat have a pet cat?
    a. Which of these percentages is the overall percentage of American adults who have a pet dog closer to?  Why do you think that is?
    
1. Continuing Example \@ref(exm:cats-dogs). Now suppose that 11.75% of American adults have both a pet cat and a pet dog (as Donny claimed was necessarily true).  Redo Example \@ref(exm:cats-dogs) and the previous exercise under this assumption.  What is true in this scenario that wasn't true in Example \@ref(exm:cats-dogs)?
    
1. Suppose that you have applied to two graduate schools, A and B.
Your subjective probability of being accepted is 0.6 for school A and 0.7 for school B.

    a. What is the largest possible probability of being accepted by both schools? Under what scenario (however unrealistic) would this be true? Explain.
    a. What is the smallest possible probability of being accepted by both schools? Under what scenario (however unrealistic) would this be true? Explain.
    a. Explain why the probability of being accepted by both schools is not necessarily 0.42.
    a. For the remaining parts, suppose your subjective probability of being accepted at both schools is 0.55. If you are accepted at school A, what is your probability of also being accepted at school B?
    a. If you are accepted at school A, what is your probability of not being accepted at school B?
    a. If you are not accepted at school A, what is your probability of being accepted at school B?
    a. If you are accepted at school B, what is your probability of also being accepted at school A?
    a. If you are not accepted at school B, what is your probability of being accepted at school A?



## Probability of what? {#probofwhat}

A probability takes a value in the sliding scale from 0 to 100%.  Throughout the book we will study how to compute probabilities in many situations.  But don't just focus on computation.  Always remember to properly interpret probabilities.  This section covers a few ideas to keep in mind when interpreting probabilities^[[Read this for a humorous take on interpreting probabilities](https://mathwithbaddrawings.com/2015/09/23/what-does-probability-mean-in-your-profession/).].  (We'll see later how to compute probabilities like those in the examples.)


```{example probability-interpret1}

In each of the following parts, which of the two probabilities, a or b, is larger, or are they equal?  You should answer conceptually without attempting any calculations.

1. Flip a coin *which is known to be fair* 10 times.  

    a. The probability that the results are, in order, HHHHHHHHHH.
    a. The probability that the results are, in order, HHTHTTTHHT.

1. Flip a coin which is known to be fair 10 times.  

    a. The probability that all 10 flips land on H.
    a. The probability that exactly 5 flips land on H.

```


```{solution probability-interpret1-sol}
to Example \@ref(exm:probability-interpret1)
```

```{asis, fold.chunk = TRUE}

1. Many people would say the probability in (b) is larger, but the probabilities in (a) and (b) are equal (and both equal to $\left(\frac{1}{2}\right)^{10} =\frac{1}{1024}$).  The sequence in (b) seems to look "more random". However, the probability of seeing that particular sequence --- H then H then T then H then T... --- is the same as seeing the sequence H then H then H then H then H...  If the coin is fair and the flips are independent, all possible sequences of flips are equally likely.  Think of it this way: choose any flip, say the third.  Then that flip is equally likely to be H (as in the third flip for (a)) or T (as in the third flip for (b)).  No matter which flip it is, or the results of the other flips, any flip is equally likely to be H or T.

    (Of course, the above response assumes that the coin is fair.  If the coin is known to be fair then the sequences in (a) and (b) are equally likely.  However, if we actually observed the sequence in (a) we might suspect that the coin is actually not fair.  There is an important difference between assumption and observation.)  

1. The probability in (b) is larger. Contrast this to the previous part.  There is only one sequence which results in 10 heads, HHHHHHHHHH.  However, there are many sequences which result in exactly 5 heads --- 252 out of 1024 possibilities in fact --- of which HHTHTTTHHT is just one possibility.

```

Pay close attention to the differences in the two parts in Example \@ref(exm:probability-interpret1).
The first part involves probabilities of the particular outcome sequence.
The second part involves more general "events" that the particular outcome sequence might satisfy.
The following provides another example of this "particular" versus "general" dichotomy.

```{example probability-interpret2}

In each of the following parts, which of the two probabilities, a or b, is larger, or are they equal?  You should answer conceptually without attempting any calculations.

1.  In the [Powerball lottery](https://www.powerball.com/) there are roughly^[The exact count is 292,201,338.  We will see how to compute this number later.] 300 million possible winning number combinations, all equally likely.

    a. The probability you win the next Powerball lottery if you purchase a single ticket, 4-8-15-16-42, plus the Powerball number, 23.
    a. The probability you win the next Powerball lottery if you purchase a single ticket, 1-2-3-4-5, plus the Powerball number, 6.

1. Continuing with the Powerball

    a. The probability that the numbers in the winning number are in a row.
    a. The probability that the numbers in the winning number are not in a row.

```


```{solution probability-interpret2-sol}
to Example \@ref(exm:probability-interpret2)
```

```{asis, fold.chunk = TRUE}

1. Many people would say the probability in (a) is larger, since the sequence in (a) looks "more random", but the probabilities in (a) and (b) are equal.  Since the outcomes are equally likely, the probability that any single sequence is the winning number is (roughly) 1/300,000,000.
(If you don't believe this, ask yourself: Why would the Powerball conduct its drawing in such a way that some numbers are more likely to be winners than others?
And if some numbers were more likely than others, why wouldn't people know about this?)
1. The probability in (b) is larger. Contrast this to the previous part.  There are only a handful of winning numbers for which the numbers are in a row: 1 through 6, 2 through 7, 3 through 8, etc. However, almost all of the 300 million possibilities do not have numbers in a row.

```


When interpreting probabilities, be careful not to confuse "the particular" with "the general".

**"The particular:"** A very specific event, surprising or not, often has low probability.

- For a fair coin, observing the particular sequence HHTHTTTHHT in 10 flips is just as likely as observing HHHHHHHHHH.
- The probability that the winning powerball number is 4-8-15-16-42-(23) is exactly the same as the probability that the winning powerball number is 1-2-3-4-5-(6).  
- The probability that you get a text from your best friend at 7:43pm on Oct 12, 2021 inviting you to dinner after you've just ordered pizza from your favorite pizza place is probably pretty small.  None of these items --- getting a text, having a friend invite you to dinner, ordering pizza from your favorite pizza place --- is unusual, but the chances of them all combining in this way at this particular time are fairly small. 


**"The general:"** While a very specific event often has low probability, if there are many like events their combined probability can be high.

- There are many possible sequences of 10 coin flips which result in 5 heads.
- For almost all of the possible Poweball combinations the numbers are not in order.
- The probability that some time in the next month or so a friend invites you for dinner is probably fairly high.









```{example probability-interpret3}

Consider the following two probabilities.

1. The probability that you win the next Powerball lottery if you purchase a single ticket.
1. The probability that someone wins the next Powerball lottery.  (FYI: especially when the jackpot is large, there are hundreds of millions of tickets sold.)

Which of these two probabilities is larger, or are they about that same?  You should answer conceptually without attempting any calculations.

```


```{solution probability-interpret3-sol}
to Example \@ref(exm:probability-interpret3)
```

```{asis, fold.chunk = TRUE}

The probability in (2) is *much* larger. (This is an understatement.)

- The probability that a specific powerball ticket is the winning number is about 1 in 300 million.  So if you buy a single ticket, it is extremely unlikely that *you* will win.
- However, if hundreds of millions of powerball tickets are sold, the probability that *someone somewhere* wins is pretty high.

We elaborate on these ideas below.

```

The probability that you win the next Powerball lottery if you purchase a single ticket is about 1 in 300 million.  Let's put this number in perspective.
There are about 260 million adults (over age 18) in the U.S.^[Source: [U.S. Census Bureau](https://www.census.gov/data/tables/2020/demo/popest/2020-demographic-analysis-tables.html).] Suppose that the name of every adult in the U.S. is written on a 3x5 index card.  These 260 million cards stacked would stretch about 62 miles high; that's commonly referenced as the [distance from the earth to where space begins](https://astronomy.com/news/2021/03/the-krmn-line-where-does-space-begin). The stack would also weigh about 400 tons, about as much 4 blue whales. Suppose we shuffle the cards (easier said than done) and select one.  The probability that your name is on the selected card is about 1 in 260 million. The chances that your next Powerball ticket is the winning number are a little less likely than this^[The statistician [Ron Wasserstein](https://twitter.com/ron_wasserstein?lang=en) has provided [several](https://www.huffpost.com/entry/chances-of-winning-powerball-lottery_b_3288129) [fanciful](https://www.huffpost.com/entry/if-winning-the-powerball-_b_8961606) [perspectives](https://www.npr.org/2016/01/12/462754290/powerball-you-cant-win-if-you-dont-play) on the likelihood of winning the Powerball lottery.].

However, if hundreds of millions of Powerball tickets are sold, the probability that *someone somewhere* wins is pretty high.  For example, if 500 million tickets are sold then there is a roughly 80% chance that at least one ticket has the winning number (under [certain assumptions](https://fivethirtyeight.com/features/new-powerball-odds-could-give-america-its-first-billion-dollar-jackpot/)).

**Even if an event has extremely small probability, given enough
repetitions of the random phenomenon, the probability that the event occurs
on *at least one* of the repetitions is often high**^[For an interesting investigation of this idea check out the [Infinite Monkey Theorem Experiment](https://pudding.cool/2020/04/infinite/) at the site [The Pudding](https://pudding.cool/).].

Consider the headline of this news article from 2010: ["Man mauled by bear after lightning strike"](https://www.upi.com/Odd_News/2010/06/24/Man-mauled-by-bear-after-lightning-strike/22821277399823/). We certainly feel sorry for this poor man, but just how unlikely is such an occurrence? Let's look a little closer.

The headline seems to imply that the man got struck by lightning and then, while he was trying to reach safety, a bear attacked. But the mauling occurred *four years after* the lightning strike. Getting mauled by a bear and struck by lightning within one's lifetime is certainly much more likely than both happening on the same day.

"Getting struck by lightning" is often colloquially used to describe a rare event, but how unlikely is it? One [study estimates that about 250,000 people in the world are struck by lightning each year](https://www.vaisala.com/sites/default/files/documents/Annual_rates_of_lightning_fatalities_by_country.pdf), and the [National Weather Service](https://www.weather.gov/safety/lightning-odds) estimates that the probability that you get struck by lightning within your lifetime is 1/15,000.  Still not very likely, but maybe not as rare as you might think.

Getting mauled by a bear is much mless likely than being struck by lightning. There are only [about 40 bear attacks of humans each year](https://www.nature.com/articles/s41598-019-44341-w). However, if the headline had been "Man bitten by shark after lightning strike" or "Man attacked by mountain lion after lightning strike" or "Man trampled by moose after lightning strike" it probably would have been equally newsworthy.  Thus we should account for all similar animal attacks, not just bear attacks, when assessing the likelihood.

The probability that you get struck by lightning and mauled by a bear today is certainly very small.  But the probability that someone somewhere within their lifetime gets both struck by lightning and attacked by an animal is orders of magnitude higher. In general, even though the probability that something very specific happens to you today is often extremely small, the probability that something similar happens to someone some time is often quite high.  


When assessing a probability, always ask "probability of what"?  Does the probability represent "the particular" or "the general"? Is it the probability that the event happens in a single occurrence of the random phenomenon, or the probability that the event happens at least once in many occurrences?  Keep these questions in mind when assessing numerical probabilities.  Remember that something that has a "one in a million chance" of happening to you today will happen to about 7000 people in the world every day.





### Exercises

1. Create your own analogy for how unlikely that a single ticket wins the Powerball lottery.  How would you describe a 1 in 300 million chance?

1. In each of the following, which is greater: (1) or (2)?
Or are they equal?
Or is there not enough information to decide?
  
    a. Election interference
        1. The probability that Russian agents successfully interfere with the 2024 U.S. Presidential election through posts on Facebook with the goal of helping the Republican candidate get elected.
        1. The probability that non-U.S. actors attempt to interfere with the 2024 U.S Presidential election.
    a. Roll a six-sided die which is known to be fair 10 times.
        1. The probability that the results are, in order, 1223334444.
        1. The probability that the results are, in order, 4614253226.
    a. Roll a six-sided die which is known to be fair 10 times.
        1. The probability that the results are, in order, 1234561234.
        1. The probability that you roll each of the six faces at least once.








## Approximating probabilities - a brief introduction to simulation {#sim}

Here's a seemingly simple problem.  Flip a fair coin four times and record the results in order. For the recorded sequence, compute *the proportion of the flips which immediately follow a H that result in H*.  What value do you expect for this proportion? (If there are no flips which immediately follow a H, i.e. the outcome is either TTTT or TTTH, discard the sequence and try again with four more flips.)


For example, the sequence HHTT means the the first and second flips are heads and the third and fourth flips are tails.  For this sequence there are two flips which immediately followed heads, the second and the third, of which one (the second) was heads.  So the proportion in question for this sequence is 1/2.  

So what value do you expect for this proportion? We think it's safe to say that most people would answer 1/2.  After all, it shouldn't matter if a flip follows heads or not, right?  We would expect half of the flips to land on heads regardless of whether the flip follows H, right?  We'll see there are some subtleties lurking behind these questions.

To get an idea of what we would expect for this proportion, we could conduct a simulation: flip a coin 4 times and see what happens.  Table Table \@ref(tab:mscoin-intro) displays the results of a few repetitions; each repetition consists of an ordered sequence of 4 coin flips for which the proportion in question is measured.  (**Flips which immediately follow H are in bold.**)

Table: (\#tab:mscoin-intro) Simulated outcomes for 10 sets of four flips of a fair coin, each set with at least one flip following a flip of H. 

| Repetition |  Outcome | Flips that follow H | H that follow H | Proportion of H following H |
|-----------:|---------:|:--------------------|:----------------|----------------------------:|
|          1 | H**HT**T | 2                   | 1               |                         0.5 |
|          2 | H**T**TH | 1                   | 0               |                           0 |
|  discarded |     TTTH | 0                   | NA              |                   try again |
|          3 | H**T**H**T** | 2                   | 0               |                           0 |
|          4 | TH**HH** | 2                   | 2               |                           1 |
|          5 | H**HT**T | 2                   | 1               |                         0.5 |
|          6 | H**HHT** | 3                   | 2               |                       0.667 |
|          7 | H**T**TH | 1                   | 0               |                           0 |
|          8 | TH**HT** | 2                   | 1               |                         0.5 |
|          9 | TH**T**T | 1                   | 0               |                           0 |
|         10 | H**HHH** | 3                   | 3               |                           1 |


The table and plot below summarize the results of these 10 repetitions of the simulation.


```{r ms-sim-10, echo=FALSE, warning=FALSE, message=FALSE, fig.show="hold"}

x = c(0, 0.5, 2/3, 1)
p = c(4, 3, 1, 2)

knitr::kable(
  data.frame(x, p, p / sum(p)),
  col.names = c("Proportion of H following H", "Frequency", "Relative frequency"),
  booktabs = TRUE,
  digits = 4
)


stripchart(rep(x, p), method = "stack", pch = 19, offset = .5, at = .15)

```


We can keep repeating the above process to investigate what happens in the long run.  Rather than actually flipping coins, we use a computer to run a simulation.  The table and plot below summarize the results of 1,000,000 successful repetitions of the simulation, after discarding the sequences with no flips following H.  (We will see how to program and run simulations in later chapters.) While you can't see the individual "dots" like in the above plot, each dot would represent a sequence of 4 coin flips (with at least one flip following a H) and the value being plotted is the proportion of H following H for that sequence.  The results would look like those in Table Table \@ref(tab:mscoin-intro), albeit a table with 1,000,000 rows (after discarding rows with no flips immediately following H.)


(ref:cap-mscoin-intro) Proportion of flips immediately following Heads that result in Heads for 1,000,000 sets of 4 coin flips.  (Each set has at least one flip immediately following H.) For example, the proportion of H following H is 0 in 429,123 of the sets.



```{r ms-coin-intro-plot, echo=FALSE, fig.cap="(ref:cap-mscoin-intro)", out.width='50%', fig.show='hold'}

knitr::include_graphics(c("_graphics/mscoin-intro-table.png", "_graphics/mscoin-intro-plot.png"))

```




We asked the question: *what would you expect* for the proportion of the flips which immediately follow a H that result in H?  That depends on how we define what's "expected".  If we are interested in the value that is most likely to occur when we flip a coin four times, then the answer is 0: we see that in the long run a little over 40\% of the sets resulted in a proportion of 0, while only about 30\% of sets resulted in a value of 1/2.  We see that the plot is not centered at 1/2; a higher percentage of repetitions resulted in a proportion below 1/2 than above 1/2.  We think that most people would find this surprising. 

Another way to interpret "expected" is as "average". Just as probability can be interpreted as long run relative frequency, there is a concept called *expected value* which can be interpreted  as the *long run average value*. (We will investigate expected value in more detail in later chapters.) After 1,000,000 repetitions, each involving a set of four fair coin flips, we have 1,000,000 simulated values of the proportion of H following H.  We could then average these values: add up all the values and divide by 1,000,000.  It turns out that average value is 0.405, which is not 1/2. Again, we think most people find this surprising.

A quick note: the term "expected value" is somewhat of a misnomer.  We are *not* saying that if we flip a coin four times we would expect the proportion of H following H for that set of flips to be 0.405.  In fact, the simulation shows that on any single set of four fair coin flips, the only possible values for the proportion of H following H are 0, 1/2, 2/3, and 1.  So in a set of four coin flips it's not possible to see a proportion of 0.405.  Rather, 0.405 is the *average value of the proportion of H following H that we would expect to see in the long run over many sets of four fair coin flips*.  We will return to this idea later. 

We will return to this example several times throughout the book to investigate these results more closely.   For now, just observe that

- The study of probability can involve some subtleties and our intuition isn't always right.
- Simulation is an effective way of investigating probability problems, and can reveal interesting and surprising patterns.
- There is a difference between (1) the probability that a flip following H lands on H and (2) the proportion of flips following H which follow H in a fixed sequence of coin flips.



<!-- ## Common misinterpretation and fallacies (e.g. outbreak of Asian disease, Utts book) -->

<!-- Sally Clark? -->

<!-- Allais paradox? -->

<!-- A famous study^[Source: <https://www.ncbi.nlm.nih.gov/pubmed/7455683>] by Kahneman and Tversky presented a group of people -->
<!-- with the following scenario.\ -->
<!-- \ -->
<!-- "Imagine that the U.S. is preparing for the outbreak of an unusual Asian -->
<!-- disease, which is expected to kill 600 people. Two alternative programs -->
<!-- to combat the disease have been proposed. Assume that the exact -->
<!-- scientific estimate of the consequences of the programs are as follows: -->

<!-- If Program A is adopted, 200 people will be saved. -->

<!-- If Program B is adopted, there is 1/3 probability that 600 people will -->
<!-- be saved, and 2/3 probability that no people will be saved. -->

<!-- Which of the two programs would you favor?"\ -->

<!-- Which of these two options, A or B, would you choose? Of the 152 -->
<!-- participants, a large majority (72%) favored one of the options; which -->
<!-- one do you think it was? -->

<!-- A second group was presented with the same set up, but the following -->
<!-- options instead of A/B.\ -->

<!-- If Program C is adopted 400 people will die. -->

<!-- If Program D is adopted there is 1/3 probability that nobody will die, -->
<!-- and 2/3 probability that 600 people will die.\ -->

<!-- Which of these two options, C or D, would you choose? Of the 155 -->
<!-- participants, a large majority (78%) favored one of the options; which -->
<!-- one do you think it was? -->

<!-- Compute the expected number of people who die and who are saved with -->
<!-- Program D. -->

<!-- Compute the expected number of people who die and who are saved with -->
<!-- Program B. -->

<!-- Compare options A and C. Are these the same? How about B and D? Do the -->
<!-- risk preferences depend on the wording of how the information is -->
<!-- presented? -->

<!-- Many studies have shown that human intuition does not generally deal -->
<!-- well with issues of uncertainty. -->

<!-- So it's worthwhile to take a careful study -->



<!-- ```{example, monty-hall, name='Monty Hall problem'} -->
<!-- MOnty Hall in CHpater 1??? -->
<!-- ``` -->




## Why study coins, dice, cards, and spinners?


Many probability problems involve “toy” situations like flipping coins, rolling dice, shuffling cards, or spinning spinners.  These situations might seem unexciting, or at least not very practically meaningful.  However, coins and spinners and the like provide familiar, concrete situations which facilitate understanding of probability concepts.  Furthermore, simple situations often provide insight into real and complex problems. The following is just one illustration.

Many basketball players and fans alike believe in the "hot hand"
phenomenon: the idea that making several shots in a row increases a
player's chances of making the next shot. However, the consensus
conclusion of thirty years of studies on the hot hand, beginning with
the seminal study @GVT, had been that there is
no statistical evidence that the hot hand in basketball is real. As a
result, many statisticians regularly caution against the "hot hand
fallacy": the belief that the hot hand exists when, in reality, the
degree of streaky behavior typically observed in sequential data is
consistent with what would be expected simply by chance in independent
trials.

The idea behind studies like @GVT is essentially the
following. Consider a player who attempts 100 shots and makes 50%. If
there is no hot hand, then we might expect the player to make 50% of
shots both on attempts that follow hit streaks --- usually considered
three (or more) made attempts in a row --- and on other attempts.
Therefore, a success rate of 50% on both sets of attempts provides no
evidence of the hot hand.

However, recent research of @MStruth, @MSthree, @MScold concludes that previous studies on the hot hand in basketball,
starting with @GVT, have been subject to a bias. After
correcting for the bias, the authors find strong evidence in favor of
the hot hand effect in basketball shooting, suggesting the hot hand
fallacy is not a fallacy after all. One interesting aspect of these
studies is that Miller and Sanjurjo's methods are simulation-based.

@MStruth introduced the coin flipping problem in Section \@ref(sim) to illustrate the idea behind their research and the
bias in previous studies. Consider again a player who attempts 100 shots
and makes 50%. Even if there is no hot hand, Miller and Sanjurjo show that we would actually expect the player to have a shooting percentage of *strictly less than* 50% on the attempts which followed streaks, and strictly greater than 50% on the other attempts.  The reason is the same as for the coin flipping problem in Section \@ref(sim): in a fixed number of trials, the proportion of H on trials following H is expected to be less than the true probability of H, even though the trials are independent.  Therefore, for the example player a success rate of 50% on both sets of attempts actually provides directional evidence in favor of the hot hand.  Properly acccounting for this bias leads to substantially different statistical analyses (i.e., p-values) and conclusions.

<!-- ## A few recurring examples -->

<!-- Add references/links to throughout text when book is finished. -->

<!-- ```{example dice-intro} -->
<!-- Roll a four-sided die^[Why four-sided?  Simply to make the number of possibilities a little more manageable (e.g., for in-class simulation activities).  Rolling a four-sided die twice yields 16 possible pairs, while rolling a six-sided die yields 36 possible pairs.] twice. What can we say about the sum of the two rolls?  The larger of the two rolls? This is an admittedly uninteresting example, but we will use this simple example to introduce many of the ideas in a relatively straightforward setting. -->
<!-- ``` -->


<!-- ```{example matching-intro, name='Matching problem'} -->

<!-- The "matching problem" is one well known probability problem.  The following version is from [FiveThirtyEight](https://fivethirtyeight.com/features/everythings-mixed-up-can-you-sort-it-all-out/). -->

<!-- A geology museum in California has $n$ different rocks sitting in a row on a shelf, with labels on the shelf telling what type of rock each is. An earthquake hits and the rocks all fall off the shelf and get mixed up. A janitor comes in and, wanting to clean the floor, puts the rocks back on the shelf in random order.  We might be interested in things like the probability that at least one rock is put back in the correct spot, or the expected number of rocks put back in the correct spot.  We might also be interested in how these quantities depend on $n$. -->

<!-- ``` -->



<!-- ```{example collector-intro, name='Collector problem'} -->

<!-- The "collector problem" is one well known probability problem.  Here is one version of it. -->

<!-- The latest series of collectible Lego Minifigures contains 12 different Minifigures.  Each package contains a single unknown Minifigure.  We buy packages one at a time until we have a complete collection. We might be interested in things like how many packages we needed to buy to complete the collection, or which Minifigure we have the most of. In particular, we might be interest in how how many packages we would expect to buy until we complete a set. -->

<!-- ``` -->


<!-- ## Preview of Probability Problems -->

<!-- The "matching problem" is one well known probability problem.  The following version is from [FiveThirtyEight](https://fivethirtyeight.com/features/everythings-mixed-up-can-you-sort-it-all-out/). -->

<!-- A geology museum in California has four different rocks sitting in a row on a shelf, with labels on the shelf telling what type of rock each is. An earthquake hits and the rocks all fall off the shelf and get mixed up. A janitor comes in and, wanting to clean the floor, puts the rocks back on the shelf in random order.  We might be interested in things like whether all the rocks are put back in the correct spot, or none are, or if the heaviest rock is put back in the correct spot. -->


<!-- The "collector problem" is one well known probability problem.  Here is one version of it. -->

<!-- The latest series of collectible Lego Minifigures contains 3 different Minifigures.  Each package contains a single unknown Minifigure.  We buy packages one at a time. We might be interested in things like how many packages we need to buy to complete the collection, or how many packages we need to buy to complete  5 collections (say one collection for each of 5 kids), or which Minifigure we have the most of. -->

<!-- The "Meeting problem" -->

<!-- Regina and Cady plan to meet for lunch between noon and 1 but they are not sure of their arrival times.  We might be interested in questions involving whether they arrive within 15 minutes of one another, who arrives first, or how long the first person to arrive needs to wait for the second.   -->