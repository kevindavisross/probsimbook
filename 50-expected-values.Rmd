# Expected Values {#EV}

<!-- \newcommand{\IP}{\textrm{P}} -->
<!-- \newcommand{\IQ}{\textrm{Q}} -->
<!-- \newcommand{\E}{\textrm{E}} -->
<!-- \newcommand{\Var}{\textrm{Var}} -->
<!-- \newcommand{\SD}{\textrm{SD}} -->
<!-- \newcommand{\Cov}{\textrm{Cov}} -->
<!-- \newcommand{\Corr}{\textrm{Corr}} -->
<!-- \newcommand{\Xbar}{\bar{X}} -->
<!-- \newcommand{\Ybar}{\bar{X}} -->
<!-- \newcommand{\xbar}{\bar{x}} -->
<!-- \newcommand{\ybar}{\bar{y}} -->
<!-- \newcommand{\ind}{\textrm{I}} -->
<!-- \newcommand{\dd}{\text{DDWDDD}} -->
<!-- \newcommand{\ep}{\epsilon} -->
<!-- \newcommand{\reals}{\mathbb{R}} -->


The distribution of a random variable specifies the possible values and the probability of any event that involves the random variable.  The distribution of a random variable contains all the information about its long run behavior. It is also useful to summarize some key features of a distribution. 

Chapter \@ref(simulation) introduced  how simulation can be used to approximate the **long run average value** of a random variable.  We also saw how variance and standard deviation can be used to summarize the overall degree of variability of a random variable by measuring, roughly, the long run average distance from the mean.  We saw a brief introduction to correlation, a number which measures the degree of the relationship between two jointly distributed random variables.  Correlation is also based on certain long run averages.

In this chapter we will see how characteristics based on long run averages can be defined as "expected" values.  We will see some properties and some strategies for computing expected values. We will also discuss how to interpret expected values, where we'll see that the "expected" in expected value is, unfortunately, a misnomer (hence the quotes).




## "Expected" value



```{example, matching-ev}

Recall the matching problem with $n=4$: objects labeled 1, 2, 3, 4, are placed at random in spots labeled 1, 2, 3, 4, with spot 1 the correct spot for object 1, etc.
Let the random variable $X$ count the number of objects that are put back in the correct spot.
Let $\IP$ denote the probability measure corresponding to the assumption that the objects are equally likely to be placed in any spot, so that the 24 possible placements are equally.

In \@ref(exm:matching-probspace) we determined the distribution of $X$, displayed in Table \@ref(tab:matching-distribution-table) below.

```

(ref:matching-distribution-table-cap) The distribution of the number of matches ($X$) in the matching problem in Example \@ref(exm:matching-ev).

```{r, matching-distribution-table, echo = FALSE}

kbl(
  data.frame(c(0, 1, 2, 4), round(c(9, 8, 6, 1) / 24, 4)),
  booktabs = TRUE,
  col.names = c("x", "P(X=x)"),
  caption = '(ref:matching-distribution-table-cap)'
) %>%
  kable_styling(fixed_thead = TRUE)

```




1. Describe two ways for simulating values of $X$.
1. The table below displays 10 simulated values of $X$.  How could you use the results of this simulation to approximate the long run average value of $X$? How could you get a better approximation of the long run average?
    ```{r, matching-sim-10-ev, echo = FALSE}


    kbl(
      data.frame(1:10, c(0, 1, 0, 0, 2, 0, 1, 1, 4, 2)),
      booktabs = TRUE,
      col.names = c("Repetition", "Y"),
      caption = "Results of the number of matches ($X$) in 10 repetitions of the matching problem."
    )  %>%
      kable_styling(fixed_thead = TRUE)

    ```
1. Rather than adding the 10 values and dividing by 10, how could you simplify the calculation in the previous part?
1. The table below summarizes 24000 simulated values of $X$.  Approximate the long run average value of $X$.
    ```{r, matching-sim-ev, echo = FALSE}

    kbl(
      data.frame(c(0, 1, 2, 4), c(8979, 7993, 6068, 960)),
      booktabs = TRUE,
      col.names = c("Value of X", "Number of repetitions"),
      caption = "Results of the number of matches ($X$) in 24000 repetitions of the matching problem."
    ) %>%
  kable_styling(fixed_thead = TRUE)

    ```
1. Recall the distribution of $X$. What would be the corresponding mathematical formula for the theoretical long run average value of $X$?  This number is called the "expected value" of $X$.
1. Is the expected value the most likely value of $X$?
1. Is the expected value of $X$ the "value that we would expect" on a *single* repetition of the phenomenon?
1. Explain in what sense the expected value is "expected".

```{solution matching-ev-sol}
to Example \@ref(exm:matching-ev)

```





```{asis, fold.chunk = TRUE}


1. We could shuffle cards labeled 1 through 4 and then distribute them into boxes labeled 1 through 4, and count the number of matches; that's one simulated value of $X$.  Or we could construct a spinner corresponding to the distribution of $X$ in the previous part and spin it once to obtain one simulated value of $X$.  We could then repeat either method many times to obtain many simulated values of $X$.
1. Compute the average of the 10 values simply by summing the values and dividing by 10.
    \[
    \frac{0 + 1 + 0 + 0 + 2 + 0 + 1 + 1 + 4 + 2}{10} = 1.1
    \]
    We could get a better approximation to the *long run* average value by simulating *many* values of $X$ and then taking the average.
1. Since every value of $X$ is either 0, 1, 2, or 4, we can compute the sum of the simulated values by multiplying each possible value by the number of repetitions on which it occurs and then adding these terms.  Then the average of the 10 values is equal to the sum of each possible value times its relative frequency
    \[
    \frac{0 \times 4 + 1 \times 3 + 2 \times 2 + 4 \times 1}{10} = 0\left(\frac{4}{10}\right)+ 1\left(\frac{3}{10}\right) + 2\left(\frac{2}{10}\right)+ 4\left(\frac{1}{10}\right) = 1.1
    \]
1. Sum the 24000 values and divide by 24000. The only possible values of $X$ are 0, 1, 2, 4 so the sum of simulated values, sorted, will be of the form
    \[
    0 + 0 + \cdots 0 + 1 + 1 + \cdots + 1 + 2 + 2 +\cdots + 2 + 4 + 4 + \cdots + 4.
    \]
      As in the previous part, since each of the 24000 values is either 0, 1, 2, or 4, the calculation of the sum can be simplified by multiplying each of the possible values by its frequency
    \begin{align*}
    & \qquad \frac{0 \times 8979 + 1 \times 7993 + 2 \times 6068 + 4 \times 960}{24000}\\ &= \frac{23969}{24000} = 0.99870\\
    & = 0\left(\frac{8979}{24000}\right)+ 1\left(\frac{7993}{24000}\right) + 2\left(\frac{6068}{24000}\right)+ 4\left(\frac{960}{24000}\right)
    \end{align*}
    The average of the 24000 values is equal to the sum of each possible value times its simulated relative frequency. Based on the results of this simulation, the long run average value of $X$ is approximately 0.9987.
1. Theoretical probabilities are long run relative frequencies.  In the long run, the simulated relative frequency of 0 will approach 9/24, of 1 will approach 8/24, etc.  So in the long run, the calculation from the previous part should approach
    \[
    0\left(\frac{9}{24}\right)+ 1\left(\frac{8}{24}\right)  + 2\left(\frac{6}{24}\right)+ 4\left(\frac{1}{24}\right) = 1
    \]
    That is, we compute the *probability-weighted average value*. The expected value of $X$ is 1.
1. No, the most likely value of $X$ is 0, not 1.
1. No, 1 is not the value of $X$ we would expect on a single repetition. The value 1 occurs with probability 1/3 and does not occur with probability 2/3.  So it's twice as likely to see a value other than 1 than to see 1.  In particularly, 0 has a higher probability of occuring than 1.
1. 1 is the value of $X$ that would we expect to see *on average in the long run.* If the matching scenario were repeated many times, then the long run average number of matches would be (close to) 1. 

```



The following Symbulate code simulates the matching problem.  The main programming aspect is to write the `count_matches` function which takes as an input a sequence of prizes and returns as an output the number of matches.  This function can then be used to define a `RV` (just as we use built in functions like `sum` and `max`).  With Python's zero-based indexing, the objects/spots are labeled 0, 1, 2, 3.

```{python}

n = 4
labels = list(range(n)) # list of labels [0, ..., n-1]

# define a function which counts number of matches
def count_matches(x):
    count = 0
    for i in range(0, n, 1):
        if x[i] == labels[i]:
            count += 1
    return count

P = BoxModel(labels, size = n, replace = False)

X = RV(P, count_matches)

(RV(P) & X).sim(10)

```


```{python}

x = X.sim(24000)

x.tabulate()

```


```{python, eval = FALSE}
x.plot()

```

```{python, echo = FALSE}
plt.figure()
x.plot()
plt.show()

```

The average of the 24000 simulated values is founded by summing all the values and then by dividing by 24000, or just by using `mean`.

```{python}

x.sum(), x.sum() / 24000, x.mean()

```


The previous example illustrates that the long run average value is also the *probability-weighted average value*.  That is, we multiplied each value by its corresponding probability, determined by the pmf, and then summed.  We can find the probability-weighted average value for continuous random variables analogously: multiply each possible value by its corresponding *density*, determined by the *pdf*, and then *integrate*.



```{example exponential-discrete-ev}

Let $X$ be a random variable which has the Exponential(1) distribution. To motivate the computation of the expected value of a continuous random variable,  we'll first consider a discrete version of $X$.

```


1. How could you use simulation to approximate the long run average value of $X$?
1. Suppose the values of $X$ are truncated^[We could also round to the nearest integer.  Whether we truncate or round won't matter as we consider what happens in the limit.] to integers.  That is, 0.73 is recorded as 0, 1.15 is recorded as 1, 2.999 is recorded as 2, 3.001 is recorded as 3, etc.  The following table summarizes 10000 simulated values of $X$, truncated.  Using just these values, how would you approximate the long run average value of $X$?
    ```{r, exponential-discrete-sim, echo = FALSE}
    ff = c(6302, 2327, 915, 287, 94, 43, 22, 5, 4, 1)

    kbl(
      data.frame(0:9, ff),
      booktabs = TRUE,
      col.names = c("Truncated value of X", "Number of repetitions"),
      caption = '10000 simulated values of X, truncated, for X with an Exponential(1) distribution'
    ) %>%
  kable_styling(fixed_thead = TRUE)

    ```
1. How could you *approximate* the probability that the truncated value of $X$ is 0? 1? 2? Suggest a formula for the (approximate) long run average value of $X$.  (Don't worry if the approximation isn't great; we'll see how to improve it.)
1. Truncating to the nearest integer turns out not to yield a great approximation of the long run average value of $X$.  How could we get a better approximation?
1. Suppose instead of truncating to an integer, we truncate to the first decimal.  For example 0.73 is recorded as 0.7, 1.15 is recorded as 1.1, 2.999 is recorded as 2.9, 3.001 is recorded as 3.0, etc.  Suggest a formula for the (approximate) long run average value of $X$.
1. We can continue in this way, truncating to the second decimal place, then the third, and so on. Considering what happens in the limit, suggest a formula for the theoretical long run average value of $X$.



```{solution exponential-discrete-ev-sol}
to Example \@ref(exm:exponential-discrete-ev)
```

```{asis, fold.chunk = TRUE}

1. Simulate many values of $X$, e.g., using the Exponential(1) spinner, and average: sum the simulated values and divide by the number of simulated values.  You can always approximate the long run average value of a random variable by simulating many values and averaging; it doesn't matter if the random variable is discrete or continuous.
1. The truncated random variable is a discrete random variable, so we can compute the average as in the matching problem
\[
0\left(\frac{6302}{10000}\right)+ 1\left(\frac{2327}{10000}\right)+2\left(\frac{915}{10000}\right) + 3\left(\frac{287}{10000}\right)+ \cdots + 9\left(\frac{1}{10000}\right)
\]
1. If $X$ is between 0 and 1 then the truncated value is 1.  We could find the probability that $X$ is between 0 and 1 by integrating the pdf over this range.  But we can *approximate* the probability by multiplying the pdf evaluated at 0.5 (the midpoint^[In the limit, any value in (0, 1) would work.  We use the midpoint mostly because just using using 0 results in an approximate probability of $e^{-0}(1)=1$, an egregious approximation of the true probability $1-e^{-1}\approx 0.632$]) by the length of the (0, 1) interval: $f(0.5)(1-0) = e^{-0.5}(1)\approx 0.607$.  Recall the end of Section \@ref(pdf).  Technically, the approximation is not great unless the interval is short, but it's the idea that is important for now.  Similarly the approximate probability that the truncated value is 1 is $f(1.5)(2-1) = e^{-1.5}(1)\approx 0.223$, and the approximate probability that the truncated value is 2 is $f(2.5)(3-2) = e^{-2.5}(1)\approx 0.082$.  Following this pattern, a reasonable formula for the (approximate) long run average value of $X$ seems to be
\begin{align*}
& \qquad 0\left(f(0+ 0.5)(1)\right)+ 1\left(f(1 + 0.5)(1)\right)+2\left(f(2+0.5)(1)\right) + 3\left(f(3 + 0.5)(1)\right) + \cdots
\\
& = \sum_{x=0}^\infty x f(x + 0.5) (1)\\
& = \sum_{x=0}^\infty x e^{-(x + 0.5)} (1)
\end{align*}
where the sum is over values $x = 0, 1, 2, \ldots$.  Plugging in $f(x + 0.5) = e^{-(x+0.5)}$ to the above yields 0.558. (This is a bad approximation, but the following parts refine it.  Using the left endpoint instead of the midpoint, that is, replacing $f(x)=e^{-x}$ instead of $f(x+0.5)=e^{-(x+0.5)}$, yields 0.92.)
1. Rather than truncating to integers, truncate to the first decimal, or the second, or the third. Or better yet don't truncate; $X$ is continuous after all.  But it helps to consider what would happen if $X$ were discrete first.  
1. Now the possible values would be 0, 0.1, 0.2, etc.  The truncated value would be 0 if $X$ lies in the interval (0, 0.1).  We could approximate this probability with $f(0.05)(0.1-0) = e^{-0.05}(0.1)$. We could approximate the probability that $X$ lies in the interval (0.1, 0.2), so the truncated value is 0.1, with $f(0.15)(0.2-0.1) = e^{-0.15}(0.1)$.  Following this pattern, a reasonable formula for the (approximate) long run average value of $X$ seems to be
\begin{align*}
& \qquad 0\left(f(0+ 0.05)(0.1)\right)+ 0.1\left(f(0.1 + 0.05)(0.1)\right)+0.2\left(f(0.2+0.05)(0.1)\right) + 0.3\left(f(0.3 + 0.05)(0.1)\right) + \cdots
\\
& = \sum_{x=0}^\infty x f(x + 0.05) (0.1)\\
& = \sum_{x=0}^\infty x e^{-(x + 0.05)} (0.1)
\end{align*}
where the sum is over values $x = 0, 0.1, 0.2, \ldots$.  Plugging in $f(x + 0.5) = e^{-(x+0.5)}$ to the above yields 0.950. 
1. Truncating to the second decimal place suggests a formula for the long run average of
\begin{align*}
& \qquad 0\left(f(0+ 0.005)(0.01)\right)+ 0.01\left(f(0.01 + 0.005)(0.01)\right)+0.02\left(f(0.02+0.005)(0.01)\right) + 0.03\left(f(0.03 + 0.005)(0.01)\right) + \cdots
\\
& = \sum_{x=0}^\infty x f(x + 0.005) (0.01)\\
& = \sum_{x=0}^\infty x e^{-(x + 0.005)} (0.01)
\end{align*}
where the sum is over values $x = 0, 0.01, 0.02, \ldots$.  Plugging in $f(x) = e^{-x}$ to the above yields 0.995.  
    If $\Delta x$ represents the level of truncation, e.g., $\Delta x = 0.01$ for truncating to the second decimal place, then a general formula is
    \begin{align*}
    & \qquad \sum_{x=0}^\infty x f(x + \Delta x / 2) \Delta x\\
    & = \sum_{x=0}^\infty x e^{-x + \Delta x / 2} \Delta x\\
    & \approx \sum_{x=0}^\infty x e^{-x} \Delta x
    \end{align*}
    In the limit as $\Delta x$ approaches 0, $f(x + \Delta x /2)$ approaches $f(x)=e^{-x}$, there are more and more terms in the sum, and the sum approaches an integral over $x$ values, 
    \begin{align*}
     & \qquad \int_0^\infty x f(x) dx\\
     & = \int_0^\infty x e^{-x} dx
    \end{align*}
```


```{definition ev}

The **expected value** (a.k.a. *expectation* a.k.a. *mean*), of a random variable $X$ defined on a probability space with measure $\IP$, is a number denoted $\E(X)$ representing the probability-weighted average value of $X$. Expected value is defined as

\begin{align*}
	& \text{Discrete $X$ with pmf $p_X$:} & \E(X) & = \sum_x x p_X(x)\\
	& \text{Continuous $X$ with pdf $f_X$:} & \E(X) & =\int_{-\infty}^\infty x f_X(x) dx
\end{align*}

```

Note well that $\E(X)$ represents *a single number*.

For a discrete random variable, the sum is over all possible values of $X$, that is, values of $x$ with $p_X(x)>0$.  For a continuous random variable, the generic bounds $(-\infty, \infty)$ should be replaced with the possible values of $X$; that is, the bounds correspond to intervals of $X$ with $f_X(x)>0$.



<!-- Note: expected value weighted average of area under the curve of x, not $f(x)$.  $f(x)$ is the weight, not the function -->




```{example exponential-ev}

Let $X$ be a random variable which has the Exponential(1) distribution.

```





1. Donny Dont says $\E(X) = \int_0^\infty e^{-x}dx = 1$.  Do you agree?
1. Compute $\E(X)$.
1. Compute $\IP(X = \E(X))$.
1. Compute $\IP(X \le \E(X))$.
1. Find the median value of $X$.  Is the median less than, greater than, or equal to the mean?  Why does this make sense?


```{solution exponential-ev-sol}
to Example \@ref(exm:exponential-ev)
```

```{asis, fold.chunk = TRUE}

1. Donny happened to get the correct value, but that's just coincidence.  His method is wrong.  Donny integrated $\int_{-\infty}^\infty f_X(x)dx$ which will always be 1.  To get the expected value, you need to find the probability weighted average value of $x$: $\int_{-\infty}^\infty x f_X(x)dx$. Forgetting the $x$ is a common mistake. Don't forget the $x$.
1. Since $X$ is continuous, with pdf $f_X(x) = e^{-x}, x > 0$, we integrate^[If you really wanted to, you could compute this integral using integration by parts.]
\[
\E(X) = \int_0^\infty x e^{-x}dx = 1
\]
    Notice that the bounds of the integral correspond to the interval of possible values of $X$.
1. The notation $\IP(X = \E(X))$ might seem strange at first.  But keep in mind that $\E(X)$ is a single number, so $\IP(X = \E(X))$ makes as much sense as $\IP(X = 1)$.  Since $X$ is a continuous random variable, the probability that it equals any particular number is 0.
1. We can use the cdf of $X$: $\IP(X \le \E(X))=\IP(X \le 1)=F_X(1) = 1-e^{-1}\approx0.632$.
1. The previous part shows that 1 is the 63rd percentile, so we know the mean of 1 will be greater than the median.
The cdf is $1-e^{-x}$, so setting the cdf to 0.5 and solving for $x$ yields the median: $0.5=1-e^{-x}$ implies $x=-\log(1-0.5)\approx 0.693$.  The mean is greater than the median because the large values in the right tail "pull the average up".

```


```{python}

X = RV(Exponential(1))

x = X.sim(10000)

x

```


```{python}

x.sum(), x.sum() / 10000, x.mean()

```



The expected value is the "balance point" (center of gravity) of a
distribution.  Imagine the impulse plot/histogram is constructed by stacking blocks on a board.  Then $\E(X)$ represents where you would need to place a stand underneath the board so that it doesn't tip to one side.






The probability of an event $A$, $\IP(A)$, is defined by the underlying probability measure $\IP$.  However, $\IP(A)$ can be interpreted as a long run relative frequency and can be approximated via a simulation consisting of many repetitions of the random phenomenon.  Similarly, the expected value of a random variable $X$ is defined by the probability-weighted average according to the underlying probability measure.  But the expected value can also be interpreted as the **long-run average value**, and so can be approximated via simulation. The fact that the long run average is equal to the probability-weighted average is known as the *law of large numbers*.  (We will see the law of large numbers in more detail later.)

Recall the discussion in Section \@ref(sim-lra), which we briefly recap here in the context of the matching problem.

The plots below illustrates the running average of $X$ in  Example \@ref(exm:matching-ev).  

(ref:cap-matching-lln-10) Running average for number of matches in the matching problem based on the simulation results in Table \@ref(tab:matching-sim-10-ev).

```{r, matching-lln-10, echo = FALSE}

x = c(0, 1, 0, 0, 2, 0, 1, 1, 4, 2)

n = length(x)

xbar = cumsum(x) / (1:n)

kbl(
  data.frame(1:n, x, xbar),
  align = "r",
  col.names = c("Repetition", "Value of X", "Running average of X"),
  booktabs = TRUE,
  caption = "(ref:cap-matching-lln-10)",
  digits = 3
) %>%
  kable_styling(fixed_thead = TRUE)

```  


(ref:cap-matching-lln-10-plot) Running average for number of matches in the matching problem based on the simulation results in Table \@ref(tab:matching-sim-10-ev).


```{r matching-lln-10-plot, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="(ref:cap-matching-lln-10-plot)"}

plot(1:n, xbar, type = "o",
     xlab = "Repetition",
     ylab = "Running average of X",
     ylim = c(0, 4),
     col = "blue",
     xaxt = "n")
axis(1, 1:n)
abline(h = 1, lty = 2, col = "orange")

```



As the number of repetitions increases, the running average of the number of matches tends to stabilize around the expected value of 1, regardless of the particular sequence of $X$ values in the simulation.
There is some natural simulation variability in the running average, but that variability decreases as the number of independently simulated values used to compute the average increases.



```{python, eval = FALSE, echo=TRUE}
rmax = 100

P = BoxModel([0, 1, 2, 4], probs = [9/24, 8/24, 6/24, 1/24]) ** rmax

X = RV(P)

Xbar_r = RandomProcess(P)

for r in range(rmax):
    Xbar_r[r] = X[0:(r + 1)].apply(mean)

Xbar_r.sim(5).plot(tmax = rmax)

plt.ylim(0, 4);
plt.xlabel('Repetition');
plt.ylabel('Running average of X');

```


(ref:cap-matching-lln) An illustration of the law of large numbers for the matching problem with $n=4$.  The plot displays the running average of simulated values of $X$, the number of matches, as the number of simulated values increases (from 1 to 100) for each of five separate simulations.  We can see that when the number of simulated values is small, the averages vary a great deal from simulation to simulation.  But as the number of simulated values increases, the average for each simulation starts to settle down to 1, the theoretical expected value.


```{r, matching-lln, echo=FALSE, fig.cap="(ref:cap-matching-lln)"}

knitr::include_graphics(c("_graphics/matching-lln.png"))
```


An expected value is defined as a probability-weight average value, but it often helps to interpret expected value as a long run average value. From a simulation perspective, you can read the symbol $\E(\cdot)$ as

- Simulate lots of values of what's inside $(\cdot)$
- Compute the average.  This is a "usual" average; just sum all the simulated values and divide by the number of simulated values.





```{example coin-heads-tails-streak-ev}

Consider the probability space corresponding to a sequence of three
flips of a fair coin. Let $X$ be the number of H, $Y$ the number of
tails, and $Z$ the length of the longest streak of H in a row (which can be 0 (TTT), 1 (e.g., HTT), 2 (e.g. THH), or 3 (HHH)).


```

1. Compute $\E(X)$.
1. Find and interpret $\IP(X=\E(X))$.
1. Is $\E(X)$ the "value that we would expect" on a *single* repetition of the process?
1. Write a clearly worded sentence interpreting $\E(X)$ in context.
1. Here is Donny Dont's response to the previous part: "1.5 is the long run average value."  Does he get full credit?  If not, what is wrong/missing? 
1. Donny tries again: "1.5 is the average number of heads in three flips."  Does he get full credit?  If not, what is wrong/missing?
1. Donny tries yet again: "If a coin is flipped three times and the number of heads is recorded and this process is repeated many times, then the number of heads is close to 1.5 in the long run." Does he get full credit?  If not, what is wrong/missing?
1. Without doing any calculations, find $\E(Y)$.  Explain.
1. Without doing any calculations determine if $\E(Z)$ will be greater than, less than, or equal to $\E(X)$.  Confirm your guess by computing $\E(Z)$.
1. Suppose now that the coin is biased and has a probability of 0.6 of landing on heads.  Without doing any calculations: Would $\E(X)$ change?  Would $\E(X)$ be equal to $\E(Y)$?


```{solution coin-heads-tails-streak-ev-sol}
to Example \@ref(exm:coin-heads-tails-streak-ev)
```

```{asis, fold.chunk = TRUE}

1. $X$ has a Binomial(3, 0.5) distribution, taking values 0, 1, 2, 3, with respective probability 1/8, 3/8, 3/8, 1/8.
$$
\E(X)=0(1/8) + 1(3/8) + 2(3/8) + 3(1/8) = 1.5.
$$
1. $\IP(X=\E(X))=\IP(X = 1.5) = 0$. Remember, $\E(X)$ is just a number.
1. $E(X)$ is not the "value that we would expect" on a *single* repetition of the process; it's not even possible to observe an  $X$ of 1.5 on a single repetition. You can't flip a coin 3 times and observe 1.5 heads in the 3 flips.
1. Over many sets of 3 fair coin flips, we expect 1.5 heads per set on average in the long run.
1. Donny only gets partial credit; he's missing the *context*.  The long run average value of what?
1. Donny only gets partial credit; he's missing any reference to the *long run*.
1. Donny only gets partial credit.  His sentence is pretty good with reference to the context and a long run description. But he's missing one extremely important word: *average*.
1. If the coin is fair then $X$ and $Y$ have the same distribution and so $\E(Y) =\E(X) = 1.5$.  If $X$ and $Y$ have the same long run pattern of variability, then they will have the same long run average value.
1. For any outcome, the length of the longest streak of H can't be more than the number of H. That is $X\ge Z$, so we must have $\E(X) \ge \E(Z)$.  If for every outcome $X$ is at least as large as $Z$, then the long run average value of $X$ should be at least as large as the long run average value of $Z$. See Table \@ref(tab:coin-transform-tab2). $\E(Z)=0(1/8) + 1(4/8) + 2(2/8) + 3(1/8) = 11/8=1.375$.
1. The sample space and the RVs would not change.  But the probability measure $\IP$ would change and so would the distribution of $X$ and $\E(X)$.  Also, the distribution of $X$ and $Y$ would not be the same anymore, and neither would the expected values.

```


```{r, coin-transform-tab22, echo = FALSE, fold.chunk = FALSE}
n = 3
# u1 = sort(rep(c("H", "T"), 4))
# u2 = rep(sort(rep(c("H", "T"), 2)), 2)
# u3 = rep(c("H", "T"), 4)
# u = paste(u1, u2, u3, sep = "")
u = c("HHH", "HHT", "HTH", "THH", "HTT", "THT", "TTH", "TTT")

x = c(3, rep(2, 3), rep(1, 3), 0)
y = 3 - x
z = c(3, 2, 1, 2, rep(1, 3), 0)


kbl(
  data.frame(u, x, y, z),
  col.names = c("Outcome", "X", "Y", "Z"),
  booktabs = TRUE,
  caption = 'Table representing $X$ the number of heads, $Y$ the number of tails, and $Z$ the length of the longest streak of heads in a row in 3 flips of a coin.'
)  %>%
  kable_styling(fixed_thead = TRUE)

```



If two random variables $X$ and $Y$ have the same distribution
(i.e., same long run pattern of variation) then they have the same
expected value (i.e., same long run average value).

But the converse is not true: $\E(X) = \E(Y)$ does NOT
imply that $X$ and $Y$ have the same distribution. For example, the random variables in Example \@ref(exm:matching-ev) and Example  \@ref(exm:exponential-ev) both have expected value 1, but they are two very different random variables. Expected value is just one summary characteristic of a  distribution,
i.e., the average. But there can be much more to the pattern of
variation, i.e., the distribution.  The following plot illustrates just a few different distributions that all have expected value 0.5.  (Don't worry about what these distributions are for now; we'll encounter some of them later.  Just know that they represent different patterns of variability.)

```{python, echo=FALSE}

plt.figure()
Normal(0.5, 0.3).plot()
Uniform(0, 1).plot()
Beta(0.9, 0.9).plot()
Beta(2, 2).plot()
Gamma(shape=2.8, rate=5.6).plot()
plt.show()
```


If $X\le Y$ --- that is, if $X(\omega)\le Y(\omega)$ for all^[This is sufficient, but technically not necessary. If $X\le Y$ *almost surely* --- that is, if $\IP(X\le Y)=1$ --- then $\E(X)\le \E(Y)$.]
$\omega\in\Omega$ --- then $\E(X)\le\E(Y)$.  That is, if for every outcome the value of $X$ is no bigger than the value of $Y$, then the long run average value of $X$ can't be any bigger than the long run average value of $Y$.

The distribution of a RV and its expected value depend on the
probability measure $\IP$. If the probability measure changes
(e.g., from representing a fair coin to a biased coin) then distributions
and expected values of RVs will change.  Remember that $\IP$ represents a probability measure that incorporates all the underlying assumptions about the random phenomenon (the symbol $\IP$ is more than just shorthand for "probability").  In the same way, the symbol $\E$ is more than just shorthand for "expected value".  Rather $\E$ represents the probability-weighted/long run average value according to all the underlying assumptions of the random phenonemon as specified by the probability measure $\IP$.  In fact, a more appropriate symbol might be $\E_{\IP}$ to emphasize the dependence on the probability measure.  We will only use such notation if multiple probability measures are being considered on the same sample
space, e.g., $\E_{\IP}$ represents the expected value according to probability measure $\IP$ (e.g., fair coin), while $\E_{\IQ}$ represents expected value according to probability measure $\IQ$ (e.g., biased coin).



```{example homerun-poisson-ev}

Recall Example \@ref(exm:homerun-poisson) in which we assume that $X$, the number of home runs hit (in total by both teams) in a randomly selected Major League Baseball game, has a Poisson(2.3) distribution with pmf

\[
p_X(x) =
\begin{cases}
e^{-2.3} \frac{2.3^x}{x!}, & x = 0, 1, 2, \ldots\\
0, & \text{otherwise.}
\end{cases}
\]



```


1. Recall from Example \@ref(exm:homerun-poisson) that $\IP(X \le 13) =0.9999998$. Evaluate the pmf for $x=0, 1, \ldots, 13$ and use arithmetic to compute $\E(X)$. (This will technically only give an approximation, since there is non-zero probability that $X>13$, but the calculation will give you a concrete example before jumping to the next part.)
1. Use the pmf and infinite series to compute $\E(X)$.
1. Interpret $\E(X)$ in context.


```{solution homerun-poisson-ev-sol}
to Example \@ref(exm:homerun-poisson-ev)
```


1. See Example \@ref(exm:homerun-poisson) and the discussion following it for calculation of the probabilities.
\[
{\scriptsize
`r paste("(", 0:13, ")", "(", round(dpois(0:13, 2.3), 5),")", collapse = "+", sep = "")` = `r round(sum((0:13) * dpois(0:13, 2.3)), 3)`
}
\]

1. $X$ is a discrete random variable that takes infinitely many possible values.  The sum in the expected value definition is now an infinite series.

    \begin{align*}
    \E(X) & = \sum_{x = 0}^\infty x p_X(x) & & \\
    & = \sum_{x = 0}^\infty x \left(e^{-2.3} \frac{2.3^x}{x!}\right) & & \\
    & = \sum_{x = 1}^\infty e^{-2.3} \frac{2.3^x}{(x-1)!}& & (x=0 \text{ term is 0})\\
    & = 2.3 \sum_{x = 1}^\infty e^{-2.3} \frac{2.3^{x-1}}{(x-1)!} & & \\
    & = 2.3(1) & & \text{Taylor series for $e^u$ at $u=2.3$}
    \end{align*}

    So $\E(X)=2.3$.

1. Over many MLB games, there are 2.3 home runs hit per game on average in the long run.  Note that 2.3 is the observed average number of home runs per game in the 2018 MLB season data, displayed in Figure \@ref(fig:poisson-hr-data).






In general, if $X$ has a Poisson($\mu$) distribution, then $\E(X)=\mu$.

```{example, uniform-ev}

Let $X$ be a random variable with a Uniform(0, 1) distribution.  Compute $\E(X)$.  Then suggest a general formula for the expected value of a random variable with a Uniform($a$, $b$) distribution.

```


```{solution uniform-ev-sol}
to Example \@ref(exm:uniform-ev)
```

```{asis, fold.chunk = TRUE}

Since the expected value is the balance point, it seems that the expected value for a Uniform distribution should just be the midpoint of the interval of possible values.

For Uniform(0, 1), the pdf is a constant of 1 between 0 and 1.

\[
\E(X) = \int_0^1 x \left(1\right) dx  = x^2/2 \Bigg|_{0}^{1}  = \frac{1}{2}
\]

For Uniform($a$, $b$) the pdf is a constant of $\frac{1}{b-a}$ between $a$ and $b$.

\[
\E(X) = \int_a^b x \left(\frac{1}{b-a}\right) dx  = \frac{1}{2(b-a)} x^2 \Bigg|_{a}^{b}  =  \frac{b^2 - a^2}{2(b-a)} = \frac{a+b}{2}
\]

```



Recall that the indicator random variable corresponding to event $A$ is defined as
\[
\ind_A(\omega) =
\begin{cases}
1, & \omega \in A,\\
0, & \omega \notin A
\end{cases}
\]

Indicators provide the bridge between events (sets) and random variables (functions), and between probabilities (of events) and expected values (of random variables).

\[
\E\left(\ind_A\right) = \IP(A)
\]



## "Law of the unconscious statistician" (LOTUS)

<!-- Rename to Expected Values of Transformations -->

A distribution is the complete picture of the long run pattern of variability of random variable.  An expected value is just one particular characteristic of a distribution, namely, the long run average value.  We can often compute expected values without first finding the entire distribution.

```{example rw-lotus}

Flip a coin 3 times and let $X$ be the number of flips that result in H, and let $Y=(X-1.5)^2$. (We will see later why we might be interested in such a transformation.)

```

1. Find the distribution of $Y$.
1. Compute $\E(Y)$.
1. How could we have computed $\E(Y)$ without first finding the distribution of $Y$?
1. Is $\E((X-1.5)^2)$ equal to $(\E(X)-1.5)^2$?


```{solution rw-lotus-sol}
to Example \@ref(exm:rw-lotus)
```

```{asis, fold.chunk = TRUE}

1. The possible values of $X$ are 0, 1, 2, 3, so the possible values of $Y$ are $(0 - 1.5)^2= 2.25$, $(1 - 1.5)^2= 0.25$, $(2 - 1.5)^2=0.25$, $(3 - 1.5)^2=2.25$.  That is, the possible values of $Y$ are  0.25 and 2.25.  $\IP(Y = 2.25) = \IP(X = 0)+\IP(X = 3) = 2/8$.  The following table provides the distribution of $Y$.  

    |  $y$ | $p_Y(y)$ |
    |-----:|---------:|
    | 0.25 |      6/8 |
    | 2.25 |      2/8 |
  
1. $\E(Y) = 0.25(6/8) + 2.25(2/8) = 0.75$.
1. Since $X$ takes the value 0 with probability 1/8, 1 with probability 3/8, 2 with probability 3/8, 3 with probability 1/8, then the random variable $(X - 1.5)^2$ takes value $(0 - 1.5)^2$ with probability 1/8, $(1 - 1.5)^2$ with probability 3/8, $(2 - 1.5)^2$ with probability 3/8, and $(3 - 1.5)^2$ with probability 1/8. Therefore
    \[
    \E((X-1.5)^2) = (0 - 1.5)^2(1/8)+ (1 - 1.5)^2(3/8) + (2 - 1.5)^2(3/8) + (3 - 1.5)^2(1/8) = 0.75.
    \]
    Finding the distribution of $Y$ and then using it to compute the expected value of $Y$ basically just groups some of the terms in the calculation in the previous sentence together.
1. NO! $\E(X) = 1.5$ so $(\E(X)-1.5)^2=0$.


```




The calculation of $\E((X-1.5)^2)$ in part 3 of the previous example probably seemed pretty natural, and only required working with the distribution of $X$ rather than first finding the distribution of a transformed random variable.  It's so natural, we could probably do it without thinking; this is the idea behind the following.

```{definition lotus, name='Law of the unconscious statistician ( LOTUS)'}

The **"law of the unconscious statistician" (LOTUS)** says that the expected value of a transformed random variable can be found without finding the distribution of the transformed random variable, simply by applying the probability weights of the original random variable to the transformed values.

\begin{align*}
	& \text{Discrete $X$ with pmf $p_X$:} & \E[g(X)] & = \sum_x g(x) p_X(x)\\
	& \text{Continuous $X$ with pdf $f_X$:} & \E[g(X)] & =\int_{-\infty}^\infty g(x) f_X(x) dx
\end{align*}

```

The left-hand side of LOTUS, $\E[g(X)]$, represents finding the expected value the "long way": define $Y=g(X)$, find the distribution of $Y$ (e.g., using the cdf method in Section \@ref(cdf-method)), then use the definition of expected value to compute $\E(Y)$.  LOTUS says we don't have to first find the distribution of $Y=g(X)$ to find $\E[g(X)]$; rather, we just simply apply the transformation $g$ to each possible value $x$ of $X$ and then apply the corresponding weight for $x$ to $g(x)$.

From a simulation perspective, the left-hand side of LOTUS, $\E[g(X)]$, represents first constructing a spinner according to the distribution of $Y=g(X)$ (e.g., using the cdf method in Section \@ref(cdf-method)), then spinning it to simulate many $Y$ values and averaging the simulated values.
LOTUS says we don't have to construct the $Y$ spinner; we can simply spin the $X$ spinner to simulate many $X$ values, apply the transformation $g$ to each simulated $X$ value, and then average the transformed values.

LOTUS is much more useful for continuous random variables.

```{example uniform-lotus}

Let $X$ be a random variable with a Uniform(-1, 1) distribution and let $Y=X^2$.
Recall  that in Example \@ref(exm:uniform-square-cdf-method) we found the pdf of $Y$: $f_Y(y) = \frac{1}{2\sqrt{y}}, 0<y<1$.

```

1. Find $\E(X^2)$ using the distribution of $Y$ and the definition of expected value.  Remember: if we did not have the distribution of $Y$, we would first have to derive it as in Example \@ref(exm:uniform-square-cdf-method).
1. Describe how to use simulation to approximate $\E(Y)$, in a way that is analogous to the method in the previous part.
1. Find $\E(X^2)$ using LOTUS.
1. Describe how to use simulation to approximate $\E(X^2)$, in a way that is analogous to the method in the previous part.
1. Is $\E(X^2)$ equal to $(\E(X))^2$?



```{solution uniform-lotus-sol}
to Example \@ref(exm:uniform-lotus)
```


```{asis, fold.chunk = TRUE}

1. If we have the distribution of $Y$, we compute expected value according to the definition, weighting $y$ values by the pdf of $Y$, $f_Y(y)$, and then integrating over possible $y$ values.
    \[
    \E(X^2) = \E(Y) = \int_{-\infty}^\infty y f_Y(y) dy = \int_0^1 y\left(\frac{1}{2\sqrt{y}}\right)dy = 1/3
    \]
1. Construct a spinner corresponding to the distribution of $Y$. Remember: this would involve first finding the cdf of $Y$ as we did in Example \@ref(exm:uniform-square-cdf-method), and then the corresponding quantile function to determine how to stretch/shrink the values on the spinner.
Spin the $Y$ spinner many times to simulate many values of $Y$ and then average the simulated $Y$ values to approximate $\E(Y)$.
1. The pdf of $X$ is $f_X(x) = 1/2, -1<x<1$. Now we just work with the distribution of $X$, but average the squared values $x^2$, instead of the $x$ values.  Notice that the integral below is a $dx$ integral.  Using LOTUS
    \[
    \E(X^2) = \int_{-\infty}^\infty x^2 f_X(x) dx = \int_{-1}^1 x^2 (1/2)dx = 1/3
    \]
    We hope you recognize that this calculation is much easier than first calculating the pdf as in Example \@ref(exm:uniform-square-cdf-method).
1. Spin the Uniform(-1, 1) spinner to simulate many values of $X$. For each simulated value $x$ compute $x^2$, then average the $x^2$ values.
(We can construct a Uniform(-1, 1) spinner by a linear rescaling of the Uniform(0, 1) spinner: $u\mapsto 2u-1$.)
1. NO!!!  $\E(X)= 0$, but $\E(X^2)=1/3$.
  
```

Recall Section \@ref(LRA).  Whether in the short run or the long run, in general
\begin{align*}
\text{Average of $g(X)$} & \neq g(\text{Average of $X$})
\end{align*}

In terms of expected values, in general
\begin{align*}
\E(g(X)) & \neq g(\E(X))
\end{align*}
The left side $\E(g(X))$ represents first transforming the $X$ values and then averaging the transformed values. The right side $g(\E(X))$ represents first averaging the $X$ values and then plugging the average (a single number) into the transformation formula.  

```{python}
X = RV(Uniform(-1, 1))

Y = X ** 2

y = Y.sim(10000)

y.mean()
```

```{python, eval = FALSE}
y.plot()
```

```{python, echo = FALSE}

plt.figure()

y.plot()

plt.show()


```

```{example, exponential-lotus}

We want to find $\E(X^2)$ if $X$ has an Exponential(1) distribution.  Donny Dont says: "I can just use LOTUS and replace $x$ with $x^2$, so $\E(X^2)$ is $\int_{-\infty}^{\infty} x^2 e^{-x^2} dx$".  Do you agree?

```



```{solution exponential-lotus-sol}
to Example \@ref(exm:exponential-lotus)
```


```{asis, fold.chunk = TRUE}

No, $x^2$ is multiplied by the density at $x$, $f_X(x)=e^{-x}$, not at $x^2$.  Think of the discrete random variable in Example \@ref(exm:rw-lotus).  There we had $(x-1.5)^2 p_X(x)$, e.g., $(3-1.5)^2(1/8)$ because $p_X(3)= 1/8$.  If we had squared the $x$ values inside the pmf, we would have $p_X(3^2)$ which is 0.  The correct use of LOTUS is

\[
\E(X^2) = \int_0^\infty x^2 e^{-x} dx = 2 
\]

```

The whole point of LOTUS is that you can work with the distribution of the original random variable $X$.  Keep the pdf of $X$, $f_X(x)$, as is, and only transform the values being averaged.
Keeping the pdf $f(x)$ as is is like sticking with the $X$ spinner rather than constructing a $Y$ spinner.
The $X$ spinner itself doesn't change; rather, you transform the values that it generates before averaging.

```{example, dice-2d-lotus}

Roll a fair four-sided die twice.  Let $X$ be the sum of the two rolls, and let $W$ be the number of rolls that are equal to 4. 

```

1. Find the joint distribution of $X$ and $W$.
1. Let $Z = XW$ be the product of $X$ and $W$.  Find the distribution of $Z$.
1. Find $\E(Z)$.
1. How could you find $\E(XW)$ without first finding the distribution of $Z = XW$?
1. Is $\E(XW)$ equal to the product of $\E(X)$ and $\E(W)$?

```{solution dice-2d-lotus-sol}
to Example \@ref(exm:dice-2d-lotus)
```

```{asis, fold.chunk = TRUE}


1.  The table displays the joint pmf $p_{X, W}(x, w)$.  

    | $x$ \\ $w$             |    0 |    1 |    2 | $p_X(x)$ |
    |:-----------------------|-----:|-----:|-----:|-----------------------:|
    | 2                      | 1/16 |    0 |    0 |                   1/16 |
    | 3                      | 2/16 |    0 |    0 |                   2/16 |
    | 4                      | 3/16 |    0 |    0 |                   3/16 |
    | 5                      | 2/16 | 2/16 |    0 |                   4/16 |
    | 6                      | 1/16 | 2/16 |    0 |                   3/16 |
    | 7                      |    0 | 2/16 |    0 |                   2/16 |
    | 8                      |    0 |    0 | 1/16 |                   1/16 |
    | $p_{W}(w)$ | 9/16 | 6/16 | 1/16 |                        |
1. For each $(x, w)$ pair find the product $xw$, and then collect like values to compute probabilities. For example, since $X>0$, $\IP(Z = 0) = \IP(XW = 0) = \IP(W=0)=9/16$. The table displays the pmf of $Z$.  

    | $z$ | $p_Z(z)$ |
    |----:|---------:|
    |   0 |     9/16 |
    |   5 |     2/16 |
    |   6 |     2/16 |
    |   7 |     2/16 |
    |  16 |     1/16 |
    
1. Since we have the distribution of $Z$ we can just use the definition of expected value.
    \[
    0(9/16) + 5(2/16)+6(2/16) + 7(2/16)  + 16(1/16) = 3.25
    \]
    So $\E(XW) = 3.25$.
1. We can use the joint pmf of $X$ and $W$, find the product for each possible pair, and multiply by the probability of that pair.
    \begin{align*}
    & \quad (2)(0)(1/16) + (3)(0)(2/16) +  (4)(0)(3/16) + (5)(0)(2/16) + (6)(0)(1/16) \\
    & + (5)(1)(2/16)+(6)(1)(2/16) + (7)(1)(2/16)  + (8)(2)(1/16) 
    \end{align*}
    Finding the distribution of $Z$ and then using it to compute the expected value of $Z$ basically just groups some of the terms in the calculation in the previous sentence together.
1. No!.  $\E(X)= 5$ and $\E(W) = 0.5$, so the expected value of the product is not equal to the product of the expected values.

```

Recall Section \@ref(LRA).  Whether in the short run or the long run, in general
\begin{align*}
\text{Average of $g(X, Y)$} & \neq g(\text{Average of $X$}, \text{Average of $Y$})
\end{align*}

In terms of expected values, in general

\begin{align*}
\E\left(g(X, Y)\right) & \neq g\left(\E(X), \E(Y))\right)
\end{align*}

There is also LOTUS for two random variables.
\begin{align*}
& \text{Discrete $X, Y$ with joint pmf $p_{X, Y}$:} & \E[g(X, Y)] & = \sum_{x}\sum_{y} g(x, y) p_{X, Y}(x, y)\\
& \text{Continuous $X, Y$ with joint pdf $f_{X, Y}$:} & \E[g(X, Y)] & = \int_{-\infty}^\infty\int_{-\infty}^\infty g(x, y) f_{X, Y}(x, y)\,dxdy
\end{align*}

LOTUS for two continuous random variables requires double integration.  However, we will later see  other tools for computing expected values, and using such tools it is often possible to avoid double integration.

Of course, LOTUS only gives a shortcut to computing expected values of transformations.  Remember that expected values are only summary characteristics of a distribution.  If we want more information about a distribution, e.g., its pdf or cdf, then LOTUS will not be enough.



## Variance and standard deviation

The values of a random variable vary.  The distribution of a random variable describes its pattern of variability. The expected value of a random variable summarizes the distribution in just a single number, the long run average value.  But the expected value does not tell us much^[You might think that the expected value doesn't tell us *anything* about the degree of variability.  But knowing the expected value does put a very rough limit on the probability that the random variable takes very large values.  We'll discuss this idea when we cover *Markov's inequality* in Section \@ref(markov-inequality).  In any case, the expected value alone tells us very little about the degree of variability.] about the degree of variability of the random variable.  Do the values of the random variable tend to be close to the expected value, or are they spread out?  Variance and standard deviation are numbers that address these questions.


```{example, roulette-black}
A roulette wheel has 18 black spaces, 18 red spaces, and 2 green spaces, all the same size and each with a different number on it.  Guillermo bets \$1 on black.  If the wheel lands on black, Guillermo wins his bet back plus an additional \$1; otherwise he loses the money he bet.  Let $W$ be Guillermo's net winnings (net of the initial bet of \$1.)

```

1. Find the distribution of $W$.
1. Compute $\E(W)$.
1. Interpret $\E(W)$ in context.
1. An expected profit *for the casino* of 5 cents per \$1 bet seems small.  Explain how casinos can turn such a small profit into billions of dollars.
1. In Section \@ref(sd) we introduced  variance as the long run average squared distance from the mean.  Describe how you could use simulation to approximate the variance of $W$.  What would you expect the simulation results to look like?
1. Without doing any further calculations, provide a ballpark estimate of the variance.  Explain.  What are the measurement units for the variance?
1. The random variable $(W-\E(W))^2$ represents the squared deviation from the mean.  Find the distribution of this random variable and its expected value.
1. In Section \@ref(sd) we introduced standard deviation as the square root of the variance.  Why would we want to take the square root of the variance?  Compute and interpret the standard deviation of $W$.
1. Compute $\E(W^2)$. (For this $W$ you should be able to compute $\E(W^2)$ without any calculations; why?) Then compute $\E(W^2) - (\E(W))^2$; what do you notice?




```{solution roulette-black-sol}
to Example \@ref(exm:roulette-black)
```

```{asis, fold.chunk = TRUE}

1. Assuming the wheel is equally likely to land on any of the 38 spaces, Guillermo wins with probability 18/38 in which case his net winnings are 1 dollar; otherwise, his net winnings are $-1$ dollar.

    | $w$ |              $p_W(w)$ |
    |----:|----------------------:|
    |  -1 | 20/38 $\approx$ 0.5263 |
    |   1 | 18/38 $\approx$ 0.4737 |
  
1. Use the definition of expected value of a discrete random variable.
    \[
    \E(W) =  (-1)(20/38) + (1)(18/38) = -2/38 \approx -0.05
    \]
1. Over many \$1 bets on black in roulette, Guillermo expects to lose on average about \$0.05 per bet.
1. Casinos operate in the long run, so over millions of bets they expect an essentially guaranteed profit of \$0.05 per bet on average.  A nickle isn't much, but billions of free nickles are nice.
1. Set up a spinner than lands on 1 with probability 18/38, and $-1$ with probability 20/38.  Spin the spinner many times, recording the result (1 or $-1$) each time.  Compute the average of the simulated values; it should be close to $-2/38$.  Take each simulated value, subtract the mean (about $-2/38$) and square, then average those values. If you simulate 38000 values of $W$, about 18000 will be 1, and 20000 will be $-1$, and the average will be about
    \[
    \frac{(1)(18000) + (-1)(20000)}{38000} \approx -0.05.
    \]
    Then about 18000 of the squared deviations will be $(1-(-0.05))^2 \approx 1.1$ and about 20000 will be $(-1 - (-0.05))^2\approx 0.9$, and the average will be about
    \[
    \frac{(1-(0.05))^2(18000) + (-1-(-0.05))^2(20000)}{38000} \approx 0.997.
    \]
    See simulation results below.
1. The mean is pretty close to 0.  The values of $-1$ and $1$ all are 1 unit away from the mean, so all the squared deviations are about 1, so the average squared deviation should be about 1.  The measurement units are squared-dollars.
1. The table summarizes the distribution of the random variable $(W-\E(W))^2$.  

    |                       Value |           Probability |
    |----------------------------:|----------------------:|
    | $(-1-(-2/38))^2\approx 0.9$ | 20/38 $\approx$ 0.5263 |
    |  $(1-(-2/38))^2\approx 1.1$ | 18/38 $\approx$ 0.4737 |  
    
    The expected value is
    \[
    \E\left((W-\E(W))^2\right) = (1-(-2/38))^2(18/38) +(-1-(-2/38))^2(20/38) = 1 - 1/19^2 \approx 0.9972
    \]
1. The measurement units of variance are squared-dollars, which aren't very practical.  We take the square root to get back to the original units of dollars.  The standard deviation of $W$ is $\sqrt{1-1/19^2}\approx 0.9986$ dollars.  The standard deviation measures roughly the average distance of the values of the $W$ from the mean.
1. In this case, since $W$ is either 1 or $-1$, then $W^2$ is just the constant 1 so its expected value is just 1. $\E(W^2) - (\E(W))^2 = 1 - (2/38)^2 = 1 - 1/19^2$, which is equal to the variance.

``` 

The following simulation corresponds to Example \@ref(exm:roulette-black).

```{python}

W = RV(BoxModel([-1, 1], probs = [20 / 38, 18 / 38]))

(W & (W - (-2 / 38)) ** 2).sim(10)

```

We simulate many values of $W$ and save them.

```{python}

w = W.sim(38000)

w

```

```{python}

w.tabulate()

```

```{python, eval = FALSE}
w.plot()
```


```{python, echo = FALSE}
plt.figure()
w.plot()
plt.show()

```


```{python}

w.mean()

```

For each simulated value, compute the squared deviation from the mean.

```{python}

(w - w.mean()) ** 2

```

Summarize the squared deviations.

```{python}

((w - w.mean()) ** 2).tabulate()

```

Approximate the variance by computing the average squared deviation.

```{python}

((w - w.mean()) ** 2).mean(), w.var()

```


Variance is also equal to the average of the squared values of $W$ minus the square of the average value of $W$.

```{python}

(w ** 2).mean() - (w.mean()) ** 2

```


The standard deviation is the square root of the variance.

```{python}

sqrt(w.var()), w.sd()

```


```{definition, variance}

The **variance** of a random variable $X$ is
\begin{align*}
  \Var(X) & = \E\left(\left(X-\E(X)\right)^2\right)\\
& = \E\left(X^2\right) - \left(\E(X)\right)^2
\end{align*}
The **standard deviation** of a random variable is
\begin{equation*}
  \SD(X) = \sqrt{\Var(X)}
\end{equation*}
```

Variance is, roughly, the long run average squared deviation from the mean.  We square the deviations because when measuring distance from the mean it doesn't matter if a value is above or below the mean.  For example, a value that is 3 units above the mean has the same squared deviation as a value that is 3 units below the mean ($3^2 = (-3)^2$). You  might think, why not just consider the absolute value of the deviations?  It turns out that squaring leads to nicer mathematical properties^[Think Pythagorean theorem: it's $a^2 + b^2 = c^2$. On the other hand, the triangle inequality says $|a + b| \le |a| + |b|$.].


Standard deviation measures, roughly, the long run average distance from the mean.  The measurement units of the standard deviation are the same as for the random variable itself.

The definition $\E((X-\E(X))^2)$ represents the concept of variance. However, variance is usually computed using the following equivalent but slightly simpler formula.

$$
\Var(X) = \E\left(X^2\right) - \left(\E\left(X\right)\right)^2
$$

That is, variance is the expected value of the square of $X$ minus the square of the expected value of $X$.  The above formula basically allows us to subtract $\E(X)$ once rather than subtracting it from each value.  The expected value of the square, $\E(X^2)$, can be computed with LOTUS.

In some cases, we have the expected value and variance and we want to compute $\E(X^2)$. Rearranging the above formula yields

$$
\E\left(X^2\right)  = \Var(X) + \left(\E\left(X\right)\right)^2
$$



We will see that variance has many nice theoretical properties.  Whenever you  need to compute a standard deviation, first find the variance and then take the square root at the end.


```{example, roulette-number}

Continuing with roulette, Nadja bets \$1 on number 7.  If the wheel lands on 7, Nadja wins her bet back plus an additional \$35; otherwise she loses the money she bet.  Let $X$ be Nadja's net winnings (net of the initial bet of \$1.)

```

1. Find the distribution of $X$.
1. Compute $\E(X)$.   
1. How do the expected values of the two \$1 bets --- bet on black versus bet on 7 --- compare?  Explain what this means.
1. Are the two \$1 bets --- bet on black versus bet on 7 --- identical?  If not, explain why not.
1. Before doing any calculations, determine if $\SD(X)$ is greater than, less than, or equal to $\SD(W)$. Explain.
1. Compute $\Var(W)$ and $\SD(W)$.
1. Which \$1 bet --- betting on black or betting on 7 --- is "riskier"?  How is this reflected in the standard deviations?



```{solution roulette-number-sol}
to Example \@ref(exm:roulette-number)
```

```{asis, fold.chunk = TRUE}

1. Assuming the wheel is equally likely to land on any of the 38 spaces, Nadja wins with probability 1/38 in which case her net winnings are 35 dollars; otherwise, her net winnings are $-1$ dollar.

    |  $x$ |              $p_X(x)$ |
    |-----:|----------------------:|
    |   -1 | 37/38 $\approx$ 0.9737 |
    |   35 |  1/38 $\approx$ 0.0263 |  
  
1. Use the definition of expected value of a discrete random variable.
    \[
    \E(X) =  (-1)(37/38) + (35)(1/38) = -2/38 \approx -0.05
    \]
1. The two expected values are the same.  If Guillermo makes many \$1 bets on black and Nadja makes many \$1 bets on 7 then each will have  long run average losses of about 5 cents per bet.
1. No, these are very different bets even though their expected values are the same.  Guillermo wins about half the time, but his winnings are small.  Nadja is much less likely to win, but when she does she wins big.
1. $\SD(X)$ is greater than $\SD(W)$. The mean is the same in both cases, but $X$ can take values that are about 35 units away from the mean, so the average distance from the mean will be greater for $X$ than for $W$.
1. We use the computational formula.
    \[
    \Var(X) = E(X^2) - (\E(X))^2 = \left[(-1)^2(37/38) + (35)^2(1/38)\right] - (-2/38)^2  \approx 33.2
    \]
    So $\SD(X) = \sqrt{33.2} = 5.76$ dollars.
1. Betting on 7 is riskier; it's less likely to win, but when it does the winnings are big.  The riskier bet has the larger standard deviation.

```

The definition of variance is the same for discrete and continuous random variables.  But remember that for continuous random variables expected values are computed via integration.

```{example, uniform-sd}

Let $X$ be a Uniform($a$, $b$) distribution.


```

1. First, suppose $X$ has a Uniform(0, 1) distribution.  Make a ballpark estimate of the standard deviation.
1. Compute $\SD(X)$ if $X$ has a Uniform(0, 1) distribution.
1. Now suggest a rough formula for the standard deviation for the general Uniform($a$, $b$) case.
1. Compute $\SD(X)$ if $X$ has a Uniform($a$, $b$) distribution.

```{solution uniform-sd-sol}
to Example \@ref(exm:uniform-sd)
```

```{asis, fold.chunk = TRUE}

1. The expected value is 0.5.  The deviations from the mean range from 0 (corresponding to a value of 0.5) to 0.5 (corresponding to a value of 0 or 1).  Since the $X$ values are uniformly distributed, the absolute deviations will also be uniformly distributed between 0 and 0.5.  Therefore, we might guess that the average deviation from the mean is around 0.25.
1. We computed $E(X^2) = 1/3$ using LOTUS in Example \@ref(exm:uniform-lotus).  $\Var(X) = \E(X^2) - (\E(X))^2 = 1/3 - (1/2)^2 = 1/12$.  $\SD(X) = 1/\sqrt{12}\approx 0.289$.  The standard deviation isn't quite 0.25 because squaring then averaging then taking the square root isn't the same as just averaging the deviations. But 0.25 is not that far off.
1. In general, the deviations range from 0 to $(b-a)/2$ (half the length of the interval), so we might guess the standard deviation is $(b-a)/4$
1. The pdf of $X$ is $f_X(x) = \frac{1}{b-a}, a<x<b$.  Compute $\E(X^2)$ using LOTUS.
    \[
    \E(X^2) = \int_a^b x^2 \left(\frac{1}{b-a}\right)dx = \frac{x^3}{3(b-a)}\Bigg|_a^b = \frac{b^3 - a^3}{3(b-a)}
    \]
    Then, after some algebra,
    \[
    \Var(X) = \E(X^2) - (\E(X))^2 = \frac{b^3 - a^3}{3(b-a)} - \left(\frac{a+b}{2}\right)^2 = \frac{(b-a)^2}{12}
    \]
    The standard deviation is
    \[
    \SD(X) = \frac{b- a}{\sqrt{12}} \approx 0.289 (b-a)
    \]
    So our guess of 0.25 times the length of the interval was not too far off.  Thinking of variability just in terms of the overall range of values, it makes sense that the standard deviation should depend on the length of the interval.  That is, the standard deviation should only depend on $a$ and $b$ through their difference $b-a$.

```

```{example, sd-matching}

The plots below summarize hypothetical distributions of quiz scores in six classes. All plots are on the same scale.  Each quiz score is a whole number between 0 and 10 inclusive.

```



```{r, sd-matching-plot, echo = FALSE}

x1 = 0:10
p1 = c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1)
p1 = p1/sum(p1)

x2 = 0:10
p2 = c(6, 5, 4, 3, 2, 1, 2, 3, 4, 5, 6)
p2 = p2/sum(p2)

x3 = 0:10
p3 = rep(1/11, 11)

x4 = c(0, 10)
p4 = c(0.5, 0.5)

x5 = 3:7
p5 = c(1, 2, 3, 2, 1)
p5 = p5/sum(p5)

x6 = c(6, 7, 8)
p6 = c(0.1, 0.8, 0.1)

xlimits = c(0, 10)
xs = 0:10
par(mfrow=c(2,3), mar=c(4, 4, 1, 1) + 0.1)
plot(x1, p1, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="A", type="h", lwd=2, xaxt="n")
axis(1, xs)
plot(x2, p2, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="B", type="h", lwd=2, xaxt="n")
axis(1, xs)
plot(x3, p3, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="C", type="h", lwd=2, xaxt="n")
axis(1, xs)
plot(x4, p4, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="D", type="h", lwd=2, xaxt="n")
axis(1, xs)
plot(x5, p5, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="E", type="h", lwd=2, xaxt="n")
axis(1, xs)
plot(x6, p6, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="F", type="h", lwd=2, xaxt="n")
axis(1, xs)

# sqrt(sum(x1^2*p1)-sum(x1*p1)^2)
# sqrt(sum(x2^2*p2)-sum(x2*p2)^2)
# sqrt(sum(x3^2*p3)-sum(x3*p3)^2)
# sqrt(sum(x4^2*p4)-sum(x4*p4)^2)
# sqrt(sum(x5^2*p5)-sum(x5*p5)^2)
# sqrt(sum(x6^2*p6)-sum(x6*p6)^2)

```


1. Donny Dont says that C represents the smallest SD, since there is no variability in the heights of the bars. Do you agree that C represents "no variability? Explain.
1. What is the smallest *possible* value the SD of quiz scores could be?  What would need to be true about the distribution for this to happen? (This scenario might not be represented by one the plots.)
1. Without doing any calculations, arrange the classes in order based on their SDs from smallest to largest.  
1. In one of the classes, the SD of quiz scores is 5.  Which one?  Why?
1. Is the SD in F greater than, less than, or equal to 1?  Why?
1. Provide a ballpark estimate of SD in each case.


```{solution sd-matching-sol}
to Example \@ref(exm:sd-matching)
```

```{asis, fold.chunk = TRUE}

1. We disagree with Donny.
SD measures variability of the *values of the variable*, not their probabilities.
If we were to simulate values according to the distribution in C, we would observe some 0s, some 1s, some 2s, all the way through some 10s (with roughly equal frequency).
So there would certainly be variability in the values of the variable.
Remember that values of the variable are along the horizontal axis, so SD measures average distance from the mean horizontally.
1. The smallest possible value of SD is 0, which occurs only if the random variable is a constant (with probability 1).  In this context, if every student had the same quiz score, e.g., if 100\% of students scored an 8, then the SD would be 0.
The distribution plot would have a single spike at a single value.
1. Remember that values of the variable are along the horizontal axis, so SD measures average distance from the mean horizontally.  The distribution in F represents the smallest SD.  The mean is 7, most of the scores are 7, and some of the scores are only 1 unit of from the mean. In all other situations, the probability that the random variable is equal to its mean is smaller, and the probability that the random variables takes a value more than 1 unit away from its mean is larger than in F. Also, in all other situations the mean is 5, so the smallest SD occurs where the values tend to be close to 5, and the largest occurs where the values tend to be far from 5.  In order from smallest to largest SD: F, E, A, C, B, D.
1. D. In D, the score takes values 0  and 10 with probability 0.5.  The mean is 5, and all deviations are 5 units away from the mean, so the SD will be 5.
1. Less than 1.  Don't forget that there is a high probability of a deviation of 0 in this case.  So the average deviation will be somewhere between 0 and 1.
1.  Some of these are harder than others.  In E, many values are 0 units away from mean, many values are 1 unit away, and some values are 2.  So the SD in E is maybe around 1.  In C, there are values that are 0 units away, and about as many values that are each 1, 2, 3, 4, and 5 units away; we might expect SD to be around 2.5.
But remember, while considering average distance helps intuition, SD is the square root of the average squared distance^[It can be shown that $\E(|X-\E(X)|)\le \SD(X)$].
    The actual values are: 	F = 0.45, E = 1.15, A = 2.4, C = 3.1, B = 3.7, D = 5.

```

Variance and standard deviation can not be negative. $\Var(X) = 0$ if and only if $X$ is constant with probability 1, i.e., $\IP(X = \E(X)) = 1$.

<!-- You enter a casino with \$1000 and decide to bet black on roulette until you have either won \$1000 (leaving the casino with \$2000 total), or you have lost all your money (leaving with \$0).  Which of the following is a better strategy for you: bet \$1000  on a single game of roulette, or bet \$1 each time on many games of roulette (until hitting either \$2000 or \$0)?  Why? -->

<!-- If we bet \$1000 on black (in a single bet), what is the expected value of our net profit?  The standard deviation?  -->

```{example, exponential-sd}
Let $X$ have an Exponential(1) distribution.  Make a ballpark estimate for $\SD(X)$, and then compute it.

```


```{solution exponential-sd-sol}
to Example \@ref(exm:exponential-sd)
```

```{asis, fold.chunk = TRUE}

It's hard to make an estimate since $X$ is continuous and the distribution is asymmetric, but we should at least get an idea of what might be a reasonable value.  The mean is 1.  The highest density occurs near 0, where values are about 1 unit away from the mean. But there is a high percentage of values that are less than 1 unit away from the mean.  While there can be some extreme values, most of the values of $X$ are at most 4, so at most 3 units above the mean.  We might guess a SD of around 1.  In particular, a guess of 2 would seem too high, since the only values that are more than 2 SDs above the mean are the $X$ values that are greater than 3, and this is a relatively small percentage of values.  A guess too close to 0 would be unreasonable because of the high density near 0 of values that are 1 unit below the mean.

We did all the hard work already: in Example \@ref(exm:exponential-ev) we found $\E(X) = 1$ and in Example \@ref(exm:exponential-lotus) we found $\E(X^2) = 1$.  Therefore, $\Var(X) = \E(X^2) - \E(X)^2 = 2 - (1)^2 = 1$ and $\SD(X) = 1$.

```

```{python}

X = RV(Exponential(1))

X.sim(10000).sd()

```




### Standardization

Standard deviation provides a "ruler" by which we can judge a particular realized value of a random variable relative to the distribution of values.  This idea is particularly useful when comparing random variables with different measurement units but whose distributions have *similar shapes*.

Recall Example \@ref(exm:sat-z-score) where we assumed SAT scores have, approximately, a Normal distribution with a mean of 1050 and a standard deviation of 200, and ACT scores have, approximately, a Normal distribution with a mean of 21 and a standard deviation of 5.5.  Darius's score of 1500 on the SAT was 2.25 standard deviations above the mean, relatively better than Alfred's score of 31 on the ACT which was 1.82 above the mean.

```{r, sat-z-score-plot-again, ref.label='sat-z-score-plot', echo=FALSE, fig.cap="(ref:cap-sat-z-score-plot)", fig.width=8}

```


Consider the plot for SAT scores in Figure \@ref(fig:sat-z-score-plot-again). There are two scales on the variable axis: one representing the actual measurement units, and one representing "standardized units".  In the standardized scale, values are measured in terms of standard deviations away from the mean:

- The mean corresponds to a value of 0.
- A one unit increment on the standardized scale corresponds to an increment equal to the standard deviation in the measurement unit scale.

For example, each one unit increment in the standardized scale corresponds to a 200 point increment in the measurement unit scale for SAT scores, and a 5.5 point increment in the measurement unit scale for ACT scores.  An SAT score of 1250 is "1 standard deviation above the mean"; an ACT score of 10 is "2 standard deviations below the mean. Given a distribution, the more standard deviations a particular value is away from its mean, the more extreme or "unusual" it is.

```{definition, z-score}

If $X$ is a random variable with expected value $\E(X)$ and standard deviation $\SD(X)$, then the **standardized random variable** is
\[
Z = \frac{X - \E(X)}{\SD(X)}
\]

```

For each outcome $\omega$, the standardized value $Z(\omega)$ measures how far the value $X(\omega)$ is away from the expected value relative to the degree of variability of values of the random variable. The random variable $X$ itself is measured in measurement units (feet, inches, dollars, etc), and the standardized random variable $Z$ is measured in standardized units --- "standard deviations away from the mean".

Standardization --- that is, subtracting the mean and dividing by the standard deviation --- is a linear rescaling.  Therefore, the shape of the distribution of the standardized random variable will be the same as the shape of the distribution of the original random variable. However, the possible values will be different, and so will the mean and standard deviation. Regardless of the original measurement units, a standardized random variable has mean 0 and standard deviation 1.


However, keep in mind that comparing standardized values is most appropriate for distributions that have *similar shapes*.

```{example dd-z-score}

For which distribution --- Uniform(0, 1) or Exponential(1) --- is it more unsual to see a value smaller than 0.15?

```

1. Standardize the value 0.15 relative to the Uniform(0, 1) distribution.
1. Standardize the value 0.15 relative to the Exponential(1) distribution.
1. Donny Dont says: "For the Uniform(0, 1) distribution, a value of 0.15 is 1.2 standard deviations below the mean.  For the Exponential(1) distribution, a value of 0.15 is 0.85 standard deviations below the mean.  So a value smaller than 0.15 is more unusual for a Uniform(0, 1) distribution, since there it's more standard deviations below the mean."  Do you agree with his conclusion?  Explain.
1. How can you answer the original question in the setup?
1. The value 0.15 is what percentile for a Uniform(0, 1) distribution?
1. The value 0.15 is what percentile for an Exponential(1) distribution?
1. For which distribution --- Uniform(0, 1) or Exponential(1) --- is it more unsual to see a value smaller than 0.15?


```{solution dd-z-score-sol}
to Example \@ref(exm:dd-z-score)
```

```{asis, fold.chunk = TRUE}

1. The mean of the Uniform(0, 1) distribution is 0.5, and the standard deviation is $1/\sqrt{12}\approx 0.289$. (See Example \@ref(exm:uniform-sd).) The standardized value for 0.15 is $(0.15 - 0.5)/(1/\sqrt{12})\approx -1.2$.  Relative to the Uniform(0, 1) distribution, a value of 0.15 is about 1.2 SDs below the mean.
1. The mean of the Exponential(1) distribution is 1, and the standard deviation is 1. (See Example \@ref(exm:exponential-sd).) The standardized value for 0.15 is $(0.15 - 1)/1 = -0.85$.  Relative to the Exponential(1) distribution, a value of 0.15 is 0.85 SDs below the mean.
1. Donny's statements about the standardized values are fine, but his conclusion is not.  The distributions here have different shapes, so for example, 1 SD below the mean does not correspond to the same percentile for the two distributions.
1. We can see what percentile a value of 0.15 represents for each distribution.
1. The Uniform(0, 1) cdf is $F(x) = x, 0<x<1$, so $F(0.15) = 0.15$.  For the Uniform(0, 1) distribution, the probability of a value smaller than 0.15 is 0.15; 0.15 is the 15th percentile.
1. The Exponential(1) cdf is $F(x) = 1-e^{-x}, x>0$, so $F(0.15) = 1-e^{-0.15} \approx 0.14$.  For the Exponential(1) distribution, the probability of a value smaller than 0.15 is 0.14; 0.15 is the 14th percentile.
1. While it's close, it is a little less likely to see a value smaller than 0.15 for the Exponential(1) distribution than for the Uniform(0, 1) distribution.  Notice that this is true despite the fact that the standardized value for 0.15 is more standard deviations below the mean for the Uniform(0, 1) distribution than for the Exponential(1) distribution.  

``` 

Standardization is useful when comparing random variables with different measurement units but whose distributions have similar shapes.  However, standardized values are only based on two features of a distribution --- mean and standard deviation --- rather than the complete pattern of variability.  Distributions with different shapes have different patterns of variability. Therefore, when comparing distributions with different shapes, it is better to compare percentiles rather than standardized values to determine what is "extreme" or "unusual".

See Figure \@ref(fig:dd-z-score-plot) for an illustration.  The figure displays the cdf of each of the Normal(0, 1), Exponential(1), and Uniform(0, 1) distributions *as a function of standardized values*.  Notice how the standardized values correspond to different percentiles for the three distributions. In particular, a standardized value of 0 corresponds to the median for the Normal(0, 1) and Uniform(0, 1) distributions, but it represents the 63rd percentile for the Exponential(1) distribution.  For another example, a standardized value of $-0.95$ corresponds to:

- a value of $-0.95$ from the Normal(0, 1) distribution, which is about the 17th percentile
- a value of $1-0.95(1) = 0.05$ from the Exponential(1) distribution, which is about the 5th percentile
- a value of $0.5-0.95(1/\sqrt{12}) = 0.226$ from the Uniform(0, 1) distribution, which is about the 23rd percentile.

Among these three distributions, a value 0.95 SDs below the mean is most extreme for the Exponential(1) distribution and least extreme for the Uniform(0, 1) distribution.
<!-- As another example, a standardized value of $0.5$ corresponds to: -->

<!-- - a value of $0.5$ from the Normal(0, 1) distribution, which is about the 69th percentile -->
<!-- - a value of $1+0.5(1) = 1.5$ from the Exponential(1) distribution, which is about the 77th percentile -->
<!-- - a value of $0.5+0.5(1/\sqrt12) = 0.644$ from the Uniform(0, 1) distribution, which is about the 64th percentile. -->


<!-- Among these three distributions, a value 0.5 SDs above the mean is most extreme for the Uniform(0, 1) distribution and least extreme for the Uniform(0, 1) distribution. -->

(ref:dd-sat-z-score-plot) Comparison of cdf, as a function of standardized value, for the Normal(0, 1), Exponential(1), and Uniform(0, 1) distributions.

```{r, dd-z-score-plot, echo=FALSE, fig.cap="(ref:dd-sat-z-score-plot)"}


za = seq(-3, 3, 0.5)
z = seq(-3, 3, 0.001)

plot(z, pnorm(z), xlim = range(z), ylim = c(0, 1), type = "l",
     xaxt = "n", ylab = "", xlab = "",
     lty = 1, lwd = 2, col = "skyblue")
par(new = T)
plot(z, pexp(1 + z, 1), xlim = range(z), ylim = c(0, 1), type = "l",
     xaxt = "n", ylab = "", xlab = "",
     lty = 2, lwd = 2, col = "orange")
par(new = T)
plot(z, punif(0.5 + z / sqrt(12), 0, 1), type = "l",
     xaxt = "n", ylab = "cdf (as function of standardized value)",
     xlab="standardized value",
     xlim = range(z), ylim = c(0, 1),
     lty = 3, lwd = 2, col = "seagreen")
axis(1, za)
abline(v = c(-0.95, 0), lty = 1, lwd = 1, col = "gray")
legend("topleft",
       c("Normal(0, 1)", "Exponential(1)", "Uniform(0, 1)"),
       col = c("skyblue", "orange", "seagreen"), lwd = 2, lty = 1:3)

```


Any random variable can be standardized, but keep in mind that just how extreme any particular standardized value is depends on the shape of the distribution.  In general, standardization is most natural for random variables that follow a Normal distribution, where percentiles follow the empirical rule discussed in Section \@ref(sec-empirical-rule).

### Probability inequalitlies


The distribution of a random variable is a complete description of its pattern of variability.  Knowing the distribution of  a random variable allows you to compute the probability of any event involving it, but the full distribution is often unavailable or difficult to obtain.  However, certain summary characteristics, like the mean or standard deviation, might be available.  What can we say about a distribution based on only information about its mean or standard deviation?

#### Markov's inequality {#markov-inequality}

```{example, markov-income}

According to 2019 data from the [U.S. Census Bureau](https://www.census.gov/data/tables/time-series/demo/income-poverty/cps-hinc/hinc-01.2019.html), the mean^[The mean is closer to \$98,000 but we're rounding to simplify a little. It is often more appropriate to consider median income, rather than mean income.  The median annual income for U.S. households in 2019 was about \$69,000.] annual income for U.S. households is about \$100,000.
Suppose that you know nothing else about the distribution of income, other than income can't be negative. What can you say about the percent of households with incomes of at least \$1 million?

```

1. Can 100% of households have income of at least \$1 million?
1. Can 50% of households have income of at least \$1 million?
1. What is the largest possible percentage of households with incomes of at least \$1 million?


```{solution markov-income-sol}
to Example \@ref(exm:markov-income)
```

```{asis, fold.chunk = TRUE}

1. No, if 100\% of households have incomes of least 1 million, then the mean must be at least 1 million.  If every household had an income of exactly 1 million, then the mean would be 1 million.  
1. No, if 50\% of households have incomes of at least 1 million, then the mean must be at least 500,000.  Even if 50% of households have incomes of exactly 1 million and the rest have incomes of 0 (the smallest possible value), the mean would be 500,000.
1. The idea is that if too many households have incomes above 1 million then the average can't be 100,000. Classify each household as either having an income of at least 1 million or not.  The mean will be smallest in the extreme case where each household has an income of either 1 million or 0; allowing other values will just pull the mean up.  In this extreme scenario, let $p$ be the  proportion of households with an income of 1 million.  Then the mean is $1000000p + 0(1-p) = 1000000p$, and setting it equal to 100000 yields $p=0.1$.  Therefore, given a mean of \$100,000 it is theoretically possible for 10\% of households to have incomes of at least \$1 million.  But 10\% is the maximum possible percentage; if more than 10\% of households have incomes above \$1 million, than the mean would be strictly greater than \$100,000.
    Knowing only that the mean is 100,000, all we can say is that between 0% and 10% of households have incomes of at least \$1 million.

```

The scenario corresponding to 10\% in the previous example is hypothetical, and in reality far fewer than 10\% of U.S. households have incomes of at least \$1 million.  (Only about 10\% of households have incomes above \$200,000, so the percentage of households with incomes above \$1 million is much smaller than 10\%.) However, the scenario is theoretically possible so we must account for it. We can't do any better based on knowing just the mean alone without any additional information about the distribution of incomes.

The previous example illustrates *Markov's inequality.*

```{theorem, markov, name = "Markov\'s inequality"}
For any random variable $X$ and any constant $c>0$
\[
\IP(|X|\ge c) \le \frac{\E(|X|)}{c}.
\]
In particular, if $\IP(X\ge0)=1$ then $\IP(X > c) \le \E(X)/c$.

```


The idea behind Markov's inequality is that large values pull the mean up, so given a fixed value of the mean there is a limit on the probability that the random variable takes large values. The proof uses the same strategy as Example \@ref(exm:markov-income). Each value of $|X|$ is either at least $c$ or not.  Consider the extreme situation where each value of $|X|$ is either $c$ or 0. That is, define the random variable $Y=c\ind\{|X|\ge c\}$. Then $|X|\ge Y$; if $|X|\ge c$ then $Y=c$; if $|X|<c$ then $Y=0$.
Therefore $\E(|X|)\ge \E(Y)$ and 
\[
\E(|X|)\ge\E(Y) = \E(c\ind\{|X|\ge c\}) = c\IP(|X| \ge c).
\]
Divide by $c>0$ to get the result.


Think of $c$ as a large value in the measurement units of the random variable, so Markov's inequality provides a very crude upper bound on the probability that $X$ takes extreme values in the absolute sense.  Probabilities like $\IP(|X| \ge c)$ are called "tail probabilities" because they depend on the "tail" of the distribution which describes the pattern of variability for extreme values.

We can also express Markov's inequality in relative terms.  If $X\ge 0$, then for any constant $k$
\[
\IP(X \ge k \E(X)) \le \frac{\E(X)}{k\E(X)} = \frac{1}{k} 
\]
Think of $k$ as a multiplier: what is the probability that the random variable takes a value at least $k$ *times* larger than the average value? Markov's inequality says that at most $1/k$ of values are at least $k$ times greater than the mean.  For example, at most 1/2 of values are at least 2 times as large as the mean; at most 1/3 of values are at least 3 times as large as the mean; etc.


```{example, markov-compare}

Suppose $X$ is a random variable with an Exponential(1) distribution.  What does Markov's inequality say about $\IP(X > 5)$?  How does this compare to the true probability?

```


```{solution markov-compare-sol}
to Example \@ref(exm:markov-compare)
```


```{asis, fold.chunk = TRUE}

The mean of an Exponential(1) distribution is 1, so Markov's inequality says 
\[
\IP(X\ge 5) \le \frac{\E(X)}{5} = \frac{1}{5} = 0.2.
\]
The true probability is $e^{-5}\approx 0.0067$.  The true probability is about 30 times smaller than the bound provided by Markov's inequality.  Markov's inequality only uses the fact the mean is 1; it provides a bound that works for any distribution with a mean of 1.  But it is not guaranteed to work well for any particular distribution.

```


The upper bound provided by Markov's inequality often grossly overestimates the tail probability.  However, without further information, we cannot rule out the extreme but theoretically possible case in which the tail probability $\IP(|X|\ge c)$ is equal to the upper bound $\E(|X|)/c$.  Markov's inequality provides a bound that works for any distribution with a given mean, but it is not guaranteed to work well for any particular distribution.

If the upper bound is so bad, how is Markov's inequality useful? Think of reading a news article involving some numerical variable.  The article might mention the mean, but have you ever read a news article that mentions the standard deviation?  At best, you might get a range of "typical" values, maybe a percentile or two, or a graph if you're really lucky.  But in many situations, the mean might be all that is available, and Markov's inequality at least tells you something about the distribution based on the mean alone (even if it doesn't tell you much).


#### Chebyshev's inequality

Markov's inequality only relies on the mean, but it provides very rough bounds on tail probabilities.  If we have more information, then we can do better.  In particular, if we also know the standard deviation --- which describes the overall degree of variability --- then we can put better bounds on the probability that a random variable takes a value far from its mean.




```{theorem, chebyshev, name = "Chebyshev\'s inequality"}

For any random variable $X$ and any constant $c>0$

\[
\IP\left(|X-\E(X)|\ge c\right)\le \frac{\Var(X)}{c^2}.
\]

Equivalently, for any constant $z>0$,
\[
\IP\left(\frac{|X-\E(X)|}{\SD(X)}\ge z\right)\le \frac{1}{z^2}.
\]

```
  
The first version of Chebyshev's inequality bounds the probability
that a random variable is at least $c$ *measurement units* away from its mean.  The proof is an application of Markov's inequality to the squared deviation random variable $|X-\E(X)|^2$:
\[
\IP\left(|X-\E(X)|\ge c\right) = \IP\left(|X-\E(X)|^2\ge c^2\right) \le \frac{\E\left(|X-\E(X)|^2\right)}{c^2}=  \frac{\Var(X)}{c^2}.
\]


```{example, chebyshev-income}

Continuing Example \@ref(exm:markov-income), suppose again that average annual income for U.S. households is about \$100,000. Now assume the standard deviation of income is about \$230,000.
What can you say about the percent of households with incomes of at least \$1 million?

```

```{asis, fold.chunk = TRUE}

We first need to relate the probability of interest to one that is of the form^[The form we have stated bounds the probability that $X$ is far away from the mean.  There are also one-sided Chebyshev's inequalities that bound the probability that $X$ is far above (or below) its mean. If we recognize that $X$ in this example can't be 900000 units below its mean, a one-sided Chebyshev's inequality yields a bound of $(1/(1+900000/230000))^2\approx 0.042$.] in Chebyshev's inequality. An income of 1 million is 900,000 dollars above the mean of 100,000.

\[
\IP\left(X \ge 1000000\right) = \IP\left(X-100000\ge 900000\right) \le \IP\left(|X-100000|\ge 900000\right).
\]
Now use Chebyshev's inequality with $c=900000$, $\E(X) = 100000$, and $\Var(X) = 230000^2$.
\[
\IP\left(X \ge 1000000\right) \le  \IP\left(|X-100000|\ge 900000\right)\le \frac{230000^2}{900000^2} = 0.065.
\]

Alternatively, a value of 1000000 is $z=(1000000 - 100000) / 230000 = 3.91$ SDs above the mean, so the probability that the standardized random variable is at least 3.91 is less than $1/3.91^2\approx 0.065$.

With information about the mean and standard deviation, we can say that at most 6.5\% of households have income above \$1 million.  This is still probably a vast overestimate, but it does improve on the bound of 10\% from Markov's inequality.

```

The bound in Markov's inequality is on the order of $1/c$ and the bound in Chebyshev's inequality is on the order of $1/c^2$.  Therefore, Chebyshev's inequality usually provides a tighter bound, but you need to know the standard deviation in order to use it.


The second version of Chebyshev's inequality follows by taking $c = z\SD(X)$ in the first version. The second version bounds the probability that a random variable
is at least $z$ *standard deviations* away from its mean.  Chebyshev's inequality says that for *any* distribution, the probability that the random variable takes a value within $z$ SDs of its mean is at least $1 - 1 / z^2$.  For *any* distribution,

- ($z = 2$.) *At least* 75% of values fall within 2 standard deviations of the mean.
- ($z = 3$.) *At least* 88.9% of values fall within 3 standard deviations of the mean.
- ($z = 4$.) *At least* 93.75% of values fall within 4 standard deviations of the mean.
- ($z = 5$.) *At least* 96% of values fall within 5 standard deviations of the mean.
- ($z = 6$.) *At least* 97.2\% of values fall within 6 standard deviations of the mean.
- and so on, for different values of $z$.


The complementary probabilities: For *any* distribution,

- ($z = 2$.) *At most* 25% of values fall more than 2 standard deviations away from the mean.
- ($z = 3$.) *At most* 11.1% of values fall more than 3 standard deviations away from the mean.
- ($z = 4$.) *At most* 6.25% of values fall more than 4 standard deviations away from the mean.
- ($z = 5$.) *At most* 4% of values fall more than 5 standard deviations away from the mean.
- ($z = 6$.) *At most* 2.8% of values fall more than 6 standard deviations away from the mean.
- and so on, for different values of $z$.

This universal "empirical rule" works for any distribution, but will tend to be very conservative when applied to any particular distribution.

In short, Chebyshev's inequality says that if a value is more than a few standard deviations away from the mean then it is a fairly extreme value, regardless of the shape of the distribution.


```{example, chebyshev-compare}
Let $X$ be a random variable with an Exponential(1) distribution.
What does Chebyshev's inequality say about $\IP(X > 5)$?  How does this compare to the bound from Markov's inequality? To the true probability?
  
```


```{solution chebyshev-compare-sol}
to Example \@ref(exm:chebyshev-compare)
```


```{asis, fold.chunk = TRUE}

Both the mean and the standard deviation of an Exponential(1) distribution are 1.  A value of 5 is $(5-1)/1=4$ units above the mean.  Chebyshev's inequality says that the probability that a value is at least 4 units away from the mean is at most $1/4^2 = 0.0625$.  This bound is 3 times smaller than 0.2, the bound from Markov's inequality.  It's still not close to the true probability of $0.0067$, but at least it's an improvement over Markov's inequality. 

```




Another situation where bounds like Markov's or Chebyshev's inequality are useful is in proofs.  Many theorems in probability consider what happens in the long run.  For example, various results say certain probabilities approach 0 in the long run.  (The law of large numbers is of this form.) To prove such theorems, you don't necessarily need to compute the probabilities to show they approach 0.  It is enough to show that some rough upper bound on the probability converges to 0.





## Covariance and correlation 


Quantities like expected value and variance summarize characteristics of the *marginal* distribution of a single random variable. When there are multiple random variables their *joint* distribution is of interest.  Covariance summarizes in a single number a characteristic of the joint distribution of two random variables, namely, the degree to which they "co-deviate from the their respective means".

Recall Section \@ref(sec-sim-corr) where we saw that **covariance** of random variables $X$ and $Y$ is the long run average of the product of the paired deviations from the respective means

$$
\text{Covariance($X$, $Y$)} = \text{Average of} ((X - \text{Average of }X)(Y - \text{Average of }Y))
$$
It turns out that covariance is equivalent to the average of the product minus the product of the averages.

$$
\text{Covariance($X$, $Y$)} = \text{Average of} XY  - (\text{Average of }X)(\text{Average of }Y)
$$

Translating the long run averages into expected values yields the following definition.

```{definition, covariance}
The **covariance** between two random variables $X$ and $Y$ is
\begin{align*}
\Cov(X,Y) & = \E\left[\left(X-\E[X]\right)\left(Y-\E[Y]\right)\right]\\
& = \E(XY) - \E(X)\E(Y)
\end{align*}

```

The first line above defines covariance as the long run average product of paired deviations from the mean.  The second provides an equivalent formula that simplifies computation.  Namely, covariance is the expected value of the product minus the product of expected values.  (Remember that in general $\E(XY)$ is not equal to $\E(X)\E(Y)$.)







```{example, dice-covariance22}
Consider the probability space corresponding to two rolls of a fair four-sided die.  Let $X$ be the sum of the two rolls, $Y$ the larger of the two rolls, $W$ the number of rolls equal to 4, and $Z$ the number of rolls equal to 1.

``` 

1. Specify the joint pmf of $X$ and $Y$. (These first few parts are review of things we have covered before.)
1. Find the marginal pmf of $X$ and $\E(X)$.
1. Find the marginal pmf of $Y$ and $\E(Y)$.
1. Find $\E(XY)$.  Is it equal to $\E(X)\E(Y)$?
1. Find $\Cov(X, Y)$.  Why is the covariance positive?
1. Is $\Cov(X, W)$ positive, negative, or zero? Why?
1. Is $\Cov(X, Z)$ positive, negative, or zero? Why?
1. Let $V=W+Z$. Is $\Cov(X, V)$ positive, negative, or zero? Why?
1. Is $\Cov(W, Z)$ positive, negative, or zero? Why?


```{solution dice-covariance22-sol}
to Example \@ref(exm:dice-covariance22)
```

```{asis, fold.chunk = TRUE}

1. See Example \@ref(exm:dice-probspace) for the joint and marginal distributions.
1. $\E(X)= 5$.
1. $\E(Y) = 1(1/16) + 2(3/16) + 3(5/16) + 4(7/16) = 3.125$.
1. $\E(XY)=(2)(1)(1/16) + (3)(2)(2/16) + \cdots (8)(4)(1/16) = 16.875$.  This is not equal to  $\E(X)\E(Y) = (5)(3.125) = 15.625.$
1. $\Cov(X, Y) = \E(XY) -  \E(X)\E(Y) = 16.875 - 15.625 = 1.25.$  There is an overall positive association; above average values of $X$ tend to be associated with above average values of $Y$ (e.g., (7, 4), (8, 4)), and below average values of $X$ tend to be associated with below average values of $Y$ (e.g., (2, 1), (3, 2)).
1. $\Cov(X, W)>0$.  If $W$ is large (roll many 4s) then $X$ (sum) tends to be large.
1. $\Cov(X, Z)<0$.  If $Z$ is large (roll many 1s) then $X$ (sum) tends to be small.
1. $\Cov(X, W + Z)=0$. Basically, the positive association between $X$ and $W$ cancels out with the negative association of $X$ and $Z$.  $V$ is large when there are many 1s or many 4s, or some mixture of 1s and 4s.
So knowing that W is large doesn't really tell you anything about the sum.
1. $\Cov(W, Z)<0$.  There is a fixed number of rolls.  If you roll lots of 4s ($W$ is large) then there must be few rolls of 1s ($Z$ is small).



```

The sign of the covariance indicates the overall direction of the association between $X$ and $Y$.

- $\Cov(X,Y)>0$ (positive association): above average values of $X$ tend to be associated with above average values of $Y$
- $\Cov(X,Y)<0$ (negative association): above average values of $X$ tend to be associated with below average values of $Y$
- $\Cov(X,Y)=0$  indicates that the random variables are  **uncorrelated**: there is no overall positive or negative association. But be careful: if $X$ and $Y$ are  uncorrelated there can still be a relationship between $X$ and $Y$; there is just no overall positive or negative association.. We will see examples that demonstrate that being uncorrelated does not necessarily imply that random variables are independent.





```{example, dd-dice-covariance-sim}
In Example \@ref(exm:dice-covariance), how could we use simulation to approximate $\Cov(X, Y)$?  Donny Dont's Symbulate code is below.   Explain to Donny in words the correct simulation process, and why his  code does not reflect that process.  What is the correct code? 

```


```{python, eval = FALSE}

P = DiscreteUniform(1, 4) ** 2
X = RV(P, sum)
Y = RV(P, max)

x = X.sim(10000)
y = Y.sim(10000)

(x * y).mean() - x.mean() * y.mean()

```


```{solution dd-dice-covariance-sim-sol}
to Example \@ref(exm:dd-dice-covariance-sim)
```

```{asis, fold.chunk = TRUE}

Donny's code attempts to simulate values of $X$ and values of $Y$ separately, from each of their marginal distributions.  However, to approximate the covariance we need to simulate $(X, Y)$ *pairs* from the *joint* distribution.  See the code below. (Otherwise, Donny's code is fine.)

```


Since $\Cov(X, Y)$ is based on expected values, it can be approximated by simulating appropriate long run averages.

- Simulate an $(X, Y)$ *pair* from the *joint* distribution.
- Find the value of the product $XY$ for the simulated pair.
- Repeat many times, simulating many $(X, Y)$ pairs and finding their product $XY$.
- Average the simulated values of the product $XY$ to approximate $\E(XY)$.
- Average the simulated values of $X$ to approximate $\E(X)$.
- Average the simulated values of $Y$ to approximate $\E(Y)$.
- $\Cov(X, Y)$ is approximately the average of the product minus the product of the averages.

The following code illustrates how to approximate covariance via simulation in the context of the previous example.  The key is to first simulate $(X, Y)$ pairs with the proper joint distribution.

<!-- Why is this causing an error when it runs? -->

```{python, eval = FALSE}

P = DiscreteUniform(1, 4) ** 2
X = RV(P, sum)
Y = RV(P, max)

xy = (X & Y).sim(10000)

xy

```

```{python, eval = TRUE, echo = FALSE}

U1, U2 = RV(DiscreteUniform(1, 4) ** 2)

X = U1 + U2
Y = (U1 & U2).apply(max)

xy = (X & Y).sim(10000)

xy

```


```{python, eval = TRUE}
plt.figure()
xy.plot('tile')
plt.show()

```

The simulated $(X, Y)$ pairs are stored as `xy`, a matrix with two columns (one for $X$ and one for $Y$) and a row for each repetition of the simulation.  The simulated $X$ values in the first column of `xy` can be extracted with `x = xy[0]`.  (Remember Python's zero-based indexing.) The simulated $Y$ values in the second column of `xy` can be extracted with `y = xy[1]`.  The product `x * y` will multiply $XY$ for each simulated $(X, Y)$ pair, row by row.


```{python, eval = TRUE}

x = xy[0]
y = xy[1]

x * y

```

We can then approximate the covariance with the average of the product minus the product of the averages.

```{python, eval = TRUE}

(x * y).mean() - x.mean() * y.mean()

```

The `.cov()` command performs the above calculation.

```{python, eval = TRUE}

xy.cov()

```


```{example}
Recall Example \@ref(sim-transform-joint).  Spin the Uniform(1, 4) spinner twice and let $X$ be the sum and $Y$ the larger of the two spins.  Sketch a plot of the joint distribution; is $\Cov(X, Y)$ positive, negative, or zero?  Then use simulation to approximate the covariance.
  
```

```{asis, fold.chunk = TRUE}

Covariance is positive as above average values of $X$ tend to be associated with above average values of $Y$.  Simulation show the covariance is about 0.75.

```


<!-- Why is the following code causing an error when it runs? -->

```{python, eval = FALSE}

P = Uniform(1, 4) ** 2
X = RV(P, sum)
Y = RV(P, max)

xy = (X & Y).sim(10000)

plt.figure()
xy.plot('density')
plt.show()

```

```{python, eval = TRUE, echo = FALSE}

P = Uniform(1, 4) ** 2

U1, U2 = RV(P)

X = U1 + U2
Y = (U1 & U2).apply(max)

xy = (X & Y).sim(10000)

plt.figure()
xy.plot('density')
plt.show()

```


```{python, eval = TRUE}
xy.cov()
```



For two continuous random variables, $\E(XY)$ involves a double integral over possible $(x, y)$ pairs of the product $xy$ weighted by the joint density.  We will see later some strategies for computing $\E(XY)$ and $\Cov(X, Y)$ that avoid double integration.


```{example}
What is another name for $\Cov(X, X)$?
```


```{asis, fold.chunk = TRUE}
The variance of $X$ is the covariance of $X$ with itself.
\[
 \Cov(X, X) = \E\left((X-\E(X))(X-\E(X))\right) 
  = \E\left((X-\E(X))^2\right) = \Var(X)
\]
```

### Correlation

```{example}

The covariance between height in inches and weight in pounds for football players is 96.

```

1. What are the measurement units of the covariance?
1. Suppose height were measured in feet instead of inches. Would the shape of the joint distribution change?  Would the strength of the association between height and weight change?  Would the value of covariance change?

```{asis, fold.chunk = TRUE}

1. Covariance deals with products, so the covariance is 96 inches$\times$pounds.
1. A linear rescaling does not change the shape of the distribution or the strength of the association. However, a linear rescaling does relabel the axis and change measurement units.  A covariance of 96 inches$\times$pounds corresponds to a covariance of 8 feet$\times$pounds.

```

The numerical value of the covariance depends on the measurement units of both variables, so interpreting it can be difficult. Covariance is a measure of joint association between two
random variables that has many nice theoretical properties, but the *correlation
coefficient* is often a more practical measure. (We saw a similar idea with variance and standard deviation. Variance has many nice theoretical properties. However, standard
deviation is often a better practical measure of variability.)


```{definition, correlation}

The **correlation (coefficient)** between random variables $X$ and $Y$ is

\begin{align*}  
\Corr(X,Y) & = \Cov\left(\frac{X-\E(X)}{\SD(X)},\frac{Y-\E(Y)}{\SD(Y)}\right)\\
& = \frac{\Cov(X, Y)}{\SD(X)\SD(Y)}
\end{align*}
  
```
  
The correlation for two random variables is the covariance between the corresponding standardized random variables.  Therefore, correlation is a *standardized* measure of the association between two random variables.

Subtracting the means doesn't change the scale of the possible pairs of values; it merely shifts the center of the joint distribution. Therefore, correlation is the covariance divided by the product of the standard deviations.


A correlation coefficient has no units and is measured on a universal scale. Regardless of the original measurement units of the random variables $X$ and $Y$
\[
-1\le \textrm{Corr}(X,Y)\le 1
\]

- $\textrm{Corr}(X,Y) = 1$ if and only if $Y=aX+b$ for some $a>0$
- $\textrm{Corr}(X,Y) = -1$ if and only if $Y=aX+b$ for some $a<0$


Therefore, correlation is a standardized measure of the strength of the *linear* association between two random variables.


The following plots display a few Bivariate Normal distributions with different correlations.


```{r bvn-correlation, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Bivariate Normal distributions"}
# | echo: false
# | label: fig-meeting-bivariate-normal
# | fig-cap: "add"
# | fig-alt: "add"


normal_box <- expand_grid(x = seq(-4, 4, 0.1), y = seq(-4, 4, 0.1))

normal_box_prob <- normal_box %>%
  mutate(independent_normal = dnorm(x, 0, 1) * dnorm(y, 0, 1),
         bivariate_normal_positive_corr = dbvn(x, y, 0, 0, 1, 1, 0.7),
         bivariate_normal_negative_corr = dbvn(x, y, 0, 0, 1, 1, -0.9),
         bivariate_normal_weak_corr = dbvn(x, y, 0, 0, 1, 1, 0.5))

normal_box_max_prob = normal_box_prob %>%
  dplyr::select(!(1:2)) %>%
  pivot_longer(cols = everything()) %>%
  summarize(max(value)) %>%
  pull()

bvn_template = ggplot(normal_box_prob,
       aes(x = x,
           y = y)) +
  scale_x_continuous(expand = c(0, 0), limits = c(-2.5, 2.5)) +
  scale_y_continuous(expand = c(0, 0), limits = c(-2.5, 2.5)) +
  scale_fill_viridis(limits = c(0, normal_box_max_prob)) +
  labs(x = "x",
       y = "y",
       fill = "Density") +
  coord_fixed() +
  theme_classic() +
  theme(plot.margin = unit(c(0, -3, 0, -3), "cm"))

ggarrange(
  bvn_template +
    geom_raster(aes(fill = bivariate_normal_positive_corr),
                interpolate = TRUE) +
    geom_contour(aes(z = bivariate_normal_positive_corr),
                 color = "white") +
    ggtitle("Corr(X, Y) = 0.7"),
  bvn_template +
    geom_raster(aes(fill = independent_normal),
                interpolate = TRUE) +
    geom_contour(aes(z = independent_normal),
                 color = "white") +
        ggtitle("Corr(X, Y) = 0"),
  bvn_template +
    geom_raster(aes(fill = bivariate_normal_negative_corr),
                interpolate = TRUE) +
    geom_contour(aes(z = bivariate_normal_negative_corr),
                 color = "white") +
        ggtitle("Corr(X, Y) = -0.9"),
  bvn_template +
    geom_raster(aes(fill = bivariate_normal_weak_corr),
                interpolate = TRUE) +
    geom_contour(aes(z = bivariate_normal_weak_corr),
                 color = "white") +
        ggtitle("Corr(X, Y) = 0.5"),
  common.legend = TRUE,
  legend = "right")


```

```{example}

The covariance between height in inches and weight in pounds for football players is 96.  Heights have mean 74 and SD 3 inches.  Weights have mean 250 pounds and SD 45 pounds.  Find the correlation between weight and height.  

```

```{asis, fold.chunk = TRUE}

\[
 \Corr(X, Y) = \frac{\Cov(X, Y)}{\SD(X)\SD(Y)} = \frac{96}{(3)(45)} = 0.71 
\]

(The means are useful to have, but they don't effect the correlation.)
```


Because correlation is computed between standardized random variables,  correlation is not affected by a linear rescaling of either variable.  One standard deviation above the mean is one standard deviation above the mean, whether that's measured in feet or inches or meters.

In many problems we are given the correlation directly and need to find the covariance. Covariance is the correlation times the product of the standard deviations.

\[
\Cov(X, Y) = \Corr(X, Y)\SD(X)\SD(Y)
\]



### Independent versus uncorrelated

The condition for independence of random variables is fairly strict.  Random variables are independent only if the joint distribution is determined by the product of the marginal distributions for all values of the random variables.  Otherwise, the random variables are not independent.  However, you can imagine that there are different degrees of dependence.  For example, the mosaic plot on the right in Figure \@ref(fig:poisson-hr-mosaic) displays a situation  where $X$ and $Y$ are "not too dependent".

We wish to measure degree of dependence in a single number.  Unfortunately, there are many different ways two random variables can be related, and there is no single measure that works well in all cases.

The most commonly used measure of the degree of an association between two random variables is covariance, or its standardized counterpart, correlation.  While covariance does have many uses and nice properties, it does NOT measure whether two random variables are independent.

```{example, zero-covariance}
Find $\Cov(X,Y)$ in
each of the following situations. Notice that the marginal distribution
of $X$ is the same for each part, and similarly for $Y$.

```

1.
    |            | $p_{X, Y}(x, y)$ |     |     |     |          |
    |-----------:|-----------------:|----:|----:|----:|---------:|
    | $x$ \\ $y$ |                  |  -1 |   0 |   1 | $p_X(x)$ |
    |          0 |                  | 1/6 | 1/6 | 1/6 |      1/2 |
    |          1 |                  | 1/6 | 1/6 | 1/6 |      1/2 |
    |   $p_Y(y)$ |                  | 1/3 | 1/3 | 1/3 |          |

1. 
    |            | $p_{X, Y}(x, y)$ |      |      |      |          |
    |-----------:|-----------------:|-----:|-----:|-----:|---------:|
    | $x$ \\ $y$ |                  |   -1 |    0 |    1 | $p_X(x)$ |
    |          0 |                  | 5/24 | 2/24 | 5/24 |      1/2 |
    |          1 |                  | 3/24 | 6/24 | 3/24 |      1/2 |
    |   $p_Y(y)$ |                  |  1/3 |  1/3 |  1/3 |          |

1. In which of the previous parts are $X$ and $Y$ independent?  Why?

```{solution zero-covarance-sol}
to Example \@ref(exm:zero-covariance)
```

```{asis, fold.chunk = TRUE}

1. $\Cov(X, Y) = \E(XY) - \E(X)\E(Y) = \E(XY)$ since $\E(Y)=0$. $\E(XY) = 0 + (1)(1)(1/6) + (1)(-1)(1/6) = 0$. So the covariance is 0.
1. Again, $\Cov(X, Y) = \E(XY)$ since $\E(Y)=0$. $\E(XY) = 0 + (1)(1)(3/24) + (1)(-1)(3/24) = 0$. So the covariance is 0.
1. $X$ and $Y$ are independent in part 1 because the joint pmf is the product of the marginal pmfs.  However, $X$ and $Y$ in part 2 are not independent even though the covariance is 0.

```

If $X$ and $Y$ are independent then $X$ and $Y$ are uncorrelated, that is, $\Cov(X, Y) = 0$. However, the converse is not true in general: there are many situations in which $\Cov(X, Y) = 0$ but $X$ and $Y$ are not independent. Independence means there is no probabilistic relationship between two random variables. Covariance only measures a particular kind of probabilistic relationship, namely: how closely do the $(X, Y)$ pairs tend to follow a single straight line with non-zero slope?


## Expected values of linear combinations of random variables


Remember that, in general, you cannot interchanging averaging and transformation.
In general, an expected value of a function of random variables is not the function evaluated at the expected values of the random variables.

\begin{align*}
\E(g(X)) & \neq g(\E(X)) & & \text{for most functions $g$}\\
\E(g(X, Y)) & \neq g(\E(X), \E(Y)) & & \text{for most functions $g$}
\end{align*}

But there are some functions, namely linear functions, for which an expected value of the transformation is the transformation evaluated at the expected values.
In this section, we will study "linearity of expected value" and applications.
We will also investigate variance of linear transformations of random variables, and in particular, the role that covariance plays.

### Linear rescaling


A linear rescaling is a transformation of the form $g(u) = au + b$. Recall that in Section \@ref(linear-rescaling) we observed, via simulation, that

- A linear rescaling of a random variable does not change the basic shape of its distribution, just the range of possible values.
- A linear rescaling transforms the mean in the same way the individual values are transformed.
- Adding a constant to a random variable does not affect its standard deviation.
- Multiplying a random variable by a constant multiples its standard deviation by the absolute value of the constant.


If $X$ is a random variable and $a, b$ are non-random constants then

\begin{align*}
\E(aX + b) & = a\E(X) + b\\
\SD(aX + b) & = |a|\SD(X)\\
\Var(aX + b) & = a^2\Var(X)
\end{align*}



### Linearity of expected value

```{example}
Spin the Uniform(1, 4) spinner twice and let $U_1$ be the first spin, $U_2$ the second, and $X = U_1 + U_2$ the sum.
```

1. Find $\E(U_1)$ and $\E(U_2)$.
1. Find $\E(X)$.
1. How does $\E(X)$ relate to $\E(U_1)$ and $\E(U_2)$?  Suggest a simpler way of finding $\E(U_1 + U_2)$.

```{asis, fold.chunk = TRUE}

1. $\E(U_1) = \frac{1+4}{2} = 2.5 = \E(U_2)$.
1. We found the pdf of $X$ in Example \@ref(exm:uniform-sum-max-pdf). Since the pdf of $X$ is symmetric about $5$ we should have $\E(X)=5$, which integrating confirms.
    \[
    \E(X) = \int_2^5 x \left((x-2)/9\right)dx + \int_5^8 x \left((8-x)/9\right) dx = 5.
    \]
1. We see that $\E(U_1+U_2) = 5 = 2.5 + 2.5 = \E(U_1) + \E(U_2)$.  Finding the expected value of each of $U_1$ and $U_2$ and adding these two numbers is much easier than finding the pdf of $U_1+U_2$ and then using the definition of expected value.

```

In the previous example, the values $U_1$ and $U_2$ came from separate spins so they were uncorrelated (in fact, they were independent).  What about the expected value of $X+Y$ when $X$ and $Y$ are correlated?



```{example sat-compare-ev}
Consider the three scenarios depicted in the tables and plots below.
Each scenario contains SAT Math ($X$) and Reading ($Y$) scores for 10 hypothetical students, along with the total score ($T  =  X + Y$) and the difference between the Math and Reading scores ($D = X - Y$, negative values indicate lower Math than Reading scores).
Note that the 10 $X$ values are the same in each scenario, and the 10 $Y$ values are the same in each scenario, but the $(X, Y)$ values are paired in different ways: the correlation^[All averages, including those used to compute variance and covariance, are computed by dividing the appropriate sum by 10.] is 0.78 in scenario 1, -0.02 in scenario 2, and -0.94 in scenario 3.

```

1. What is the mean of $T = X + Y$ in each scenario? How does it relate to the means of $X$ and $Y$?
Does the correlation affect the mean of $T = X + Y$?
1. What is the mean of $D = X - Y$ in each scenario? How does it relate to the means of $X$ and $Y$?
Does the correlation affect the mean of $D = X - Y$?


**Scenario 1.**

| Student        |  $X$ | $Y$ |  $T$ | $D$ |
|----------------|-----:|----:|-----:|----:|
| 1              |  520 | 530 | 1050 | -10 |
| 2              |  540 | 470 | 1010 |  70 |
| 3              |  620 | 670 | 1290 | -50 |
| 4              |  620 | 630 | 1250 | -10 |
| 5              |  630 | 600 | 1230 |  30 |
| 6              |  670 | 610 | 1280 |  60 |
| 7              |  700 | 680 | 1380 |  20 |
| 8              |  700 | 580 | 1280 | 120 |
| 9              |  710 | 640 | 1350 |  70 |
| 10             |  760 | 720 | 1480 |  40 |
|                |      |     |      |     |
| Mean           |  647 | 613 | 1260 |  34 |
| SD             |   72 |  70 |  134 |  47 |
| Corr($X$, $Y$) | 0.78 |     |      |     |


```{r, echo = FALSE, fig.show="hold", out.width="33%"}
x = c(520, 540, 620, 620, 630, 670, 700, 700, 710, 760)
y = c(530, 470, 670, 630, 600, 610, 680, 580, 640, 720)

# mean(x)
# mean(y)
# sx = sqrt(mean(x ^ 2) - mean(x) ^ 2); sx
# sy = sqrt(mean(y ^ 2) - mean(y) ^ 2); sy
# (mean(x * y) - mean(x) * mean(y)) / sx / sy
# sqrt(mean((x + y) ^ 2) - mean(x + y) ^ 2)
# sqrt(mean((x - y) ^ 2) - mean(x - y) ^ 2)

plot(x, y,
     xlim = c(500, 800),
     ylim = c(500, 800),
     xlab = "X", ylab = "Y")


ggplot(data.frame(x, y),
       aes(x = x + y ,
           y = 0)) +
  geom_point(shape = "|", size = 10) +
  scale_y_continuous(limits = c(0, 5), expand = c(0, 0)) +
  scale_x_continuous(limits = c(1000, 1500)) +
  theme_classic() +
  coord_fixed() +
  labs(x = "X + Y") +
  theme(axis.text.y=element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y = element_blank()
  )


ggplot(data.frame(x, y),
       aes(x = x - y ,
           y = 0)) +
  geom_point(shape = "|", size = 10) +
  scale_y_continuous(limits = c(0, 5), expand = c(0, 0)) +
  scale_x_continuous(limits = c(-200, 300)) +
  theme_classic() +
  coord_fixed() +
  labs(x = "X - Y") +
  theme(axis.text.y=element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y = element_blank()
  )
```


**Scenario 2.**

| Student        |   $X$ | $Y$ |  $T$ |  $D$ |
|----------------|------:|----:|-----:|-----:|
| 1              |   520 | 680 | 1200 | -160 |
| 2              |   540 | 530 | 1070 |   10 |
| 3              |   620 | 630 | 1250 |  -10 |
| 4              |   620 | 600 | 1220 |   20 |
| 5              |   630 | 720 | 1350 |  -90 |
| 6              |   670 | 470 | 1140 |  200 |
| 7              |   700 | 670 | 1370 |   30 |
| 8              |   700 | 580 | 1280 |  120 |
| 9              |   710 | 640 | 1350 |   70 |
| 10             |   760 | 610 | 1370 |  150 |
|                |       |     |      |      |
| Mean           |   647 | 613 | 1260 |   34 |
| SD             |    72 |  70 |   98 |  103 |
| Corr($X$, $Y$) | -0.04 |     |      |      |

```{r, echo = FALSE, fig.show="hold", out.width="33%"}
y = c(680, 530, 630, 600, 720, 470, 670, 580, 640, 610)

# mean(x)
# mean(y)
# sx = sqrt(mean(x ^ 2) - mean(x) ^ 2); sx
# sy = sqrt(mean(y ^ 2) - mean(y) ^ 2); sy
# (mean(x * y) - mean(x) * mean(y)) / sx / sy
# sqrt(mean((x + y) ^ 2) - mean(x + y) ^ 2)
# sqrt(mean((x - y) ^ 2) - mean(x - y) ^ 2)

plot(x, y,
     xlim = c(500, 800),
     ylim = c(500, 800),
     xlab = "X", ylab = "Y")

ggplot(data.frame(x, y),
       aes(x = x + y ,
           y = 0)) +
  geom_point(shape = "|", size = 10) +
  scale_y_continuous(limits = c(0, 5), expand = c(0, 0)) +
  scale_x_continuous(limits = c(1000, 1500)) +
  theme_classic() +
  coord_fixed() +
  labs(x = "X + Y") +
  theme(axis.text.y=element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y = element_blank()
  )


ggplot(data.frame(x, y),
       aes(x = x - y ,
           y = 0)) +
  geom_point(shape = "|", size = 10) +
  scale_y_continuous(limits = c(0, 5), expand = c(0, 0)) +
  scale_x_continuous(limits = c(-200, 300)) +
  theme_classic() +
  coord_fixed() +
  labs(x = "X - Y") +
  theme(axis.text.y=element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y = element_blank()
  )
```

**Scenario 3.**

| Student        |   $X$ | $Y$ |  $T$ |  $D$ |
|----------------|------:|----:|-----:|-----:|
| 1              |   520 | 720 | 1240 | -200 |
| 2              |   540 | 680 | 1220 | -140 |
| 3              |   620 | 670 | 1290 |  -50 |
| 4              |   620 | 640 | 1260 |  -20 |
| 5              |   630 | 630 | 1260 |    0 |
| 6              |   670 | 610 | 1280 |   60 |
| 7              |   700 | 600 | 1300 |  100 |
| 8              |   700 | 580 | 1280 |  120 |
| 9              |   710 | 530 | 1240 |  180 |
| 10             |   760 | 470 | 1230 |  290 |
|                |       |     |      |      |
| Mean           |   647 | 613 | 1260 |   34 |
| SD             |    72 |  70 |   26 |  140 |
| Corr($X$, $Y$) | -0.94 |     |      |      |


```{r, echo = FALSE, fig.show="hold", out.width="33%"}

y = c(720, 680, 670, 640, 630, 610, 600, 580, 530, 470)

# mean(x)
# mean(y)
# sx = sqrt(mean(x ^ 2) - mean(x) ^ 2); sx
# sy = sqrt(mean(y ^ 2) - mean(y) ^ 2); sy
# (mean(x * y) - mean(x) * mean(y)) / sx / sy
# sqrt(mean((x + y) ^ 2) - mean(x + y) ^ 2)
# sqrt(mean((x - y) ^ 2) - mean(x - y) ^ 2)

plot(x, y,
     xlim = c(500, 800),
     ylim = c(500, 800),
     xlab = "X", ylab = "Y")

ggplot(data.frame(x, y),
       aes(x = x + y ,
           y = 0)) +
  geom_point(shape = "|", size = 10) +
  scale_y_continuous(limits = c(0, 5), expand = c(0, 0)) +
  scale_x_continuous(limits = c(1000, 1500)) +
  theme_classic() +
  coord_fixed() +
  labs(x = "X + Y") +
  theme(axis.text.y=element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y = element_blank()
  )


ggplot(data.frame(x, y),
       aes(x = x - y ,
           y = 0)) +
  geom_point(shape = "|", size = 10) +
  scale_y_continuous(limits = c(0, 5), expand = c(0, 0)) +
  scale_x_continuous(limits = c(-200, 300)) +
  theme_classic() +
  coord_fixed() +
  labs(x = "X - Y") +
  theme(axis.text.y=element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y = element_blank()
  )
```





```{solution sat-compare-ev-sol}
to Example \@ref(exm:sat-compare-ev)
```

```{asis, fold.chunk = TRUE}
1. In each situation, the mean of $X+Y$ is $1260 = 647 + 613$, which is equal to the sum of the means of $X$ and $Y$.
Even though the joint distribution of $(X, Y)$ pairs and the distribution of the sum $X+Y$ are different for each situation, the correlation between $X$ and $Y$ does not affect the average of the $X + Y$. 
1. In each situation, the mean of $X-Y$ is $1260 = 647 - 613 = 34$, which is equal to the difference of the means of $X$ and $Y$.
Even though the joint distribution of $(X, Y)$ pairs and the distribution of the difference $X-Y$ are different for each situation, the correlation between $X$ and $Y$ does not affect the average of the $X - Y$. 


```


**Linearity of expected value.** For *any* two random variables $X$ and $Y$,
\begin{align*}
\E(X + Y) & = \E(X) + \E(Y)
\end{align*}
That is, the expected value of the sum is the sum of expected values, regardless of how the random variables are related.  Therefore, you only need to know the marginal distributions of $X$ and $Y$ to find the expected value of their sum.  (But keep in mind that the *distribution* of $X+Y$ will depend on the joint distribution of $X$ and $Y$.)


Linearity of expected value follows from simple arithmetic properties of numbers. Whether in the short run or the long run,
\begin{align*}
\text{Average of $X + Y$ } & = \text{Average of $X$} + \text{Average of $Y$}
\end{align*}
regardless of the joint distribution of $X$ and $Y$.  For example, for the two $(X, Y)$ pairs (4, 3) and (2, 1)
\[
\text{Average of $X + Y$ } = \frac{(4+3)+(2+1)}{2} = \frac{4+2}{2} + \frac{3+1}{2} = \text{Average of $X$} + \text{Average of $Y$}.
\]
Changing the $(X, Y)$ pairs to (4, 1) and (2, 3) only moves values around in the calculation of the average without affecting the result.
\[
\text{Average of $X + Y$ } = \frac{(4+1)+(2+3)}{2} = \frac{4+2}{2} + \frac{3+1}{2} = \text{Average of $X$} + \text{Average of $Y$}.
\]


A **linear combination** of two random variables $X$ and $Y$ is of the form $aX + bY$ where $a$ and $b$ are non-random constants.  Combining properties of linear rescaling with linearity of expected value yields the expected value of a linear combination.
\[
\E(aX + bY) = a\E(X)+b\E(Y)
\]
For example, $\E(X - Y) = \E(X) - \E(Y)$. The left side above, $\E(aX+bY)$, represents the "long way": find the distribution of $aX + bY$, which will depend on the joint distribution of $X$ and $Y$, and then use the definition of expected value.  The right side above, $a\E(X)+b\E(Y)$, is the "short way": find the expected values of $X$ and $Y$, which only requires their marginal distributions, and plug those numbers into the transformation formula.  Similar to LOTUS, linearity of expected value provides a way to find the expected value of certain random variables without first finding the distribution of the random variables.


Linearity of expected value extends naturally to more than two random variables.

```{example, matching-ev-n}
Recall the matching problem in Example \@ref(exm:matching-ev). We showed that the expected value of the number of matches $X$ is $\E(X)=1$ when $n=4$.  Now consider a general $n$: there are $n$ objects that are shuffled and placed uniformly at random in $n$ spots with one object per spot.  Let $X$ be the number of matches.  Can you find a general formula for $\E(X)$? 

```

1. Before proceeding take a minute to consider: how do you think $\E(X)$ depends on $n$? Will $\E(X)$ increase as $n$ increases? Decrease? Stay the same?
1. When $n=4$ we derived the distribution of $X$ and used it to find $\E(X)=1$. Now we'll see how to find $\E(X)$ without first finding the distribution of $X$. The key is to use the indicator random variables from Example \@ref(exm:matching-indicator).  Let $\ind_1$ be the indicator that object 1 is placed correctly in spot 1.  Find $\E(\ind_1)$.
1. When $n=4$, find $\E(\ind_j)$ for $j=1,2,3, 4$.
1. What is the relationship between the random variables $X$ and $\ind_1, \ind_2,\ind_3, \ind_4$?
1. Use the previous parts to find $\E(X)$.
1. Now consider a general $n$. Let $\ind_i$ be the indicator that object $j$ is placed correctly in spot $j$, $j=1, \ldots, n$.  Find $\E(\ind_j)$.
1. What is the relationship between $X$ and $\ind_1, \ldots, \ind_n$? 
1. Find $\E(X)$.  Be amazed.
1. Interpret $\E(X)$ is context.

```{asis, fold.chunk = TRUE}

1. There are two common guesses.  (1) As $n$ increases, there are more chances for a match, so maybe $\E(X)$ increases with $n$. (2) But as $n$ increases the chance that any particular object goes in the correct spot decreases, so maybe $\E(X)$ decreases with $n$.  These considerations move $\E(X)$ in opposite directions; how do they balance?
1. Recall that the expected value of an indicator random variable is just the probability of the corresponding event. There are $4$ objects which are equally likely to be placed in spot 1, only 1 of which is correct.  The probability that object 1 is correctly placed in spot 1 is $1/4$.  That is, $\E(\ind_1) = (1)(1/4) + (0)(1 - 1/4) = 1/4$.
1. If the objects are placed uniformly at random then no object is more or less likely than any other to be placed in its correct spot, so the probability and expected value should be the same for all $j$. Given any spot $j$, any of the $4$ objects is equally likely to be placed in spot $j$, and only one of those is the correct object, so $\IP(\ind_j = 1) = 1/4$, and $\E(\ind_j) = 1/4$. Note that these are *marginal* probabilities and *marginal* expected values; see the note after the example below.
1. Recall Example \@ref(exm:matching-indicator). We can count the total number of matches by starting with a count of 0, inspecting each spot, and incrementally adding 1 to our counter each time object $j$ matches spot $j$ for $j=1, \ldots, 4$.  That is, the total number of matches is the sum of the indicator random variables: $X=\ind_1 + \ind_2+\ind_3+\ind_4$.
1. Linearity of expected value says the expected value of the sum is the sum of the expected values
\begin{align*}
\E(X) & = \E(\ind_1 + \ind_2 + \ind_3 + \ind_4)\\
& = \E(\ind_1) + \E(\ind_2) + \E(\ind_3) + \E(\ind_4)\\
& = 1/4 + 1/4 + 1/4 + 1/4\\
& = 4(1/4) = 1
\end{align*}
1. Now we repeat the above process for a general $n$.
If the objects are placed uniformly at random then no object is more or less likely than any other to be placed in its correct spot, so the probability and expected value should be the same for all $j=1, \ldots, n$. Given any spot $j$, any of the $n$ objects is equally likely to be placed in spot $j$, and only one of those is the correct object, so $\IP(\ind_j = 1) = 1/n$, and $\E(I_j) = 1/n$.
1. We can count the total number of matches by incrementally adding 1 to our counter each time object $j$ matches spot $j$ for $j=1, \ldots, n$.  That is, the total number of matches is the sum of the indicator random variables: $X=\ind_1 + \cdots + \ind_n$.
1. Use linearity of expected value
\begin{align*}
\E(X) & = \E(\ind_1 + \ind_2 + \cdots + \ind_n)\\
& = \E(\ind_1) + \E(\ind_2) + \cdots + \E(\ind_n)\\
& = \frac{1}{n} + \frac{1}{n} + \cdots + \frac{1}{n}\\
& = n\left(\frac{1}{n}\right) = 1
\end{align*}
Regardless of the value of $n$, $\E(X) = 1$!
1. Imagine placing $n$ distinct objects uniformly at random in $n$ distinct spots with one object per spot. Then over many such placements, on average 1 object per placement is placed in the correct spot *regardless of the number of objects/spots*.
```

The answer to the previous problem is not an approximation: the expected value of the number of matches is equal to 1 for any $n$.  We think that's pretty amazing.  (We'll see some even more amazing results for this problem later.)  Notice that we computed the expected value without first finding the distribution of $X$.
When $n=4$ we found the distribution of $X$ by enumerating all the possibilities.
Obviously this is not feasible when $n$ is large, and in general it is difficult to find the exact distribution of $X$ in the matching problem (though we'll see a pretty good approximation later).
However, as the previous example shows, we don't need to find the distribution of $X$ to find $\E(X)$.


Intuitively, if the objects are placed in the spots uniformly at random, then the probability that object $j$ is placed in the correct spot should be the same for all the objects, $1/n$. But you might have said: "if object 1 goes in spot 1, there are only $n-1$ objects that can go in spot 2, so the probability that object 2 goes in spot to is $1/(n-1)$".  That is true *if object 1 goes in spot 1*.  However, when computing the *marginal* probability that object 2 goes in spot 2, we don't know whether object 1 went in spot 1 or not, so the probability needs to account for both cases.  Remember, there is a difference between  *marginal/unconditional* probability and *conditional* probability; recall Section \@ref(conditional-versus-unconditional).
Linearity of expected value is useful because we only need the marginal distribution of each random variable to compute the sum of their expected values.

When a problem asks "find the expected number of..." it's a good idea to try using indicator random variables and linearity of expected value. The following is a general statement of the strategy we used in the matching problem.

Let $A_1, A_2, \ldots, A_n$ be a collection of $n$ events.  Suppose event $i$ occurs with marginal probability $p_i=\IP(A_i)$. Let $N = \ind_{A_i} + \ind_{A_2} + \cdots + \ind_{A_n}$ be the random variable which counts the number of the events in the collection which occur.  Then the expected number of events that occur is the sum of the event probabilities.
\[
\E(N) = \sum_{i=1}^n p_i.
\]
If each event has the same probability, $p_i \equiv p$, then $\E(N)$ is equal to $np$.
These formulas for the expected number of events are true regardless of whether there is any association between the events (that is, regardless of whether the events are independent.)

For example, in the matching problem $A_i$ was the event that object $i$ was placed in spot $i$ and $p_i=1/n$ for all $i$.

```{example}

Kids wake up during the night. On any given night,

- the probability that Paul wakes up is 1/14
- the probability that Bob wakes up is 2/7
- the probability that Tommy wakes up is 1/30
- the probability that Chris wakes up is 1/2
- the probability that Slim wakes up is 6/7.

If any kid wakes up they're likely to wake other kids up too.  Find and interpret the expected number of kids that wake up on any given night.

```

```{asis, fold.chunk = TRUE}

Simply add the probabilities: $1/14 + 2/7 + 1/30+ 1/2 + 6/7=1.75$.  The expected number of kids to wake up in a night is 1.75.  Over many nights, on average 1.75 kids wake up per night.

The fact that kids wake each other up implies that the events are not independent, but this is irrelevant here. Because of linearity of expected value, we only need to know the *marginal* probability^[If there were too much dependence, then the provided marginal probabilities might not be possible.  For example if Slim always wakes up all the other kids, then the other marginal probabilities would have to be at least 6/7.  So a specified set of marginal probabilities puts some limits on how much dependence there can be.  This idea is similar to Example \@ref(exm:cats-dogs).] of each event (provided) in order to determine the expected number of events occur.  (The *distribution* of the number of kids that wake up would depend the relationships between the events, but not the long run average value.)

```

When computing the expected value of a random variable, consider if it can be written as a sum of component random variables.  If so, then using linearity of expected value is usually easier than first finding the distribution of the random variable.  Of course, the expected value is only one feature of the distribution of a random variable; there is much more to a distribution than its expected value.

### Variance of linear combinations of random variables

We have seen that correlation does not affect the expected value of a linear combination of random variables.
But what affect, if any, does correlation have on the variance of a linear combination of random variables?

```{example}
Consider a random variable $X$ with $\Var(X)=1$.  What is $\Var(2X)$?

- Walt says: $\SD(2X) = 2\SD(X)$ so $\Var(2X) = 2^2\Var(X) = 4(1) = 4$.
- Jesse says: Variance of a sum is a sum of variances, so $\Var(2X) = \Var(X+X)$ which is equal to $\Var(X)+\Var(X) = 1+1=2$.

Who is correct?  Why is the other wrong?
  
```

```{asis, fold.chunk = TRUE}

If $\Var(X)=1$ then $\Var(2X)= 4$. Walt is correctly using properties of linear rescaling.  Jesse is assuming that a variance of a sum is the sum of the variances, which is not true in general.  We'll see why below.

```

When two variables are correlated the degree of the association will affect the variability of linear combinations of the two variables.


```{example sat-compare-var}
Recall Example \@ref(exm:sat-compare-ev).
```

1. In which of the three scenarios is $\Var(X + Y)$ the largest?
Can you explain why?
1. In which of the three scenarios is $\Var(X + Y)$ the smallest?
Can you explain why?
1. In which scenario is $\Var(X + Y)$ roughly equal to the sum of $\Var(X)$ and $\Var(Y)$?
1. In which of the three scenarios is $\Var(X - Y)$ the largest?
Can you explain why?
1. In which of the three scenarios is $\Var(X - Y)$ the smallest?
Can you explain why?
1. In which scenario is $\Var(X - Y)$ roughly equal to the *sum* of $\Var(X)$ and $\Var(Y)$?

```{solution sat-compare-var-sol}
to Example \@ref(exm:sat-compare-var)
```


```{asis, fold.chunk = TRUE}
1. Variance of $X + Y$ is largest when $\Corr(X, Y)$ is near 1 (scenario 1).
With a strong positive correlation, students who scored high on Math tended to also score high on Reading so their total score was very high; students who scored low on Math tended to also score low on Reading so their total score was very low. Of these three scenarios we see the most variability in $X+Y$ in scenario 1. 
1. Variance of $X + Y$ is smallest when $\Corr(X, Y)$ is near $-1$ (scenario 3).
With a strong negative correlation, students who scored high on Math tended to score low on Reading so their total score was moderate; students who scored low on Math tended to score high on Reading so their total score was moderate. Of these three scenarios we see the least variability in $X+Y$ in scenario 3. 
1. When the correlation between $X$ and $Y$ is near 0 (scenario 2) the variance of $X + Y$ is roughly equal to the sum of the variances.
1. Variance of $X - Y$ is largest when $\Corr(X, Y)$ is near $-1$ (scenario 3).
With a strong negative correlation, students who scored high on Math tended to score low on Reading so their difference in scores was high and positive; students who scored low on Math tended to score high on Reading so their difference in scores was high and negative. Of these three scenarios we see the most variability in $X-Y$ in scenario 3. 
1. Variance of $X - Y$ is smallest when $\Corr(X, Y)$ is near 1 (scenario 1).
With a strong positive correlation, students who scored high on Math tended to also score high on Reading so their difference in scores was small; students who scored low on Math tended to also score low on Reading so their difference in scores was small. Of these three scenarios we see the least variability in $X-Y$ in scenario 1. 
1. When the correlation between $X$ and $Y$ is near 0 (scenario 2) the variance of $X - Y$ is roughly equal to the *sum* of the variances.
That is, when the correlation is 0, the sum $X+Y$ and the difference $X-Y$ have the same variance.
```


The degree of correlation between two random variables affects the variability of their sum and difference.
The following formulas represent the math behind the observations we made in the previous problem.



**Variance of sums and differences of random variables.**
\begin{align*}
\Var(X + Y) & = \Var(X) + \Var(Y) + 2\Cov(X, Y)\\
\Var(X - Y) & = \Var(X) + \Var(Y) - 2\Cov(X, Y)
\end{align*}

The left side represents first finding the distribution of the random variable $X+Y$ and computing its variance.
The right side represents using the joint (and marginal) distribution of $(X, Y)$ to compute the variance of the sum.
However, to compute the right side we do not need the full joint and marginal distributions; we simply need the marginal variances and the covariance (or correlation).

```{example}

Assume that SAT Math ($X$) and Reading ($Y$) scores follow a Bivariate Normal distribution, Math  scores have mean 527 and standard deviation 107, and Reading scores have mean 533 and standard deviation 100.  Compute $\Var(X + Y)$ and $\SD(X+Y)$ for each of the following correlations.

```

1. $\Corr(X, Y) = 0.77$
1. $\Corr(X, Y) = 0.40$
1. $\Corr(X, Y) = 0$
1. $\Corr(X, Y) = -0.77$


```{asis, fold.chunk = TRUE}

Recall that we can obtain covariance from correlation: $\Cov(X, Y) = \Corr(X, Y)\SD(X)\SD(Y) = (0.77)(107)(100) = 8239$.

1. $\Var(X + Y) = \Var(X) + \Var(Y) + 2\Cov(X, Y) = 107^2 + 100^2 + 2(8239)=37927$.  $\SD(X+Y)=\sqrt{37927} = 195$. 
1. $\Var(X + Y) = 107^2 + 100^2 + 2(0.40)(107)(100)=30009$.  $\SD(X+Y)= 173$.
1. $\Var(X + Y) = 107^2 + 100^2 + 0=21449$.  $\SD(X+Y)= 146$.
1. $\Var(X + Y) = 107^2 + 100^2 + 2(-0.77)(107)(100)=4971$.  $\SD(X+Y)= 70$.


```




If $X$ and $Y$ have a positive correlation: Large values of $X$ are associated with large values of $Y$ so the sum is really large, and small values of $X$ are associated with small values of $Y$ so the sum is really small. That is, the sum exhibits more variability than it would if the values of $X$ and $Y$ were uncorrelated.

If $X$ and $Y$ have a negative correlation: Large values of $X$ are associated with small values of $Y$ so the sum is moderate, and small values of $X$ are associated with large values of $Y$ so the sum is moderate. That is, the sum exhibits less variability than it would if the values of $X$ and $Y$ were uncorrelated.

The following simulation illustrates the previous example when the correlation is 0.77.
First we simulate $(X, Y)$ pairs.

```{python}
X, Y = RV(BivariateNormal(mean1 = 527, sd1 = 107, mean2 = 533, sd2 = 100, corr = 0.77))

x_and_y = (X & Y).sim(10000)

x_and_y
```


```{python, eval = FALSE}
x_and_y.plot()
```


```{python, echo = FALSE}
plt.figure();
x_and_y.plot()
plt.show();
```

```{python}
x_and_y.mean()
```


```{python}
x_and_y.var()
```


```{python}
x_and_y.sd()
```

Now we look at the sum $X + Y$.
So that our simulation results our consistent with those above we'll define `x + y` in "simulation world" (but we could have defined `X + Y` in "random variable world" and then simulated values of it.)

```{python}
x = x_and_y[0]
y = x_and_y[1]

t = x + y

t
```


```{python, eval = FALSE}
t.plot()
```


```{python, echo = FALSE}
plt.figure()
t.plot()
plt.show()
```

The simulated mean, variance, and standard deviation as close to what we computed in the previous example (of course, there is natural simulation variability).

```{python}
t.mean()
```


```{python}
t.var()
```


```{python}
t.sd()
```

Now we compare the distribution of the sum for each of the four cases for the correlation.
Notice how the variability of $X+Y$ changes based on the correlation.
The variability of $X + Y$ is largest when the correlation is strong and positive, and smallest when the correlation is strong and negative.

```{python}

X2, Y2 = RV(BivariateNormal(mean1 = 527, sd1 = 107, mean2 = 533, sd2 = 100, corr = 0.4))
t2 = (X2 + Y2).sim(10000)

X3, Y3 = RV(BivariateNormal(mean1 = 527, sd1 = 107, mean2 = 533, sd2 = 100, corr = 0))
t3 = (X3 + Y3).sim(10000)

X4, Y4 = RV(BivariateNormal(mean1 = 527, sd1 = 107, mean2 = 533, sd2 = 100, corr = -0.77))
t4 = (X4 + Y4).sim(10000)

plt.figure()
t.plot()
t2.plot()
t3.plot()
t4.plot()

plt.legend(['corr = 0.77', 'corr = 0.40', 'corr = 0', 'corr = -0.77']);
plt.show()
```

The simulated means, variances, and standard deviations as close to what we computed in the previous example (of course, there is natural simulation variability).

```{python}
t.mean(), t2.mean(), t3.mean(), t4.mean()
```

```{python}
t.sd(), t2.sd(), t3.sd(), t4.sd()
```

Compare the 90th percentiles of $X+Y$. The largest value for the 90th percentile occurs when there is the most variability in the sum, so we see more extreme values of the sum.


```{python}
t.quantile(0.9), t2.quantile(0.9), t3.quantile(0.9), t4.quantile(0.9)
```



```{example}
Continuing the previous example. Compute $\Var(X - Y)$ and $\SD(X-Y)$ for each of the following correlations.

```

1. $\Corr(X, Y) = 0.77$
1. $\Corr(X, Y) = 0.40$
1. $\Corr(X, Y) = 0$
1. $\Corr(X, Y) = -0.77$


```{asis, fold.chunk = TRUE}

1. $\Cov(X, Y) = \Corr(X, Y)\SD(X)\SD(Y) = (0.77)(107)(100) = 8239$. $\Var(X - Y) = \Var(X) + \Var(Y) - 2\Cov(X, Y) = 107^2 + 100^2 - 2(8239)=4971$.  $\SD(X-Y)=\sqrt{4971} = 70$. 
1. $\Var(X - Y) = 107^2 + 100^2 - 2(0.40)(107)(100)=12889$.  $\SD(X-Y)= 114$.
1. $\Var(X - Y) = 107^2 + 100^2 - 0=21449$.  $\SD(X-Y)= 146$.
1. $\Var(X - Y) = 107^2 + 100^2 - 2(-0.77)(107)(100)=37927$.  $\SD(X-Y)= 195$.


```

If $X$ and $Y$ have a positive correlation:
Large values of $X$ are associated with large values of $Y$ so the difference is small, and small values of $X$ are associated with small values of $Y$ so the difference is small. That is, the difference exhibits less variability than it would if the values of $X$ and $Y$ were uncorrelated.


If $X$ and $Y$ have a negative correlation:
Large values of $X$ are associated with small values of $Y$ so the difference is large and positive, and small values of $X$ are associated with large values of $Y$ so the difference is large and negative. That is, the difference exhibits more variability than it would if the values of $X$ and $Y$ were uncorrelated.




We continue the simulation from above when the correlation is 0.77.
New we look at the difference $X - Y$.
Again, we define the difference `x - y` in "simulation world" (but we could have defined `X - Y` in "random variable world" and then simulated values of it).

```{python}
d = x - y

d
```


```{python, eval = FALSE}
d.plot()
```


```{python, echo = FALSE}
plt.figure()
d.plot()
plt.show()
```


Now we compare the distributions of the difference $X - Y$ for each of the four cases of correlation.
Notice how the variability of $X-Y$ changes based on the correlation.
The variability of $X - Y$ is largest when the correlation is strong and negative, and smallest when the correlation is strong and positive.


```{python}

X2, Y2 = RV(BivariateNormal(mean1 = 527, sd1 = 107, mean2 = 533, sd2 = 100, corr = 0.4))
d2 = (X2 - Y2).sim(10000)

X3, Y3 = RV(BivariateNormal(mean1 = 527, sd1 = 107, mean2 = 533, sd2 = 100, corr = 0))
d3 = (X3 - Y3).sim(10000)

X4, Y4 = RV(BivariateNormal(mean1 = 527, sd1 = 107, mean2 = 533, sd2 = 100, corr = -0.77))
d4 = (X4 - Y4).sim(10000)

plt.figure()
d.plot()
d2.plot()
d3.plot()
d4.plot()

plt.legend(['corr = 0.77', 'corr = 0.40', 'corr = 0', 'corr = -0.77']);
plt.show()
```


The simulated mean, variance, and standard deviation as close to what we computed in the previous example (of course, there is natural simulation variability).

```{python}
d.mean(), d2.mean(), d3.mean(), d4.mean()
```


```{python}
d.sd(), d2.sd(), d3.sd(), d4.sd()
```


Compare the 90th percentiles of $X-Y$. The largest value for the 90th percentile occurs when there is the most variability in the difference, so we see more extreme values of the difference.

```{python}
d.quantile(0.9), d2.quantile(0.9), d3.quantile(0.9), d4.quantile(0.9)
```



The variance of the sum is the sum of the variances if and only if $X$ and $Y$ are uncorrelated.
\begin{align*}
\Var(X+Y)  & = \Var(X) + \Var(Y)\qquad \text{if $X, Y$ are uncorrelated}\\
\Var(X-Y)  & = \Var(X) + \Var(Y)\qquad \text{if $X, Y$ are uncorrelated}
\end{align*}
 
The variance of the difference of uncorrelated random variables is the *sum* of the variances.  Think just about the range of values.  Suppose SAT Math and Reading scores are each uniformly distributed on the interval [200, 800].  Then the sum takes values in [400, 1600], an interval of length 1200.  The difference takes values in $[-600, 600]$, also an interval of length 1200.

<!-- We can use the formulas for variances of sums and differences to show that $-1 \le \Corr(X, Y) \le 1$.  Consider two random variables $X$ and $Y$ with $\Var(X) \ge \Var(Y)$.  Rearrange the formula for the variance of a sum to show -->
<!-- \begin{align*} -->
<!-- \Cov(X, Y) & = 0.5 (\Var(X + Y) - \Var(X) - \Var(Y))\\ -->
<!-- & \le 0.5 (- \Var(X) - \Var(Y))\\ -->
<!-- & \le 0.5 (-) -->
<!-- \end{align*} -->

Combining the formula for variance of sums with some properties of covariance in the next subsection, we have a general formula for the variance of a linear combination of two random variables.
If $a, b, c$ are non-random constants and $X$ and $Y$ are random variables then
$$
\Var(aX + bY + c) = a^2\Var(X) + b^2\Var(Y) + 2ab\Cov(X, Y)
$$

### Bilinearity of covariance

The formulas for variance of sums and differences are application of several more general properties of covariance. Let $X,Y,U,V$ be random variables and $a,b,c,d$ be non-random constants.

**Properties of covariance.**
\begin{align*}
\Cov(X, X) &= \Var(X)\qquad\qquad\\
\Cov(X, Y) & = \Cov(Y, X)\\
\Cov(X, c) & = 0 \\
\Cov(aX+b, cY+d) & = ac\Cov(X,Y)\\
\Cov(X+Y,\; U+V) & = \Cov(X, U)+\Cov(X, V) + \Cov(Y, U) + \Cov(Y, V)
\end{align*}


- The variance of a random variable is the covariance of the random variable with itself.
- Non-random constants don't vary, so they can't co-vary.
- Adding non-random constants shifts the center of the joint distribution but does not affect variability.
- Multiplying by non-random constants changes the scale and hence changes the degree of variability.  
- The last property is like a "FOIL" (first, outer, inner, last) property. 

The last two properties together are called **bilinearity of covariance.** These properties extend naturally to sums involving more than two random variables.  To compute the covariance between two sums of random variables, compute the covariance between each component random variable in the first sum and each component random variable in the second sum, and sum the covariances of the components.


```{example}

Let $X$ be the number of two-point field goals a basketball player makes in a game, $Y$ the number of three point field goals made, and $Z$ the number of free throws made (worth one point each).  Assume $X$, $Y$, $Z$ have standard deviations of 2.5, 3.7, 1.8, respectively, and $\Corr(X,Y) = 0.1$, $\Corr(X, Z) = 0.3$, $\Corr(Y,Z) = -0.5$.  

```

1. Find the standard deviation of the number of  fields goals in a game (not including free throws)
1. Find the standard deviation of total points scored on fields goals in a game (not including free throws)
1. Find the standard deviation of total points scored in a game.


```{asis, fold.chunk = TRUE}

1. We want $\SD(X+Y)$, so we first find $\Var(X + Y)$.  We could use the formula for a variance of sums, but we'll use bilinearity of covariance instead to illustrate how it works, and to motivate part 3.
    \begin{align*}
    \Var(X + Y) & = \Cov(X + Y, X + Y)\\
    & = \Cov(X, X) + \Cov(X, Y) + \Cov(Y, X) + \Cov(Y, Y)\\
    & = (2.5^2) + (0.1)(2.5)(3.7) + (0.1)(3.7)(2.5) + 3.7^2 = 21.49
    \end{align*}
    So $\SD(X + Y) = 4.67$.
1. We want $\SD(2X+3Y)$, so we first find $\Var(2X + 3Y)$.  We'll use bilinearity of covariance again.
    \begin{align*}
    \Var(2X + 3Y) & = \Cov(2X + 3Y, 2X + 3Y)\\
    & = \Cov(2X, 2X) + \Cov(2X, 3Y) + \Cov(3Y, 2X) + \Cov(3Y, 3Y)\\
    & = 2^2\Cov(X, X) + (2)(3)\Cov(X, Y) + (3)(2)\Cov(Y, X)+ (3)(3)\Cov(Y, Y)\\
    & = (2^2)(2.5^2) + (2)(3)(0.1)(2.5)(3.7) + (3)(2)(0.1)(3.7)(2.5) + (3^2)(3.7^2) = 159.31
    \end{align*}
    So $\SD(2X + 3Y) = 12.62$.
1. We want $\SD(2X+3Y + Z)$, so we first find $\Var(2X + 3Y + Z)$.  We'll use bilinearity of covariance again.  Notice how we take the covariance of each term in the sum with each of the others.
    \begin{align*}
    \Var(2X + 3Y + Z) & = \Cov(2X + 3Y + Z, 2X + 3Y + Z)\\
    & = \Cov(2X, 2X) + \Cov(2X, 3Y) + \Cov(2X, Z) \\
    & \quad + \Cov(3Y, 2X) + \Cov(3Y, 3Y) + \Cov(3Y, Z)\\
    & \quad + \Cov(Z, 2X) + \Cov(Z, 3Y) + \Cov(Z, Z)\\
    & = 2^2\Cov(X, X) + (2)(3)\Cov(X, Y) + (2)(1)\Cov(X, Z)\\
    & \quad + (3)(2)\Cov(Y, X)+ (3)(3)\Cov(Y, Y) + (3)(1)\Cov(Y, Z)\\
    & \quad + (1)(2)\Cov(Z, X)+ (1)(3)\Cov(Z, Y) + 1^2\Cov(Z, Z)\\
    & = (2^2)(2.5^2) + (2)(3)(0.1)(2.5)(3.7) + (2)(1)(0.3)(2.5)(1.8)\\
    & \quad + (3)(2)(0.1)(3.7)(2.5) + (3^2)(3.7^2) + (3)(1)(-0.5)(3.7)(1.8)\\
    & \quad + (1)(2)(0.3)(1.8)(2.5) + (1)(3)(-0.5)(1.8)(3.7) + 1^2(1.8^2)= 114.72
    \end{align*}
    So $\SD(2X + 3Y + Z) = 12.16$.


```



<!-- ## Other moments -->



<!-- Expected values and variance are summary characteristics of a -->
<!-- distribution. While these are typically the two most important -->
<!-- characteristics, there are other summary characteristics like "skewness" -->
<!-- or "kurtosis". Higher order characteristics of a distribution are -->
<!-- defined via "moments". -->

<!-- The $k$**th moment** of $X$ is $\textrm{E}(X^k$). -->

<!-- The $k$th moment of a RV exists as long as $\textrm{E}(|X|^k)<\infty$. -->

<!-- Whether or not a certain moment exists depends on how quickly the tails -->
<!-- of the distribution go to 0. (The tails of a distribution refer to the -->
<!-- probabilities of values large in magnitude.) -->

<!-- If the $k$th moment of a distribution exists, then the $j$th moment -->
<!-- exists for all $j<k$. -->

<!-- The third moment is related to "skewness", and the fourth moment is -->
<!-- related to "kurtosis". -->

<!-- Expected value, variance, and moments are summary characteristics of a -->
<!-- distribution, so if two random variables have the same distribution then -->
<!-- they have all the same summary characteristics. Conversely, if for any -->
<!-- summary characteristic you pick the random variables yield the same -->
<!-- value, it seems reasonable that they must share the same distribution. -->
<!-- Unfortunately, it's not enough to just compare (polynomial) moments. -->

<!-- Random variables $X$ and $Y$ have the same distribution if and only if -->
<!-- $\textrm{E}[g(X)]=\textrm{E}[g(Y)]$ for all functions $g$ (for which the -->
<!-- expected values are defined). -->

<!-- ```{theorem, samedist-thm} -->
<!-- Random variables $X$ and $Y$ have the same distribution if and only if $\E[g(X)]=\E[g(Y)]$ for all functions $g$ (for which the expected values are defined). -->
<!-- ``` -->

<!-- Expected values are summary characteristics of a distribution, so if two random variables have the same distribution then they have all the same summary characteristics.  Conversely, if for any summary characteristic you pick the random variables yield the same value, it seems reasonable that they must share the same distribution. -->

<!-- ### Infinite or undefined expected values -->

<!-- There are some random variables for which $\E(X)=\infty$. There are also some random variables for which $\E(X)$ is undefined. -->



<!-- Technically, we haven't provided a general definition of expected value yet.  For discrete RVs, expected value is defined naturally as the probability-weighted average value. -->
<!-- \[ -->
<!-- \E(X) = \sum_x x \IP(X=x) -->
<!-- \] -->
<!-- The analogous definition for continuous RVs is: If $X$ is a continuous RV with probability density function $f_X$ -->
<!-- \[ -->
<!-- \E(X) = \int_{-\infty}^{\infty} x f_X(x) dx -->
<!-- \] -->
<!-- We will study continuous RVs in more detail later. -->

<!-- The above formulas are the ones generally used to compute expected values.  There is an alternative formula --- \emph{the tail probability formula for expected value} --- that works for both discrete and continuous RVs, provided they do not take negative values. -->
<!-- \[ -->
<!-- \text{If $X \ge 0$ then } \E(X) = \int_0^\infty \IP(X\ge x)\, dx -->
<!-- \] -->
<!-- The above suggests that it is possible to have RVs with $\E(X)=\infty$ if the tail probabilities $\IP(X\ge x)$ do not converge to 0 fast enough in order for the integral to converge. -->

<!-- If $X$ can take negative values, it can be written as the difference of its positive and negative parts\footnote{If $x$ is a number, its positive part is $x^{+} = \max(x, 0)$ and its negative part is $x^{-} = -\min(x, 0)$.  For example, if $x=3$ then $x^{+}=3$ and $x^{-}=0$; if $x=-2$ then $x^{+}=0$ and $x^{-}=2$. Note that $x^{-}\ge0$.  Then $x=x^{+}-x^{-}$ and $|x| = x^{+}+x^{-}$. }, $X = X^{+} - X^{-}$.  Since both $X^{+}\ge0$ and $X^{-}\ge 0$, their expected values are given by the tail probability formula.  Then $\E(X)$ is defined to be $\E(X^{+})-\E(X^{-})$, provided that at least one of $\E(X^{+})$ and $\E(X^{-})$ is finite.  If both $\E(X^{+})=\infty$ and $\E(X^{-})=\infty$ then $\E(X)$ is undefined  (since $\infty - \infty$ is undefined.) The most commonly used example for a situation where the expected value is undefined is the Cauchy distribution (a.k.a.\ the $t$-distribution with one degree of freedom). -->





## Conditional expected value {#ce}

Conditioning on the value of a random variable $X$ in general changes the distribution of another random variable $Y$.  If a distribution changes, its summary characteristics like expected value and variance can change too.


```{example, dice-ce}
Roll a fair four-sided die twice.  Let $X$ be the sum of the two rolls, and let $Y$ be the larger of the two rolls (or the common value if a tie). We found the joint and marginal distributions of $X$ and $Y$ in Example \@ref(exm:dice-probspace), displayed in the table below.

```

| $p_{X, Y}(x, y)$ |      |      |      |      |            |
|------------------|-----:|-----:|-----:|-----:|-----------:|
| $x$ \\ $y$       |    1 |    2 |    3 |    4 | $p_{X}(x)$ |
| 2                | 1/16 |    0 |    0 |    0 |       1/16 |
| 3                |    0 | 2/16 |    0 |    0 |       2/16 |
| 4                |    0 | 1/16 | 2/16 |    0 |       3/16 |
| 5                |    0 |    0 | 2/16 | 2/16 |       4/16 |
| 6                |    0 |    0 | 1/16 | 2/16 |       3/16 |
| 7                |    0 |    0 |    0 | 2/16 |       2/16 |
| 8                |    0 |    0 |    0 | 1/16 |       1/16 |
| $p_Y(y)$         | 1/16 | 3/16 | 5/16 | 7/16 |            |


1. Find $\E(Y)$. How could you find a simulation-based approximation?
1. Find $\E(Y|X=6)$.  How could you find a simulation-based approximation?
1. Find $\E(Y|X=5)$.  How could you find a simulation-based approximation?
1. Find $\E(Y|X=x)$ for each possible value of $x$ of $X$.
1. Find $\E(X|Y = 4)$. How could you find a simulation-based approximation?
1. Find $\E(X|Y = y)$ for each possible value $y$ of $Y$.





```{solution, dice-ce-sol}
to Example \@ref(exm:dice-ce)
```

```{asis, fold.chunk = TRUE}

1. $\E(Y) = 1(1/16) + 2(3/16) + 3(5/16) + 4(7/16) = 3.125$.  Approximate this long run average value by simulating many values of $Y$ and computing the average.
1. The conditional pmf of $Y$ given $X=6$ places probability 2/3 on the value 4 and 1/3 on the value 3.  Compute the expected value using this conditional distribution: $\E(Y|X=6) = 3(1/3) + 4(2/3) = 3.67$.  This conditional long run average value could be approximated by simulating many $(X, Y)$ pairs from the joint distribution, discarding the pairs for which $X\neq 6$, and computing the average value of the $Y$ values for the remaining pairs.
1. The conditional pmf of $Y$ given $X=5$ places probability 1/2 on the value 4 and 1/2 on the value 3.  Compute the expected value using this conditional distribution: $\E(Y|X=5) = 3(1/2) + 4(1/2) = 3.5$.  This conditional long run average value could be approximated by simulating many $(X, Y)$ pairs from the joint distribution, discarding the pairs for which $X\neq 5$, and computing the average value of the $Y$ values for the remaining pairs.
1. Proceed as in the previous two parts. Find $\E(Y|X=x)$ for each possible value of $x$ of $X$.

    | $x$ |            $\E(Y|X=x)$ |
    |----:|-----------------------:|
    |   2 |               1(1) = 1 |
    |   3 |               2(1) = 2 |
    |   4 |  2(1/3) + 3(2/3) = 8/3 |
    |   5 |  3(1/2) + 4(1/2) = 3.5 |
    |   6 | 3(1/3) + 4(2/3) = 11/3 |
    |   7 |               4(1) = 4 |
    |   8 |               4(1) = 4 |
  
1. The conditional pmf of $X$ given $Y=4$ places probability 2/7 on each of the values 5, 6, 7, and 1/7 on the value 8.  Compute the expected value using this conditional distribution: $\E(X|Y=4) = 5(2/7) + 6(2/7) +7(2/7) + 8(1/7)= 6.29$.  This conditional long run average value could be approximated by simulating many $(X, Y)$ pairs from the joint distribution, discarding the pairs for which $Y\neq 4$, and computing the average value of the $X$ values for the remaining pairs.
1. Proceed as in the previous part.

    | $y$ |                             $\E(X|Y=y)$ |
    |----:|----------------------------------------:|
    |   1 |                                2(1) = 2 |
    |   2 |                  3(2/3) + 4(1/3) = 10/3 |
    |   3 |          4(2/5) + 5(2/5) + 6(1/5) = 4.8 |
    |   4 | 5(2/7) + 6(2/7) +7(2/7) + 8(1/7) = 44/7 |


```


```{python}

U1, U2 = RV(DiscreteUniform(1, 4) ** 2)

X = U1 + U2

Y = (U1 & U2).apply(max)

y_given_Xeq6 = (Y | (X == 6) ).sim(3000)

y_given_Xeq6

```


```{python}

y_given_Xeq6.tabulate()

```

```{python}

y_given_Xeq6.mean()

```



```{definition ce}

The **conditional expected value** (a.k.a. *conditional expectation* a.k.a. *conditional mean*), of a random variable $Y$ given the event $\{X=x\}$, defined on a probability space with measure $\IP$, is a *number* denoted $\E(Y|X=x)$ representing the probability-weighted average value of $Y$, where the weights are determined by the conditional distribution of $Y$ given $X=x$.

\begin{align*}
	& \text{Discrete $X, Y$ with conditional pmf $p_{Y|X}$:} & \E(Y|X=x) & = \sum_y y p_{Y|X}(y|x)\\
	& \text{Continuous $X, Y$ with conditional pdf $f_{Y|X}$:} & \E(Y|X=x) & =\int_{-\infty}^\infty y f_{Y|X}(y|x) dy
\end{align*}

```


Remember, when conditioning on $X=x$, $x$ is treated as a fixed constant. The conditional expected value  $\E(Y | X=x)$ is  a *number* representing the mean of the conditional distribution of $Y$ given $X=x$. The conditional expected value $\E(Y | X=x)$ is the long run average value of $Y$ over only those outcomes for which $X=x$.
To approximate $\E(Y|X = x)$, simulate many $(X, Y)$ pairs, discard the pairs for which $X\neq x$, and average the $Y$ values for the pairs that remain. 







```{example, uniform-sum-max-ce}

Recall Example \@ref(exm:uniform-sum-max-conditional). Consider the probability space corresponding to two spins of the Uniform(1, 4) spinner and let $X$ be the sum of the two spins and $Y$ the larger to the two spins (or the common value if a tie).

```


1. Find $\E(X | Y = 3)$.
1. Find $\E(X | Y = 4)$.
1. Find $\E(X | Y = y)$ for each value $y$ of $Y$.
1. Find $\E(Y | X = 3.5)$.
1. Find $\E(Y | X = 6)$.
1. Find $\E(Y | X = x)$ for each value $x$ of $X$.



```{solution, uniform-sum-max-ce-sol}
to Example \@ref(exm:uniform-sum-max-ce)
```

```{asis, fold.chunk = TRUE}

1. Recall Figure \@ref(fig:uniform-sum-max-conditional-plot).  All the conditional distributions (slices) are Uniform, but over different ranges of possible values. Remember, the mean of any Uniform distribution is the midpoint of the possible range of values. The conditional distribution of $X$ given $Y=3$ is the Uniform(4, 6) distribution, which has mean 5.  Therefore, $\E(X | Y = 3)=5$.  As an integral, since $f_{X|Y}(x|3) = 1/2, 4<x<6$,
\[
\E(X | Y = 3) = \int_4^6  x (1/2)dx = \frac{x^2}{4}\Bigg|_{x=4}^{x=6} = \frac{6^2}{4} - \frac{4^2}{4} = 5.
\]
1. The conditional distribution of $X$ given $Y=4$ is the Uniform(5, 8) distribution, which has mean 6.5.  Therefore, $\E(X | Y = 4)=6.5$.
1. For a given $y$, the conditional distribution of $X$ given $Y=y$ is the Uniform($y+1$, $2y$) distribution, which has mean $\frac{y+1+2y}{2}=1.5y + 0.5$.  Therefore, $\E(X | Y = y)=1.5y + 0.5$. As an integral, since $f_{X|Y}(x|y) = \frac{1}{y-1}, y+1 < x< 2y$,
\[
\E(X | Y = y) = \int_{y+1}^{2y}  x \left(\frac{1}{y-1}\right)dx = \frac{x^2}{2(y-1)}\Bigg|_{x=y+1}^{x=2y} = \frac{(2y)^2}{2(y-1)} - \frac{(y+1)^2}{2(y-1)} = 1.5y + 0.5.
\]
In the above, $y$ is treated like a fixed constant, and we are averaging over values of $X$ by taking a $dx$ integral. For a given value of $y$ like $y=3$, $1.5y + 0.5$ is a number like $1.5(3)+0.5=5$.
1. The conditional distribution of $Y$ given $X=3.5$ is the Uniform(1.75, 2.5) distribution, which has mean 2.125.  Therefore, $\E(Y | X = 3.5)=2.125$.  As an integral, since $f_{Y|X}(y|3.5) = 1/0.75, 1.75<y<2.5$,
\[
\E(Y | X = 3.5) = \int_{1.75}^{2.5}  y (1/0.75)dy = \frac{y^2}{1.5}\Bigg|_{y=1.75}^{y=2.5} = \frac{2.5^2}{1.5} - \frac{1.75^2}{1.5} = 2.125.
\]
1. The conditional distribution of $Y$ given $X=6$ is the Uniform(3, 4) distribution, which has mean 3.5.  Therefore, $\E(Y | X = 6)=3.5$.
1. There are two general cases.  If $2<x<5$ then the conditional distribution of $Y$ given $X=x$ is Uniform($0.5x$, $x-1$) so $\E(Y|X = x) = \frac{0.5x + x - 1}{2} = 0.75x - 0.5$. If $5<x<8$ then the conditional distribution of $Y$ given $X=x$ is Uniform($0.5x$, 4) so $\E(Y|X = x) = \frac{0.5x + 4}{2} = 0.25x +2$.  The two cases can be put together as
\[
\E(Y | X = x) = 0.25x + 0.5\min(4, x-1).  
\]
In the above, $x$ is treated like a fixed constant, and we are averaging over values of $Y$ by taking a $dy$ integral. For a given value of $x$ like $x=3.5$, $0.25x + 0.5\min(4, x-1)$ is a number like $0.25(3.5) + 0.5\min(4, 3.5-1)=2.125$.
    
```



Remember that the probability that a continuous random variable is equal to a particular value is 0; that is, for continuous $X$, $\IP(X=x)=0$. When we condition on $\{X=x\}$ we are really conditioning on $\{|X-x|<\ep\}$ and seeing what happens in the idealized limit when $\ep\to0$.

When simulating, *never* condition on $\{X=x\}$ for a continuous random variable $X$; rather, condition on $\{|X-x|<\ep\}$ where $\ep$ represents some suitable degree of precision (e.g. $\ep=0.005$ if rounding to two decimal places).

To approximate $\E(Y|X = x)$ for continuous random variables, simulate many $(X, Y)$ pairs, discard the pairs for which $X$ *is not close to* $x$, and average the $Y$ values for the pairs that remain. 

```{python}

U1, U2 = RV(Uniform(1, 4) ** 2)

X = U1 + U2

Y = (U1 & U2).apply(max)

x_given_Yeq3 = (X | (abs(Y - 3) < 0.05) ).sim(1000)

x_given_Yeq3

```



```{python}

x_given_Yeq3.plot()
plt.show()

x_given_Yeq3.mean()

```

### Conditional expected value as a random variable


Given a value $x$ of $X$, the conditional expected value $\E(Y|X=x)$ is a *number*.  However, since $X$ can take different values $x$, then $\E(Y|X=x)$ can also take different values depending on the value of $x$.  That is, $\E(Y|X=x)$ is a function of $x$. Moreover, since $X$ is a random variable, $\E(Y|X=x)$ is a function of values of a random variable.


```{example meeting-conditional-then-marginal-ce}

Recall Example \@ref(exm:meeting-conditional-then-marginal).
In the meeting problem, assume that $R$ follows a Normal(30, 10) distribution.
For any value $r$, assume that the conditional distribution of $Y$ given $R=r$ is a Normal distribution with mean $30 + 0.7(r - 30)$ and standard deviation 7.14 minutes.
```

1. Compute and interpret $\E(Y| R = 40)$.
1. Compute and interpret $\E(Y| R = 15)$.
1. Provide an expression for $\E(Y|R)$.
1. Identify the distribution of the random variable $E(Y|R)$.
1. Explain in words in context what the distribution in the previous part represents.

```{solution, meeting-conditional-then-marginal-ce-sol}
to Example \@ref(exm:meeting-conditional-then-marginal-ce)
```

```{asis, fold.chunk = TRUE}
1. The assumed conditional distribution of $Y$ given $R=40$ is Normal with mean $30 + 0.7(40 - 30) = 37$ and standard deviation 7.14 minutes.
The mean of this distribution is 37.
Therefore $\E(Y | R = 40) = 37$.
Over many days *where Regina arrives 40 minutes after noon*, Cady's conditional average arrival time is 37 minutes after noon.
1. The assumed conditional distribution of $Y$ given $R=15$ is Normal with mean $30 + 0.7(15 - 30) = 19.5$ and standard deviation 7.14 minutes.
The mean of this distribution is 19.5.
Therefore $\E(Y | R) = 19.5$.
Over many days *where Regina arrives 15 minutes after noon*, Cady's conditional average arrival time is 19.5 minutes after noon.
1. The assumed conditional distribution of $Y$ given $R=r$ is Normal with mean $30 + 0.7(r - 30)$ and standard deviation 7.14 minutes.
The mean of this distribution is $30 + 0.7(r - 30)$.
Therefore $\E(Y | R = r) = 30 + 0.7(r - 30)$; in this expression, $r$ represents a particular number (like 40 or 15).
Regardless of Regina's arrival time, Cady's conditional average arrival time is given by $\E(Y | R) = 30 + 0.7(R - 30)$; notice that this is a function of the random variable $R$.
1. $\E(Y | R) = 30 + 0.7(R - 30)$ is a linear rescaling of $R$. Since $R$ has a Normal distribution, any linear rescaling of $R$ also has a Normal distribution.
The mean is $30 + 0.7(\E(R) - 30) = 30 + 0.7(30-30) = 30$ minutes after noon and the standard deviation is $0.7(\SD(R)) = 0.7(10) = 7$ minutes after noon.
That is, $\E(Y | R) = 30 + 0.7(R - 30)$ has a Normal(30, 7) distribution.
1. See below.
```


Consider Figure \@ref(fig:meeting-bvn-conditional-ce) which represents the situation in Example \@ref(exm:meeting-conditional-then-marginal-ce).
The orange vertical slices represent the conditional distribution of $Y$ given $R=r$ for $r = 10, 15, 20, \ldots, 45, 50$.
The pink dots in the center of the slices represent the conditional averages, $\E(Y|R = r)$ for the different values of $r$.
The pink line connecting the conditional averages represents $\E(Y | R) = 30 + 0.7(R - 30)$.

```{r meeting-bvn-conditional-ce, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE, fig.cap="A Bivariate Normal distribution with some conditional distributions and conditional expected values highlighted."}
# | echo: false
# | label: fig-meeting-bivariate-normal
# | fig-cap: "add"
# | fig-alt: "add"

xs = seq(10, 50, 5)

ggplot(unit_box_prob,
       aes(x = x,
           y = y,
           z = bivariate_normal)) +
  geom_raster(aes(fill = bivariate_normal), interpolate = TRUE) +
  geom_contour(color = "white") +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 60)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 60)) +
  scale_fill_viridis(limits = c(0, unit_box_max_prob)) +
  labs(x = "Regina's arrival time (minutes after noon)",
       y = "Cady's arrival time (minutes after noon)",
       fill = "Density") +
  coord_fixed() +
  theme_classic() +
  geom_vline(xintercept = xs, linetype = "solid", 
                 color = c("#E69F00"), size = 2, alpha = 0.3) +
  geom_abline(intercept = 30 - 0.7 * 30, slope = 0.7, linetype = "solid", 
                 color = c("#CC79A7"), size = 2, alpha = 0.5) +
  geom_point(data = data.frame(x = xs, y = 30 + 0.7 * (xs - 30)),
             aes(x = x, y = y, z = 0),
             color = c("#CC79A7"), size = 3)
```

In the previous example, suppose that every day when Regina arrives she guesses what time Cady arrived/will arrive that day (if Regina arrives second/first).
Suppose each day Regina's guess is equal to Cady's conditional average arrival time given Regina's arrival time.
For example, every day Regina arrives 40 minutes after noon, she guesses Cady's arrival time is 37 minutes after noon; every day Regina arrives 15 minutes after noon, she guess Cady's arrival time is 19.5 minutes after noon.
Then the distribution of $\E(Y|R)$ represents how Regina's guesses for Cady's arrival time would be distributed over a large number of days.
The values of $\E(Y|R)$ would be given by $30 + 0.7(R - 30)$, a function of $R$.
The *distribution* of values of $\E(Y|R)$ would be determined by the distribution of $R$.
For example, there would be more days where Regina arrives 40 minutes after noon than where she arrives 15 minutes after noon, so guesses of 37 minutes after noon ($\E(Y|R=40)=37$) would occur more frequently than guesses of 19.5 minutes after noon ($\E(Y|R=15)=19.5$).



```{example, dice-ce-rv}
Continuing Example \@ref(exm:dice-ce).  Let $X$ be the sum of the two rolls, and let $Y$ be the larger of the two rolls (or the common value if a tie).

```

1. Let $\ell(x)$ denote the function that maps values $x$ of $X$ to $\E(Y|X=x)$.  Find the distribution of the *random variable* $Z=\ell(X)$.
1. Find $\IP(Z\le 3)$.
1. Let $\E(X|Y)$ denote the *random variable* that takes value $\E(X|Y=y)$ when $Y=y$.  Find the distribution of $\E(X|Y)$.
1. Find $\IP(\E(X|Y)\le 4)$.




```{solution, dice-ce-rv-sol}
to Example \@ref(exm:dice-ce-rv)
```

```{asis, fold.chunk = TRUE}

1. We have already found $\E(Y|X=x)$ for each $x$.  The table below defines the function $\ell$. 

    | $x$ |  $\ell(x) = \E(Y|X =x)$ |
    |----:|------------------------:|
    |   2 |                       1 |
    |   3 |                       2 |
    |   4 |                     8/3 |
    |   5 |                     3.5 |
    |   6 |                    11/3 |
    |   7 |                       4 |
    |   8 |                       4 |
    
    The random variable $Z=\ell(X)$ takes values 1, 2, 8/3, 3.5, 11/3, and 4.  Since $Z$ is a function of $X$, the distribution of $Z$ is determined by the distribution of $X$.  For example, $\IP(Z = 8/3) = \IP(X=4) = 3/16$, and $\IP(Z = 4) = \IP(X=7)+\IP(X = 8)=3/16$.  The following table displays the pmf of $Z$.

    |  $z$ | $p_Z(z)$ |
    |-----:|---------:|
    |    1 |     1/16 |
    |    2 |     2/16 |
    |  8/3 |     3/16 |
    |  3.5 |     4/16 |
    | 11/3 |     3/16 |
    |    4 |     3/16 |
  
1. Use the table above. The possible values of $Z$ that are at most 3 are 1, 2, 8/3, so $\IP(Z\le 3) = 6/16$.
1. This is similar to the previous parts, but now we are conditioning the other way and using different notation.  Let $w$ denote a generic possible value of the random variable $\E(X|Y)$.  The possible values of $\E(X|Y)$ are determined by $\E(X|Y=y)$ for each possible value $y$ of $Y$, and the corresponding probabilities are determined by the distribution of $Y$.  The following table displays the pmf of $\E(X|Y)$.

    |  $w$ | $p_{\E(X|Y)}(w)$ |
    |-----:|-----------------:|
    |    2 |             1/16 |
    | 10/3 |             3/16 |
    |  4.8 |             5/16 |
    | 44/7 |             7/16 |

1. Use the table above. $\IP(\E(X|Y)\le 4) = 4/16$.

```

```{definition, ce-rv}

The **conditional expected value of $Y$ given $X$** is the *random variable*, denoted $\E(Y|X)$, which takes value $\E(Y|X=x)$ on the occurrence of the event $\{X=x\}$.  The random variable $\E(Y|X)$ is a *function of* $X$.

```

For a given value $x$ of $X$, $\E(Y|X=x)$ is a *number*. Let $\ell$ denote the function which maps $x$ to the number $\ell(x)=\E(Y|X=x)$. The random variable  $\E(Y|X)$ is a function of $X$, namely $\E(Y|X)=\ell(X)$.

Roughly, $\E(Y|X)$ can be thought of as the "best guess" of the value of $Y$ given only the information available from $X$.

Since $\E(Y|X)$ is a random variable, it has a distribution.  And since $\E(Y|X)$ is a function of $X$, the distribution of $X$ will be depend on the distribution of $X$.  However, remember that a transformation generally changes the shape of a distribution, so the distribution of $\E(Y|X)$ will usually have a different shape than that of $X$.


```{example, uniform-sum-max-ce-rv}

Continuing Example \@ref(exm:uniform-sum-max-ce). Consider the probability space corresponding to two spins of the Uniform(1, 4) spinner and let $X$ be the sum of the two spins and $Y$ the larger to the two spins (or the common value if a tie).

```


1. Find an expression for $\E(X | Y)$.
1. Find $\IP(\E(X|Y) \le 5)$.
1. Find the pdf of $\E(X|Y)$.
1. Find an expression for $\E(Y | X)$.


```{solution, uniform-sum-max-ce-rv-sol}
to Example \@ref(exm:uniform-sum-max-ce-rv)
```

```{asis, fold.chunk = TRUE}

1. The conditional distribution of $X$ given $Y=y$ is Uniform($y+1$, $2y$) distribution, which has mean $\frac{y+1+2y}{2}=1.5y + 0.5$.  This is true for any value $y$ of $Y$.  Therefore, $\E(X|Y) = 1.5Y + 0.5$, a function of $Y$.
1. Remember that the pdf of $Y$ is $f_Y(y) = (2/9)(y-1), 1<y<4$.
    \[
    \IP(\E(X|Y) \le 5)   = \IP(1.5Y + 0.5 \le 5) = \IP(Y \le 3) = \int_1^3 (2/9)(y-1)dy = 4/9
    \]
1. $E(X|Y)=1.5Y+0.5$ is a linear transformation of $Y$, so the shape of its distribution will be the same as the shape of the distribution of $Y$.  The possible values of $\E(X|Y)$ are 2 to 6.5.  We can use the cdf method.  For $2<w<6.5$,

    \begin{align*}
    F_{\E(X|Y)}(w) & = \IP(\E(X|Y)\le w)\\
    & = \IP(1.5Y + 0.5 \le w)\\
    & = \IP(Y \le (w - 0.5)/1.5)\\
    F_{\E(X|Y)}(w)& = F_Y((w-0.5)/1.5)
    \end{align*}
    
    Differentiate both sides with respect to $w$; remember the chain rule.
    \[
    f_{\E(X|Y)}(w) = f_Y((w-0.5)/1.5)(1/1.5) = (2/9)((w-0.5)/1.5 - 1)/1.5 = (8/81)(w - 2)
    \]

    That is, the pdf of $\E(X|Y)$ is $f_{\E(X|Y)}(w) = (8/81)(w - 2), 2<w<6.5$.
    
1. For each $2<x<8$,
\[
\E(Y | X = x) = 0.25x + 0.5\min(4, x-1).  
\]
Therefore, $\E(Y | X) = 0.25X + 0.5\min(4, X-1)$, a function of $X$.
    
```

### Linearity of conditional expected value

Conditional expected value, whether viewed as a number $\E(Y|X=x)$ or a random variable $\E(Y|X)$, possesses properties analogous to those of (unconditional) expected value.  In particular, we have **linearity of conditional expected value.**


If $X, Y_1, \ldots, Y_n$ are RVs and $a_1, \ldots, a_n$ are non-random constants then
\begin{align*}
\E(a_1Y_1+\cdots+a_n Y_n|X=x) & = a_1\E(Y_1|X=x)+\cdots+a_n\E(Y_n|X=x)\\
\E(a_1Y_1+\cdots+a_n Y_n|X) & = a_1\E(Y_1|X)+\cdots+a_n\E(Y_n|X)
\end{align*}
The first line above is an equality involving *numbers*; the second line is an equality involving *random variables* (i.e., functions).


```{example, uniform-sum-max-ce-rv-linear}

Continuing Example \@ref(exm:uniform-sum-max-ce-rv). Spin the Uniform(1, 4) spinner twice, let $U_1$ be the result of the first spin, $U_2$ the second, and let $X=U_1+U_2$ and $Y=\max(U_1, U_2)$.

```

1. Use linearity to show $\E(U_1|Y) = 0.75Y + 0.25$.
1. Explain intuitively why $\E(U_1|Y) = 0.75Y + 0.25$.


```{solution, uniform-sum-max-ce-rv-linear-sol}
to Example \@ref(exm:uniform-sum-max-ce-rv-linear)
```

```{asis, fold.chunk = TRUE}

1. By symmetry, $\E(U_1|Y) = \E(U_2|Y)$. By linearity of conditional expected value
\[
\E(X|Y) = \E(U_1 + U_2|Y) = \E(U_1|Y) + \E(U_2|Y) = 2\E(U_1|Y)  
\]
So $\E(U_1|Y) = 0.5\E(X|Y) = 0.5(1.5Y + 0.5)=0.75Y + 0.25$.
1. Given the larger value $Y$, there are two cases.  Either the first spin is the larger, which happens with probability 0.5, in which case $U_1=Y$ so $\E(U_1|Y) = Y$.  Otherwise, the second spin is the larger, which happens with probability 0.5, in which case $U_1$ is Uniformly distributed between 1 and $Y$ with mean $(Y+1)/2$.  Therefore, $\E(U_1|Y) = 0.5Y + 0.5(Y+1)/2 = 0.75Y + 0.25$.

```

### Law of total expectation

Analogous to the law of total probability, the law of total expectation 
 provides a way of computing an expected value by breaking down a problem into various cases, computing the conditional expected value given each case, and then computing the overall expected value as a probability-weighted average of these case-by-case conditional expected values.  

```{example, dice-lte}
Continuing Example \@ref(exm:dice-ce-rv).  Let $X$ be the sum of the two rolls, and let $Y$ be the larger of the two rolls (or the common value if a tie).

```

1. Find the expected value of the random variable $\E(X|Y)$.  That is, find $\E(\E(X|Y))$.  How does it relate to $\E(X)$?
1. Find the expected value of the random variable $\E(Y|X)$.  That is, find $\E(\E(Y|X))$.  How does it relate to $\E(Y)$?

```{solution, dice-lte-sol}
to Example \@ref(exm:dice-lte)
```

```{asis, fold.chunk = TRUE}

1. $\E(X|Y)$ is a discrete random variable with pmf

    |  $w$ | $p_{\E(X|Y)}(w)$ |
    |-----:|-----------------:|
    |    2 |             1/16 |
    | 10/3 |             3/16 |
    |  4.8 |             5/16 |
    | 44/7 |             7/16 |
  
    Therefore,
    \[
    \E(\E(X|Y)) = (2)(1/16) + (10/3)(3/16) + (4.8)(5/16) + (44/7)(7/16) = 5
    \]
    We see that $\E(\E(X|Y)) = 5 = \E(X)$.
    
1. $\E(Y|X)$ is a discrete random variable with pmf

    |  $z$ | $p_{\E(Y|X)}(z)$ |
    |-----:|-----------------:|
    |    1 |             1/16 |
    |    2 |             2/16 |
    |  8/3 |             3/16 |
    |  3.5 |             4/16 |
    | 11/3 |             3/16 |
    |    4 |             3/16 |

  
    Therefore,
    \[
    \E(\E(Y|X)) = (1)(1/16) + (2)(2/16) + (8/4)(3/16) + (3.5)(4/16) +(11/3)(3/16)+(4)(3/16)= 3.125
    \]
    We see that $\E(\E(Y|X)) = 3.125 = \E(Y)$.

```


```{theorem LTE, name="Law of Total Expectation (LTE)"}
For any two random variables $X$ and $Y$ (defined on the same probability space)
\[
\E(Y) = \E(\E(Y|X))
\]
```

Remember that $\E(Y|X)$ is a *random variable* and so it has an expected value $\E(\E(Y|X))$ representing the long run average value of the random variable $\E(Y|X)$. Also remember that $\E(Y|X)$ is a function of $X$ and so $\E(\E(Y|X))$ can be computed using LOTUS using the distribution of $X$. For two discrete random variables $X$ and $Y$
\[
\E(\E(Y|X)) = \sum_x \E(Y|X=x)p_X(x)
\]

Here is a proof of the LTE for discrete random variables. (The proof for continuous random variables is analogous).
\begin{align*}
\E(\E(Y|X)) & = \sum_x \E(Y|X=x)p_X(x) & & \text{LOTUS, $\E(Y|X)$ is a function of $X$}\\
& = \sum_x \left(\sum_y y p_{Y|X}(y|x)\right) p_X(x) & & \text{definition of CE}\\
& = \sum_x \sum_y y p_{X, Y}(x, y) & & \text{joint = conditional $\times$ marginal}\\
& = \sum_y y \sum_x p_{X, Y}(x, y) & & \text{interchange sums}\\
& = \sum_y y p_Y(y) & & \text{collapse joint to get marginal}\\
& = \E(Y) & & \text{definition of expected value}
\end{align*}

```{example, uniform-sum-max-lte}

Continuing Example \@ref(exm:uniform-sum-max-ce-rv). Consider the probability space corresponding to two spins of the Uniform(1, 4) spinner and let $X$ be the sum of the two spins and $Y$ the larger to the two spins (or the common value if a tie).

```


1. Use the distribution of the random variable $E(X|Y)$ to compute $\E(\E(X|Y))$.  Compare to $\E(X)$.
1. Use the expression for $\E(X|Y)$ and properties of expected value to compute $\E(\E(X|Y))$.


```{solution, uniform-sum-max-lte-sol}
to Example \@ref(exm:uniform-sum-max-lte)
```

```{asis, fold.chunk = TRUE}

1. The continuous random variable $\E(X|Y)$ has pdf $f_{\E(X|Y)}(w) = (8/81)(w - 2), 2<w<6.5$.  So the expected value is
    \[
    \E(\E(X|Y))  = \int_2^{6.5} w \left((8/81)(w-2)\right)dw = 5
    \]
1. $E(X|Y)=1.5Y+0.5$ so $\E(E(X|Y))=\E(1.5Y+0.5)=1.5\E(Y) + 0.5=1.5(3)+0.5$.  We can find $\E(Y)=3$ using its pdf: $\E(Y) = \int_1^4 y (2/9)(y-1)dy = 3$.

```

Conditioning can be used as a problem solving strategy.  Conditioning can be used with the law of total probability to compute unconditional probabilities.  Likewise, conditioning can be used with the law of total expectation to compute unconditional expected values.



```{example, coin-lte}
Flip a fair coin  repeatedly.

```


1. What is the expected value of the number of tosses until a flip lands on H?  (Count the tosses that result in H, so H is 1 flip, TH is 2 flips, TTH is 3 flips, etc).
1. What is the expected value of the number of flips until you see H followed immediately by T?  (HT is 2 flips, HHT is 3 flips, THT is 3 flips, HHHT is 4 flips, etc)
1. What is the expected value of the number of flips until you see H followed immediately by H?  (HH is 2 flips, THH is 3 flips, HTHH is 4 flips, HTTHH is 5 flips, etc)
1. Which of the previous two parts has the larger expected value?  Can you explain why?



```{solution, coin-lte-sol}
to Example \@ref(exm:coin-lte)
```

```{asis, fold.chunk = TRUE}

1. Let $\mu$ be the expected value in question.  Condition on the result of the first flip.  Either the first flip is H, with probability 1/2, in which case you're done with 1 flip.  Otherwise, the first flip is T in which case the process starts over after the first flip and the expected number of additional flips is also $\mu$.  Use the law of total expectation to put the two expected values together.
    \[
    \mu = (1/2)(1) + (1/2)(1+\mu)
    \]
    Solve for $\mu=2$.
1. To achieve the pattern HT, we first need to flip until we get H, and then we complete the pattern once we get the first T after that. The expected number of flips until the first H is 2 (from the previous part).  By symmetry, the expected number of additional flips until the first T is also 2.  By linearity of expected value, the expected value of the number of flips to achieve HT is 4.
1. Let $\mu$ denote the expected value in question.  Condition on the result of the first flip.  If we get T, we're right back where we started after 1 flip, and the expected number of additional flips is $\mu$.  If the first flip is H, consider the second flip.  If it's H, then we're done in 2 flips.  If the second flip is T, then after 2 flips we're back at the beginning again and the expected number of additional flips is $\mu$.  Use the law of total expectation to put it all together.
    \[
    \mu = (1/2)(1 + \mu) + (1/2)((1/2)(2) + (1/2)(2+\mu))
    \]
    Solve to find $\mu = 6$.
1. It takes longer on average to see HH than HT. When trying for HH, any T that follows H destroys our progress and takes us back to the beginning.  But when trying for HT, any H that follows H just maintains our current position.

```


```{example lookaway-ce}
Recall Example \@ref(exm:lookaway).
You and your friend are playing the ["lookaway challenge"](https://fivethirtyeight.com/features/what-are-your-chances-of-winning-the-u-s-open/).
The game consists of possibly multiple rounds. In the first round, you point in one of four directions: up, down, left or right. At the exact same time, your friend also looks in one of those four directions. If your friend looks in the same direction you're pointing, you win! Otherwise, you switch roles and the game continues to the next round — now your friend points in a direction and you try to look away. (So the player who starts as the pointer is the pointer in the odd-numbered rounds, and the player who starts as the looker is the pointer in the even-numbered rounds, until the game ends.) As long as no one wins, you keep switching off who points and who looks.
The game ends, and the current "pointer" wins, whenever the  "looker" looks in the same direction as the pointer.

We saw in Example \@ref(exm:lookaway) that the probability that the player who starts as the pointer wins the game is 4/7 = 0.571.

```


1. Compute and interpret the expected number of rounds in a game.
1. Compute and intepret the conditional expected number of rounds in a game given that the player who is the pointer in the first round wins the game.
1. Compute and interpret the conditional expected number of rounds in a game given that the player who is the looker in the first round wins the game.




```{solution, lookaway-ce-sol}
to Example \@ref(exm:lookaway-ce)
```

```{asis, fold.chunk = TRUE}
1. Let $X$ be the number of rounds in the game. We want $\mu = \E(X)$.
Condition on the result of the first round.
If the pointer wins the first round, which occurs with probability 1/4, the game is over and $X=1$.
If the pointer does now win the first round, which occurs with probability 3/4, one round is played and then the game "starts over" and the expected number of additional rounds is $\mu$.
By the law of total expectation $\mu = (1)(1/4) + (1+\mu)(3/4)$; solve for $\mu = 4$.
Over many games, on average 4 rounds are played.
1. Let $I$ be the indicator that the player who starts as the pointer wins the game.
We want $\mu_1 = \E(X|I=1)$.
We can basically repeat our strategy from the previous part, but now we condition on the player who starts as the pointer winning the game everywhere.
Again, we'll consider two cases based on the results of the first round.
If the pointer wins the first round, the game ends and $X = 1$; the weight of this case is the *conditional* probability that the pointer wins in the first round given that the pointer wins the game, which is
$$
\IP(\text{first pointer wins first round} | \text{first pointer wins game}) = \frac{\IP(\text{first pointer wins first round and first pointer wins game})}{\IP(\text{first pointer wins game})} = \frac{1/4}{4/7} = 7/16=0.4375
$$
If the pointer does not win the first round, *given that the first pointer wins the game* then 2 more rounds are played --- given that the first pointer wins the game, the game cannot end in round 2 --- and then the game "starts over".
By the law of total expectation
$$
\mu_1 = (1)(7/16) + (2 + \mu_1)(9/16)
$$
Solve for $\mu_1 = 25/7 = 3.57$.
Over many games *where the player who starts as the pointer wins* on average 3.57 rounds are played.  
1. We might expect the answer to this part to be 32/7, the answer to the previous part plus 1; the previous part is the average number of rounds given that the game ends in an odd number of rounds, and now we want the average number of rounds give that the game ends in an even number of rounds. We want $\mu_0 = \E(X|I=0)$.
We can use the results of the previous two parts if we condition on which player wins the game and use the law of total expectation.
If the first pointer wins the game, which happens with probability 4/7, the conditional expected value is 25/7.
If the first pointer does not win the game, which happens with probability 3/7, the conditional expected value is $\mu_0$.
The overall expected value is 4, so use the law of total expected value
\begin{align*}
\E(X) & = \E(X|I = 1)\IP(I = 1) + \E(X | I = 0)\IP(I = 0)\\
4 & = (25/7)(4/7) + \mu_0(3/7)
\end{align*}
Solve for $\mu_0 = 32/7 = 4.57$.
Over many games *where the player who starts as the pointer does not win* on average 4.57 rounds are played.

```

The following is a simulation of the lookaway challenge problem.


```{python}

def count_rounds(sequence):
    for r, pair in enumerate(sequence):
        if pair[0] == pair[1]:
            return r + 1 # +1 for 0 indexing

P = BoxModel([1, 2, 3, 4], size = 2) ** inf

X = RV(P, count_rounds)

x = X.sim(25000)

x
```


Approximate distribution of the number of rounds.

```{python, eval = FALSE}
x.plot()
```


```{python, echo = FALSE}
plt.figure()
x.plot()
plt.show()
```

Approximate probability that the player who starts as the pointer wins the game (which occurs if the game ends in an odd number of rounds).

```{python}
def is_odd(u):
    return (u % 2) == 1 # odd if the remainder when dividing by 2 is 1

x.count(is_odd) / x.count()
```


Approximate expected number of rounds.

```{python}
x.mean()
```


Approximate conditional probability that the player who starts as the pointer wins in the first round given that the player who starts as the pointer wins the game.

```{python}

x.count_eq(1) / x.count(is_odd)

```


Approximate conditional expected number of rounds given that the player who starts as the pointer wins the game.


```{python}
x.filter(is_odd).mean()
```


Approximate conditional expected number of rounds given that the player who starts as the pointer does not win the game.


```{python}
def is_even(x):
    return (x % 2) == 0 # odd if the remainder when dividing by 2 is 0

x.filter(is_even).mean()
```



### Taking out what is known





```{example random-rectangle-height}

Suppose you construct a "random rectangle" as follows. The base $X$  is a random variable with a Uniform(0, 1) distribution.  The height $Y$ is a random variable whose conditional distribution given $X=x$ is  Uniform(0, $x$). We are interested in $\E(Y)$ the expected value of the height of the rectangle.

```

1. Explain how you could use the Uniform(0, 1) spinner to simulate an $(X, Y)$ pair.
1. Explain how you could use simulation to approximate $\E(Y)$.
1. Find $\E(Y|X=0.5)$.
1. Find $\E(Y|X=0.2)$.
1. Find $\E(Y|X=x)$ for a generic $x\in(0, 1)$.
1. Identify the random variable $\E(Y|X)$.
1. Use LTE to find $\E(Y)$.
1. Sketch a plot of the joint distribution of $(X, Y)$.
1. Sketch a plot of the marginal distribution of $Y$.  Be sure to specify the possible values.  Is it Uniform?
1. What would you need to do to find $\E(Y)$ using the definition of expected value?

```{solution, random-rectangle-height-sol}
to Example \@ref(exm:random-rectangle-height)
```

1. Spin the spinner twice and let $U_1$ be the result of the first spin and $U_2$ the result of the second.  Let $X=U_1$.  Now consider an example. Given $X=0.2$, we want $Y$ to have a Uniform(0, 0.2) distribution. So we could take the result of the second spin (on a (0, 1) scale) and multiply by 0.2 to get a value on a (0, 0.2) scale.  (Remember: linear rescaling only changes the possible values and not the shape of the distribution; see Section \@ref(sec-linear-rescaling).)  That is, conditional on $X=0.2$, $0.2U_2$ will have a Uniform(0, 0.2) distribution.  Conditional on a general $x$, $xU_2$ will have a Uniform(0, $x$) distribution.  So if we define the random variable $Y$ as $Y=XU_2$, then the conditional distribution of $Y$ given $X=x$ will be Uniform(0, $x$).
1. Simulate many $(X, Y)$ pairs in the above manner, and find the average of the simulated $Y$ values to approximate $\E(Y)$.
1. The conditional distribution of $Y$ given $X=0.5$ is Uniform(0, 0.5) so $\E(Y|X=0.5)=0.5/2 = 0.25$.
1. The conditional distribution of $Y$ given $X=0.2$ is Uniform(0, 0.2) so $\E(Y|X=0.2)=0.2/2 = 0.10$.
1. For $x\in(0, 1)$, the conditional distribution of $Y$ given $X=x$ is Uniform(0, $x$) so $\E(Y|X=0.2)=x/2$.  Note that for any particular $x$, $\E(Y|X=x)$ is a *number* (e.g., $\E(Y|X=0.2)= 0.10$).
1. $\E(Y|X)=X/2$.  Recall that $\E(Y|X)$ is a random variable, and moreover a function of $X$.  From the previous part we can see that $x/2$ maps $x\mapsto\E(Y|X=x)$, so $\E(Y|X) = X/2$.
1. Use LTE.  Remember that non-random constants pop out of expected values.
\[
\E(Y) = \E(\E(Y|X)) = \E(X/2) = \E(X)/2 = (0.5)/2 = 0.25
\]
1. The $x$ values will be uniformly distributed between 0 and 1.  For each $x$, the $y$ values will be uniformly distributed along the vertical strip between 0 and $x$.  The $(X, Y)$ pairs will lie in the triangular region, $\{(x,y):0<y<x<1\}$, but since the vertical strips are shorter for smaller values of $x$, the density will be higher when $x$ is small than when $x$ is large.  The joint pdf is
\[
f_{X,Y}(x,y) = f_{Y|X}(y|x)f_X(x) = \frac{1}{x}(1), \qquad 0<y<x<1
\]
1. Unconditionally, $Y$ can take any value between 0 and 1.  Collapse $x$ values in the joint pdf.  By looking the horizontal strips in the joint pdf plot, we see that the density of $Y$ will be higher when $y$ is near 0.  We can find the marginal pdf by integrating out the $x$.  For a fixed $y$ in (0, 1) the joint density is positive only if $x$ is in $(y, 1)$.
\[
f_Y(y) = \int f_{X,Y}(x,y) dx = \int_y^1 \frac{1}{x} dx = -\log(y), \qquad 0<y<1
\]
1. In order to find $\E(Y)$ using the definition of expected value, you would need to (1) find the joint pdf of $(X, Y)$, (2) integrate the joint pdf with respect to $x$ to find the marginal pdf of $Y$, and (3) then integrate $\int y f_Y(y) dy$ to find $\E(Y)$:
\[
\int_0^1 y \left(-\log(y)\right)dy=0.25
\]



```{example random-rectangle-area}

Continuing the previous example. Suppose you construct a "random rectangle" as follows. The base $X$  is a random variable with a Uniform(0, 1) distribution.  The height $Y$ is a random variable whose conditional distribution given $X=x$ is  Uniform(0, $x$). We are interested in $\E(XY)$ the expected value of the area of the rectangle.

```

1. Explain how you could use simulation to approximate $\E(XY)$.
1. Find $\E(XY|X=0.5)$.
1. Find $\E(XY|X=0.2)$.
1. Find $\E(XY|X=x)$ for a generic $x\in(0, 1)$.  How does $\E(XY|X=x)$ relate to $\E(Y|X=x)$?
1. Identify the random variable $\E(XY|X)$. How does $\E(XY|X)$ relate to $\E(Y|X)$?
1. Use LTE to find $\E(XY)$.
1. Find $\Cov(X, Y)$.  Does the sign of the covariance make sense?

```{solution, random-rectangle-area-sol}
to Example \@ref(exm:random-rectangle-area)
```

```{asis, fold.chunk = TRUE}


1. Generate an $(X, Y)$ pair as in the previous part: spin the Uniform(0, 1) spinner twice, let $X$ be the result of the first spin and let $Y=XU$ where $U$ is the result of the second spin. Simulate many $(X, Y)$ pairs, for each pair compute the product $XY$, and find the average of the simulated $XY$ values to approximate $\E(XY)$.
1. The conditional distribution of $XY$ given $X=0.5$ is the same as the conditional distribution of $0.5Y$ given $X=0.5$.  Conditional on $X=0.5$ we treat $X$ like the constant 0.5.  So $\E(XY|X=0.5)=\E(0.5Y|X=0.5) = 0.5\E(Y|X=0.5) = 0.5(0.25)=0.125$.  $\E(Y|X=0.5)=0.25$ because the conditional distribution of $Y$ given $X=0.5$ is Uniform(0, 0.5), with mean 0.25.
1. Similar to the previous part, $\E(XY|X=0.2)=\E(0.2Y|X=0.2) = 0.2\E(Y|X=0.2) = 0.2(0.1) = 0.02$.  Notice that even after replacing $X$ with 0.2 we can't drop the conditioning, since the condition $X=2$ changes the distribution of $Y$; $\E(Y|X=0.2)=0.1$ is not the same as $\E(Y)=0.25$.
1. Observe the pattern in the two previous parts and replace 0.5 and 0.2  with a generic $x$: $\E(XY|X=x)=\E(xY|X=x) = x\E(Y|X=x)$.  So we have $\E(XY|X=x)=x\E(Y|X=x)$; conditioning on $X=x$, we treat $X$ as the non-random constant $x$ and so it pops out of the expected value, just like 0.5 and 0.2 did.    Since $\E(Y|X=x)=x/2$ we have $\E(XY|X=x)=x\E(Y|X=x)=x(x/2)=x^2/2$. Note that for any particular $x$, $\E(XY|X=x)$ is a *number* (e.g., $\E(XY|X=0.2)= 0.2^2/2 = 0.02$).
1. $\E(XY|X)=X\E(Y|X)$ and moreover $\E(XY|X)=X^2/2$.  Recall that $\E(XY|X)$ is a random variable, and moreover a function of $X$.  From the previous part we can see that $x^2/2$ maps $x\mapsto\E(Y|X=x)$, so $\E(XY|X) = X^2/2$.
1. Use LTE.  Remember that non-random constants pop out of expected values.
\[
\E(XY) = \E(\E(XY|X)) = \E(X\E(Y|X))) = \E(X^2/2) = \E(X^2)/2 = (1/3)/2 = 1/6
\]
$\E(X^2)=1/3$ follows either by LOTUS, $\int_0^1 x^2(1)dx=1/3$, or since $\E(X^2) = \Var(X) + (\E(X))^2 = 1/12 + (1/2)^2=1/3$ where $\E(X)=1/12$ and $\Var(X)=1/12$ since $X$ has a Uniform(0, 1) distribution.

```




```{theorem TOWIK, name="Taking out what is known (TOWIK)"}
\[
\E(g(X)Y|X) = g(X)\E(Y|X)
\]
```

In particular, $\E(XY|X) = X\E(Y|X)$, $\E(X|X)=X$, and $\E(g(X)|X)=g(X)$.
Intuitively, when we condition on $X$ we treat it as though its value is known, so it behaves like a non-random constant. For example, $\E(XY|X)=X\E(Y|X)$ is the conditional, random variable analog of the unconditional, numerical relationship $\E(cY) = c\E(Y)$ where $c$ is a constant. Note that TOWIK is a relationship between *random variables*.

Let $x$ be a particular possible value of $X$.  Then $g(x)$ is just a number.
Remember that given $X=x$, the random variable $X$ is treated as the fixed constant $x$. Therefore, the conditional distribution of the random variable $g(X)Y$ given $X=x$ is the same as the conditional distribution of the random variable $g(x)Y$ given $X=x$.  Therefore $\E(g(X)Y|X=x) = \E(g(x)Y|X=x)= g(x)\E(Y|X=x)$, where $g(x)$ pops out of the expected value since it is just a number.




A rectangle example like the one in Example \@ref(exm:random-rectangle-area) illustrates the ideas behind the law of total expectation and taking out what is known. Suppose $X$ represents the base of a rectangle and $Y$ its height; the product $XY$ represents the area of the rectangle. We can simulate a rectangle by simulating an $(X, Y)$ from the joint distribution, which might be specified by a marginal distribution of one variable and the conditional distribution of the other.  After simulating many rectangles, we can compute the average height to estimate $\E(Y)$ and the average area to estimate $\E(XY)$.

To estimate $\E(Y)$ and $\E(XY)$ by conditioning on $X$ and using the law of total expectation, we first sort and group the rectangles according to the value of their base $X$.

- One group consists of all the rectangles with a base of $X=0.1$.  The heights of the rectangles in this group are distributed according to the conditional distribution of $Y$ given $X=0.1$.  The average height of the rectangles in this group is $\E(Y|X=0.1)$.  Since all areas in this group have a base of 0.1, the average area of rectangles in this group is $(0.1)\E(Y|X=0.1)$.
- Similarly, the average height of the rectangles with base of $X=0.2$ is $\E(Y|X=0.2)$ and the average area is $(0.2)\E(Y|X=0.2)$.
- Generally, the average height of the rectangles with base of $X=x$ is $\E(Y|X=x)$ and the average area is $(x)\E(Y|X=x)$.


We now have the average height and average area of the rectangles in each group.  But not all groups have the same number of rectangles.  So when computing the overall average height and average area groups with more rectangles get more weight.




### Independent, uncorrelated, and something in between

```{theorem}
For any random variables $X$ and $Y$,

1. If $X$ and $Y$ are independent then $\IP(\E(Y|X)=\E(Y))=1$ and $\IP(\E(X|Y)=\E(X)) = 1$.
1. If either $\IP(\E(Y|X)=\E(Y))=1$ or $\IP(\E(X|Y)=\E(X)) = 1$ then $X$ and $Y$ are uncorrelated.

```

Roughly, if $X$ and $Y$ are independent then $\E(Y|X)=\E(Y)$.  However, this is a  nonsensical statement: on the left is $\E(Y|X)$ a random variable (a function), and on the right is $\E(Y)$ a number.  If $X$ and $Y$ are independent, then the conditional distribution of $Y$ is the same for all values of $X$, and so the mean of $Y$ is the same for all values of $X$.

If, roughly, $\E(Y|X)=\E(Y)$, then the average value of $Y$ does not change with $X$.  This is enough for $X$ and $Y$ to be uncorrelated.  Since the average value of $Y$ does not change with $X$ there is no overall positive or negative association.  Here is a proof; suppose $\IP(\E(Y|X)=\E(Y))=1$, then

\begin{align*}
\E(XY) & = \E(\E(XY|X)) & & \text{LTE}\\
& = \E(X\E(Y|X)) & & \text{TOWIK}\\
& = \E(X\E(Y)) & & \text{by assumption}\\
& = \E(X)\E(Y) & & \text{$\E(Y)$ is a number}
\end{align*}

So if $\IP(\E(Y|X)=\E(Y))=1$ then $X$ and $Y$ are uncorrelated.

In short, if $X$ and $Y$ are independent then $\E(Y|X)=\E(Y)$, and if $\E(Y|X)=\E(Y)$ then $X$ and $Y$ are uncorrelated.  By the converses are not true.

```{example uncorrelated-not-orthogonal}

Let $X$ and $Y$ be discrete random variables with joint pmf

|             |       |       |       |
|------------	|-----:	|-----:	|-----:	|
| $x$ \\ $y$ 	|   -1 	|    0 	|    1 	|
| -1        	| 0.10 	|    0 	| 0.25 	|
| 0          	| 0.30 	|    0 	|    0 	|
| 1          	|    0 	| 0.20	| 0.15 	|

```

1. Find $\E(Y)$.
1. Find $\E(Y|X=x)$ for each $x$.  Is $\E(Y|X)$ constant?
1. Find $\E(X)$.
1. Find $\E(X|Y=y)$ for each $y$.  Is $\E(X|Y)$ constant?
1. Find $\Cov(X, Y)$. Are $X$ and $Y$ uncorrelated?
1. Are $X$ and $Y$ independent?



```{solution, uncorrelated-not-orthogonal-sol}
to Example \@ref(exm:uncorrelated-not-orthogonal)
```

1. $\E(Y)= (-1)(0.40) + (0)(0.20)+(1)(0.40) = 0$.
1. No, as is true in general, $\E(Y|X)$ is not constant in this example.
\begin{align*}
\E(Y|X=-1) & = (-1)(10/35) + (0)(0)+(1)(20/35) = 2/7\\
\E(Y|X=0) & = (-1)(1) + (0)(0)+(1)(0) = -1\\
\E(Y|X=1) & = (-1)(0) + (0)(20/35)+(1)(10/35) = 2/7\\
\end{align*}
1.$\E(X)= (-1)(0.40) + (0)(0.20)+(1)(0.40) = 0$.
1. No, as is true in general, $\E(X|Y)$ is not constant in this example.
\begin{align*}
\E(X|Y=-1) & = (-1)(1/4) + (0)(3/4)+(1)(0) = -1/4\\
\E(X|Y=0) & = (-1)(0) + (0)(0)+(1)(1) = 1\\
\E(X|Y=1) & = (-1)(25/40) + (0)(0)+(1)(15/40) = -1/4\\
\end{align*}
1. $\E(XY)= (-1)(-1)(0.1)+(1)(-1)(0.25) + (1)(-1)(0)+(1)(1)(0.15)+0=0$ so $\Cov(X, Y)=\E(XY)-\E(X)\E(Y)=0$. Yes, $X$ and $Y$ are uncorrelated.
1. No, $X$ and $Y$ are not independent.  For example $\E(Y|X=-1)=2/7$ but $\E(Y|X=0)=-1$.


